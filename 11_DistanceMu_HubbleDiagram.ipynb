{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance modulus computation using the NIR template\n",
    "\n",
    "#### I have to run this notebook 2 times: \n",
    "1) The first time to determine:\n",
    "- the apparent magnitudes (and their uncertainties, sigma_m) at t_Bmax infered from the template fit.\n",
    "- uncertainty in the photometric distance moduli of the SNe sample defined as: \n",
    "    error_mu_photometric^2 = sigma_m^2\n",
    "where sigma_m is the uncertainty in the apparent magnitude at t_Bmax computed in this first run.\n",
    "- the absolute magnitude for each SN from AbsMag = appMag - mu_LCDM(z).\n",
    "- the average absolute magnitude at t_Bmax, mean_AbsMag, with its standard deviation of the SNe sample. Write down these values in (AverageAbsMag_atMax, err_AverageAbsMag_atMax).\n",
    "\n",
    "Run this notebook until the end of section \"Determining average Absolute magnitude of the sample\".\n",
    "Set: AbsMagFromHisto = False\n",
    "\n",
    "2) The second time to determine: \n",
    "- the photometric distance moduli of the SNe sample defined as mu_photometric = appMag - mean_AbsMag.\n",
    "- the intrinsic dispersion of the Hubble-diagram residual, sigma_intrinsic. \n",
    "\n",
    "Run the entire notebook\n",
    "Set: AbsMagFromHisto = True\n",
    "    \n",
    "#### Diverse\n",
    "\n",
    "Relationship between index (a.k.a, row or line) of the \"Template_phase_mu_tau_FromR.dat\" and the day (= phase):\n",
    "day = (index - 71)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HoFix = 73.24 # Valued used by default in the paper\n",
    "# HoFix = 72.0 # 72 # 73.24  # Hubble constant (km/(s Mpc))\n",
    "# HoFix = 72.78 # # TEMPORAL: value reported by Dhawan et al 2017.\n",
    "\n",
    "# Peculiar velocity (km/s). Options: (150, 200, 300, 400)\n",
    "# This number must be an integer: it is used to name the output folder.\n",
    "vpecFix = 150   \n",
    "\n",
    "BandName = 'Y'   # What band to fit:(Y, J, H ,K)\n",
    "\n",
    "# Mean Absolute magnitude determined from histogram of 'appMagTmax_s - mu_s'?:\n",
    "# First run the notebook with this option with setting the value to \n",
    "# \"False\" in order to determine \n",
    "# the mean abs mag, then once I get that number, run a second time \n",
    "# the notebook with this option as \"True\"\n",
    "# to compute the final tables and results.\n",
    "# If \"True\" it is generated the final 'DistanceMu_Good_AfterCutoffs_Main_.txt' \n",
    "# text file, otherwise if \"False\"\n",
    "# generate temporal text files.\n",
    "\n",
    "AbsMagFromHisto = False  \n",
    "\n",
    "# Use all this notebook just to plot the Hubble diagram?\n",
    "# Useful to create the HD for other cases  different to the template method.\n",
    "# If 'False' then compute the distance modulus using the template method.\n",
    "NotebookToPlotOnly = True\n",
    "\n",
    "NotebookName = '11_DistanceMu_HubbleDiagram.ipynb'    \n",
    "\n",
    "###############################################################\n",
    "\n",
    "#--- Fixed values ---\n",
    "OmMFix = 0.28 # Omega_Matter\n",
    "OmLFix = 0.72 # Omega_Lambda\n",
    "wFix = -1 # Dark energy EoS\n",
    "c = 299792.458  # Speed of light (km/s)\n",
    "# In the process to convert all the 'c' to 'cc'\n",
    "cc = 299792.458  # Speed of light (km/s) \n",
    "\n",
    "#--- Uncertainty in z_CMB:---\n",
    "\n",
    "# Used to plot the -theoretical- peculiar velocity uncertanty in the\n",
    "# Hubble residual plot.\n",
    "\n",
    "# Dan Scolnic gave me the value of err_cz_CMB = 150 km/s about the \n",
    "# collection of z_CMB values he provided me.\n",
    "# err_zCMB_fix =  0.0005003461427972281 when err_cz_CMB = 150 km/s\n",
    "err_zCMB_fix = 150.0/cc  # 150 has units of km/s\n",
    "\n",
    "# Just to plot the peculiar velocity uncertainty curve in the \n",
    "# Hubble-diagram residual, \n",
    "# I was using,  err_zCMB_fix = 0.001, that is the average \n",
    "# error_zcmb in Andy's compilation.\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "#   SELECT THE APPARENT MAG DATA TO USE TO CONSTRUCT THE HUBBLE DIAGRAM\n",
    "# The plots with cuts z>0 and z>0.01 are done automatically.\n",
    "\n",
    "# KindOfData4HD = 'CfA'\n",
    "# KindOfData4HD = 'CSP'\n",
    "# KindOfData4HD = 'Others'\n",
    "KindOfData4HD = 'AllSamples'\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "#   SELECT THE TEMPLATE TO USE TO COMPUTE THE DISTANCE MODULUS\n",
    "\n",
    "# This will be also the data used to construct the Hubble diagram\n",
    "# Selecting from '3_Template' folder\n",
    "\n",
    "#- Use the template constructed from the subsample?:\n",
    "# KindOfTemp = 'CfA'\n",
    "# KindOfTemp = 'CSP'\n",
    "# KindOfTemp = 'Others'\n",
    "KindOfTemp = 'AllSamples'\n",
    "\n",
    "KindOfTempSubgroup = 'z_gr_0'\n",
    "# KindOfTempSubgroup = 'z_gr_001'\n",
    "# KindOfTempSubgroup = 'AllGoodData'\n",
    "\n",
    "# Indicate the technique used to compute the GP fitting in \n",
    "# the '1_AllData_InitialFit' step:\n",
    "# TempPrior_Hyper = Using a template prior (computed from \n",
    "# the Moving Windows Average template) for the Gaussian Process \n",
    "# fitting, then determining the hyperparameters using all \n",
    "# the LCs simultaneously.\n",
    "# FlatPrior= Assuming a flat prior at ~ -17 Abs mag, then \n",
    "# computing the hyperparameters for each LC independently.\n",
    "# MWA = Moving windows average\n",
    "\n",
    "# TempType = 'TempPrior_Hyper' \n",
    "TempType = 'FlatPrior' # I use this option for the paper\n",
    "# TempType = 'MWA' \n",
    "\n",
    "# - Smoothed Moving windows average to construct the template\n",
    "# TempType = 'MWA' # Moving windows average\n",
    "# If TempType = 'MWA' then specify the template file to use\n",
    "MWATempTypeFile = 'TempWeightedSmooth_Box7_Step05_Window21_Poly3.dat'\n",
    "\n",
    "# Use a build-in normalized template?:\n",
    "# Normalized = True\n",
    "# It is, use a template that was constructed assuming \n",
    "# vPec=0 km/s during the GP fitting of the individual LCs, \n",
    "# and then with the option 'NormalizedTemp' in the \n",
    "# hierarchical Bayesian code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset the values:\n",
    "Average_NIRAbsMag_TBmax = None;  \n",
    "error_Average_NIRAbsMag_TBmax = None;\n",
    "\n",
    "#--------------------------------------\n",
    "\n",
    "if BandName == 'J':\n",
    "    \n",
    "    # Redshift cutoff.\n",
    "    # In the low-z paper we use zcmbUpperLim = 0.04.\n",
    "    zcmbUpperLim = 0.04      # Options: (0.04,0.06,0.09, 0.65). \n",
    "\n",
    "    # These values have to be computed the first time I run this notebook.\n",
    "    # NOTE: The values of \"Average_NIRAbsMag_TBmax\" and \n",
    "    # \"error_Average_NIRAbsMag_TBmax\" do NOT depend on the value of \"vpecFix\".\n",
    "\n",
    "    if zcmbUpperLim == 0.04:\n",
    "        \n",
    "        # ------------------------------\n",
    "        #   J band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        # Average_NIRAbsMag_TBmax = -18.3930007685;  # 2018-04-26; 01:29 hrs.\n",
    "        # error_Average_NIRAbsMag_TBmax = 0.182603385426;\n",
    "        \n",
    "        # ------------------------------\n",
    "        #   J band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        Average_NIRAbsMag_TBmax = -18.338193359;  # 2018-07-12; 21:34 hrs.\n",
    "        error_Average_NIRAbsMag_TBmax = 0.176009661876;\n",
    "\n",
    "    elif zcmbUpperLim == 0.06:\n",
    "        # Using Foley + Cepheid + Special cases's zcmb: \n",
    "        Average_NIRAbsMag_TBmax = -18.3915728254;   \n",
    "        error_Average_NIRAbsMag_TBmax = 0.177460478042; \n",
    "\n",
    "    elif zcmbUpperLim == 0.09:\n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = nan ;   error_Average_NIRAbsMag_TBmax = nan ; #\n",
    "\n",
    "        \n",
    "    # Ignore data with a chi^2_dof larger than a given threshold:\n",
    "    # Use the values ( chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6') \n",
    "    # the first time I run the notebook.\n",
    "    chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6'  \n",
    "    # chi2_dof_Max = 3.5; chi2_dof_Max_Label = 'chi3_5'\n",
    "\n",
    "    # Length hyperparameter from the GP fit.\n",
    "    l_kern = 7.0552; \n",
    "\n",
    "    # PHASE RANGE IN DAYS OF TEMPLATE TO USE TO COMPUTE THE DISTANCE MODULUS\n",
    "    PhaseMinTemp = -8 # -8 days\n",
    "    PhaseMaxTemp = 30 # 30, 41, days\n",
    "\n",
    "    # Not in use yet. AbsMag_NIRmax= -18.4670;  error_AbsMag_NIRmax=0.02974; phase_NIRmax = -4.5; \n",
    "\n",
    "    #-- EBV cutoff\n",
    "    EBVhostMin = -0.4 # -0.4 # host galaxy\n",
    "    EBVhostMax = 0.4 # 0.4 # host galaxy. \n",
    "    EBVMWLim = 1 # Milky-Way galaxy\n",
    "\n",
    "    #-- dm15 cutoff\n",
    "    dm15LowerLim = 0.8 # I assume 0.79.\n",
    "    dm15UpperLim = 1.6\n",
    "    \n",
    "    # - Smoothed Moving windows average to construct the template\n",
    "    # If TempType = 'MWA' then specify the template file to use\n",
    "    MWATempTypeFile = 'TempWeightedSmooth_Box7_Step05_Window21_Poly3.dat'\n",
    "\n",
    "###########################################################\n",
    "\n",
    "if BandName == 'Y': \n",
    "\n",
    "    # Redshift cutoff.\n",
    "    # In the low-z paper we use zcmbUpperLim = 0.04.\n",
    "    zcmbUpperLim = 0.04      # Options: (0.04,0.06,0.09, 0.65). \n",
    "\n",
    "    # These values have to be computed the first time I run this notebook.\n",
    "    # NOTE: The values of \"Average_NIRAbsMag_TBmax\" and \"error_Average_NIRAbsMag_TBmax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if zcmbUpperLim == 0.04: \n",
    "\n",
    "        # ------------------------------\n",
    "        #   Y band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        Average_NIRAbsMag_TBmax = -18.127153489;  # 2018-07-12; 21:02 hrs.\n",
    "        error_Average_NIRAbsMag_TBmax = 0.160051080419;\n",
    "\n",
    "    elif zcmbUpperLim == 0.06:\n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = -18.2640428698;   \n",
    "        error_Average_NIRAbsMag_TBmax = 0.145468431004; \n",
    "\n",
    "\n",
    "    elif zcmbUpperLim == 0.09: \n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = nan ;   \n",
    "        error_Average_NIRAbsMag_TBmax = nan ; #\n",
    "\n",
    "\n",
    "    # Ignore data with a chi^2_dof larger than a given threshold:\n",
    "    # Use the values ( chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6') \n",
    "    # the first time I run the notebook.\n",
    "    # chi2_dof_Max = 3.5; chi2_dof_Max_Label = 'chi3_5'\n",
    "    chi2_dof_Max = 3; chi2_dof_Max_Label = 'chi3'\n",
    "\n",
    "    l_kern = 7.9874; \n",
    "\n",
    "    # PHASE RANGE IN DAYS OF TEMPLATE TO USE TO COMPUTE THE DISTANCE MODULUS\n",
    "    PhaseMinTemp = -8 # -8 days\n",
    "    PhaseMaxTemp = 30 # 30, 41, days\n",
    "\n",
    "    #-- EBV cutoff\n",
    "    EBVhostMin = -0.4 # -0.4 # host galaxy\n",
    "    EBVhostMax = 0.4 # 0.4 # host galaxy. \n",
    "    EBVMWLim = 1 # Milky-Way galaxy\n",
    "\n",
    "    #-- dm15 cutoff\n",
    "    dm15LowerLim = 0.8 # I assume 0.8.\n",
    "    dm15UpperLim = 1.6\n",
    "    \n",
    "    # - Smoothed Moving windows average to construct the template\n",
    "    # If TempType = 'MWA' then specify the template file to use\n",
    "    MWATempTypeFile = 'TempWeightedSmooth_Box7_Step05_Window21_Poly3.dat'\n",
    "\n",
    "###########################################################\n",
    "\n",
    "if BandName == 'H': \n",
    "\n",
    "    # Redshift cutoff.\n",
    "    # In the low-z paper we use zcmbUpperLim = 0.04.\n",
    "    zcmbUpperLim = 0.04      # Options: (0.04,0.06,0.09, 0.65). \n",
    "\n",
    "    # These values have to be computed the first time I run this notebook.\n",
    "    # NOTE: The values of \"Average_NIRAbsMag_TBmax\" and \"error_Average_NIRAbsMag_TBmax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    # The value of 'IntrinsicDisp_GP' comes from the Gaussian-Process Hubble diagram\n",
    "\n",
    "    if zcmbUpperLim == 0.04: \n",
    "        \n",
    "        # ------------------------------\n",
    "        #   H band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        # Average_NIRAbsMag_TBmax = -18.1321913853;  # 2018-04-26; 02:22 hrs.\n",
    "        # error_Average_NIRAbsMag_TBmax = 0.17494126888;\n",
    "        \n",
    "        # ------------------------------\n",
    "        #   H band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        Average_NIRAbsMag_TBmax = -18.1847957204;  # 2018-07-12; 22:48 hrs.\n",
    "        error_Average_NIRAbsMag_TBmax = 0.163480843711;\n",
    "\n",
    "\n",
    "    elif zcmbUpperLim == 0.06: \n",
    "        # Using Foley + Cepheid + Special cases's zcmb: \n",
    "        Average_NIRAbsMag_TBmax = -18.1365343086;   error_Average_NIRAbsMag_TBmax = 0.166013465848 ;   \n",
    "         \n",
    "\n",
    "    elif zcmbUpperLim == 0.09: \n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = nan ;   error_Average_NIRAbsMag_TBmax = nan ; #\n",
    "\n",
    "\n",
    "    # Ignore data with a chi^2_dof larger than a given threshold:\n",
    "    # Use the values ( chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6') \n",
    "    # the first time I run the notebook.\n",
    "    chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6'\n",
    "    # chi2_dof_Max = 3.5; chi2_dof_Max_Label = 'chi3_5'\n",
    "\n",
    "    l_kern = 9.9966; # From the normalized template (with peculiar velocity 0 km/s).\n",
    "\n",
    "    # PHASE RANGE IN DAYS OF TEMPLATE TO USE TO COMPUTE THE DISTANCE MODULUS\n",
    "    PhaseMinTemp = -8 # -8 days\n",
    "    PhaseMaxTemp = 30 # 30, 41, days\n",
    "\n",
    "    # Not in use yet. AbsMag_NIRmax= -18.4670;  error_AbsMag_NIRmax=0.02974; phase_NIRmax = -4.5; \n",
    "\n",
    "    #-- EBV cutoff\n",
    "    EBVhostMin = -0.4 # -0.4 # host galaxy\n",
    "    EBVhostMax = 0.4 # 0.4 # host galaxy. \n",
    "    EBVMWLim = 1 # Milky-Way galaxy\n",
    "\n",
    "    #-- dm15 cutoff\n",
    "    dm15LowerLim = 0.8 # I assume 0.78.\n",
    "    dm15UpperLim = 1.6\n",
    "    \n",
    "    # - Smoothed Moving windows average to construct the template\n",
    "    # If TempType = 'MWA' then specify the template file to use\n",
    "    MWATempTypeFile = 'TempWeightedSmooth_Box7_Step05_Window21_Poly3.dat'\n",
    "\n",
    "###########################################################\n",
    " \n",
    "if BandName == 'K': \n",
    "\n",
    "    # Redshift cutoff.\n",
    "    # In the low-z paper we use zcmbUpperLim = 0.04.\n",
    "    zcmbUpperLim = 0.04      # Options: (0.04,0.06,0.09, 0.65). \n",
    "\n",
    "    # These values have to be computed the first time I run this notebook.\n",
    "    # NOTE: The values of \"Average_NIRAbsMag_TBmax\" and \"error_Average_NIRAbsMag_TBmax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if zcmbUpperLim == 0.04: # \n",
    "        \n",
    "        # ------------------------------\n",
    "        #   K band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        # Average_NIRAbsMag_TBmax = -18.431089343;  # 2018-04-26; 13:09 hrs.\n",
    "        # error_Average_NIRAbsMag_TBmax = 0.214342169223;\n",
    "        \n",
    "        # ------------------------------\n",
    "        #   K band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "        Average_NIRAbsMag_TBmax = -18.3562703093;  # 2018-07-12; 23:02 hrs.\n",
    "        error_Average_NIRAbsMag_TBmax = 0.209567671681;\n",
    "\n",
    "\n",
    "    elif zcmbUpperLim == 0.06:\n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = nan ;   \n",
    "        error_Average_NIRAbsMag_TBmax = nan ; #\n",
    "\n",
    "\n",
    "    elif zcmbUpperLim == 0.09: \n",
    "        # Using Foley + Cepheid + Special cases's zcmb\n",
    "        Average_NIRAbsMag_TBmax = nan ;   \n",
    "        error_Average_NIRAbsMag_TBmax = nan ; #\n",
    "\n",
    "    # Ignore data with a chi^2_dof larger than a given threshold:\n",
    "    # Use the values ( chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6') \n",
    "    # the first time I run the notebook.\n",
    "    # chi2_dof_Max = 1e6; chi2_dof_Max_Label = 'chi_1e6'\n",
    "    chi2_dof_Max = 4; chi2_dof_Max_Label = 'chi4'\n",
    "\n",
    "    l_kern = 8.2101; \n",
    "\n",
    "    # PHASE RANGE IN DAYS OF TEMPLATE TO USE TO COMPUTE THE DISTANCE MODULUS\n",
    "    PhaseMinTemp = -8 # -8 days\n",
    "    PhaseMaxTemp = 30 # 30, 41, days\n",
    "\n",
    "    # Not in use yet. AbsMag_NIRmax= -18.2861;  error_AbsMag_NIRmax=0.03908; phase_NIRmax = -4; \n",
    "\n",
    "    #-- EBV cutoff\n",
    "    EBVhostMin = -0.4 # -0.4 # host galaxy\n",
    "    EBVhostMax = 0.4 # 0.4 # host galaxy. \n",
    "    EBVMWLim = 1 # Milky-Way galaxy\n",
    "\n",
    "    #-- dm15 cutoff\n",
    "    dm15LowerLim = 0.8 # I assume 0.78.\n",
    "    dm15UpperLim = 1.6\n",
    "    \n",
    "    # - Smoothed Moving windows average to construct the template\n",
    "    # If TempType = 'MWA' then specify the template file to use\n",
    "    MWATempTypeFile = 'TempWeightedSmooth_Box7_Step05_Window21_Poly3.dat'\n",
    "    \n",
    "#########################################################################\n",
    "\n",
    "# Warning in case that the mean abs mag was not defined:\n",
    "if Average_NIRAbsMag_TBmax == None and  error_Average_NIRAbsMag_TBmax == None:\n",
    "    print \"# ERROR: The mean abs magnitude and its std dev have to be defined.\"\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "# Text in the notes about the origin of (Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax)\n",
    "if AbsMagFromHisto == True:\n",
    "    Notes1 = 'Determined from the histogram of {appMagTmax_s - mu_LCDM_s}' \n",
    "elif AbsMagFromHisto == False:\n",
    "    Notes1 = 'Just a random guess about these values. It doesnt matter the value of this guess \\\n",
    "because this numbers are to determine the distance modulus but in this first step I m computing \\\n",
    "the appMag_TBmax only.'  \n",
    "\n",
    "#------------------\n",
    "\n",
    "# About 'l_kern': Lenght scale 'l' of the kernel in the covariance matrix for the residual.\n",
    "# this value is ignored in case of 'CovMat_MeanMu = False'\n",
    "# The values I obtained when using the global marginal likehood function to compute \n",
    "# the hyperparameter 'l' using all the LCs together.\n",
    "\n",
    "#==============================================================\n",
    "\n",
    "#             Method to determine the distance modulus\n",
    "# (see description below)\n",
    "\n",
    "Method = 7 # Options  = (1,2,3,4,5,6,7). In the paper I use method 7, before I was using 5.\n",
    "# The best methods are 5 (unnormalized template) and 7 (normalized template).\n",
    "\n",
    "# COVARIANCE MATRICES\n",
    "# It is not necessary to modify the following 2 lines unless some very particular computation is needed.\n",
    "# Using the covariance matrix of the photometry to determine the -mean- and -uncertainty-\n",
    "# of the distance modulus?:\n",
    "if Method==1 or Method==5 or Method==6 or Method==7: CovMat_MeanMu = False; CovMat_ErrorMu = True\n",
    "elif Method==2 or Method==3 or Method==4: CovMat_MeanMu = True; CovMat_ErrorMu = True\n",
    "    \n",
    "# CovMat_MeanMu = False # (True, False). # In the paper I use 'False'\n",
    "# CovMat_ErrorMu = False # (True, False). # In the paper I use 'True'\n",
    "\n",
    "# Use the peculiar velocity covariance square matrix to determine the distance modulus?: \n",
    "#OLD.  Use_CovMat_PecVel = True # (True, False).\n",
    "# NOTE: When \"Use_CovMat_PecVel == True\" then in the total covariance matrix it is used the -uncertainty- \n",
    "# in the mean template instead of the -population standard deviation- of the template.\n",
    "\n",
    "#-------------\n",
    "\n",
    "#-- Minimal number of data in LC:\n",
    "MinNumOfDataInLC = 3\n",
    "\n",
    "# Print the (RMS, WRMS, sigma_int) text in the residual plot?:\n",
    "WRMS_label = True # Print the WRMS of the total sample (or total+subsamples)?\n",
    "RMS_simple = True # or print instead the simple RMS only of total and subsamples?\n",
    "WRMS_subsamples = True # Print the RMS, WRMS of each subsample?\n",
    "\n",
    "#=================================================================\n",
    "#( Fixed values usually) \n",
    "\n",
    "# --- (FIX) Residual cutoff ---\n",
    "# residualMax = 0.7; residualMax_Label = 'resid07'\n",
    "# residualMax = 0.8; residualMax_Label = 'resid08'\n",
    "# residualMax = 0.9; residualMax_Label = 'resid09'\n",
    "# residualMax = 1; residualMax_Label = 'resid1'\n",
    "# residualMax = 3; residualMax_Label = 'resid3'\n",
    "# residualMax = 5; residualMax_Label = 'resid5' \n",
    "residualMax = 20; residualMax_Label = 'resid20' \n",
    "\n",
    "#---- (FIX) Limits in the plots for the Hubble diagram and residual  ----\n",
    "\n",
    "# For the Hubble diagram:\n",
    "xlimPlots = 0.0015, zcmbUpperLim+0.003 # For low-z only\n",
    "ylimPlots = 29.8, 38 # For low-z only\n",
    "\n",
    "# For the Hubble residual\n",
    "ylimPlots_residual = -1, 1\n",
    "\n",
    "#----------------\n",
    "\n",
    "# Plotting range of the fitted LC figures.\n",
    "x_RangePlots = -10, 60;\n",
    "\n",
    "# In the plots of the individual LC, print the chi2_dof value?:\n",
    "Chi2dofPrint = True \n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "#---- (FIX) Filter system ----\n",
    "FilterSyst = 'Std_filters/'\n",
    "# FilterSyst = 'CSP_filters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the methods\n",
    "\n",
    "\"\"\" \n",
    "- Method 1: \n",
    "\t- No use of CovMatrix to determine the best estimate of distance mu (but still optional using \n",
    "    \"CovMat_use == True\" [default: \"CovMat_use == False\" ]),  BUT using it (i.e., \"CovMat_use == True\") \n",
    "    to determine its uncertainty [default: \"CovMat_use == True\" ].\n",
    "\t- using the uncertainty in the mean template instead of the population standard deviation\n",
    "\t- adding the uncertainty in the distance modulus due to the peculiar velocity uncertainty in the total \n",
    "    covariance matrix -before- to compute the distance-modulus uncertainty.\n",
    "\t- CovMat_MeanMu == False\n",
    "\t- CovMat_ErrorMu == True\n",
    "\t- Template = np.genfromtxt('Template_phase_mu_stdError_FromR.dat')\n",
    "\t- CovMatrix_Mu = CovMatResidualMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag + Cov_pecvel # Total covariance matrix -before- \n",
    "    computing\n",
    "\t- sigma2_mu = (1/Denominator_ErrorMu) # Variance mu\n",
    "\t\n",
    "\n",
    "- Method 2: \n",
    "\t- using the uncertainty in the mean template instead of the population standard deviation\n",
    "\t- mean mu: using the CovMat_MeanMu == True and ignoring Cov_pecvel to compute it.\n",
    "\t- error mu: adding in quadratures the uncertainty in the distance modulus due to the peculiar velocity \n",
    "    uncertainty with the uncertainty in the distance modulus from fitting the template -after- computing \n",
    "    the distance modulus\n",
    "    - Apparently, this method gives exactly the same results than Method 3\n",
    "    - CovMat_MeanMu == True\n",
    "\t- CovMat_ErrorMu == True\n",
    "\t- Template = np.genfromtxt('Template_phase_mu_stdError_FromR.dat')\n",
    "\t- CovMatrix_Mu = CovMatResidualMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- sigma2_mu = (1/Denominator_ErrorMu) +  sigma2_pec(zcmbInt, err_zcmb, vpecFix) # Variance mu\n",
    "\n",
    "\n",
    "- Method 3: \n",
    "\t- using the uncertainty in the mean template instead of the population standard deviation\n",
    "\t- adding the uncertainty in the distance modulus due to the peculiar velocity uncertainty in the total \n",
    "    covariance matrix -before- to compute the mean distance modulus and its uncertainty.\n",
    "    - Apparently, this method gives exactly the same results than Method 2\n",
    "\t- CovMat_MeanMu == True\n",
    "\t- CovMat_ErrorMu == True\t\n",
    "\t- Template = np.genfromtxt('Template_phase_mu_stdError_FromR.dat')\n",
    "\t- CovMatrix_Mu = CovMatResidualMu + Cov_appmag + Cov_pecvel # Total covariance matrix -before- computing\n",
    "\t- CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag + Cov_pecvel # Total covariance matrix -before- \n",
    "    computing\n",
    "\t- sigma2_mu = (1/Denominator_ErrorMu) # Variance mu\n",
    "\t\n",
    "\t\n",
    "- Method 4: \n",
    "\t- using the population standard deviation of the template\n",
    "\t- NOT including the uncertainty in the distance modulus due to the peculiar velocity during the fitting.\n",
    "\t= It produces very small error bars for the distance-modulus uncertainty\n",
    "\t- CovMat_MeanMu == True\n",
    "\t- CovMat_ErrorMu == True\t\n",
    "\t- Template = np.genfromtxt('Template_phase_mu_tau_FromR.dat')\n",
    "\t- CovMatrix_Mu = CovMatResidualMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- sigma2_mu = (1/Denominator_ErrorMu) # Variance mu\n",
    "    \n",
    "- Method 5: \n",
    "    - Equal to the method 1 with the difference of using the -population standard deviation- of the template \n",
    "    instead of its uncertainty. The idea of this is that during the fitting of the template to the app mag data \n",
    "    is that it gives more weight to the data around the first NIR peak than the data in the 2nd peak because the \n",
    "    population standard deviation of the template is larger around the 2nd peak, so that my fitting is not \n",
    "    screwed up by the fact that the 2nd peak seems to have an independent variability between the SNe, then \n",
    "    biasing my distance mu estimations.\n",
    "\t- CovMat_MeanMu == False\n",
    "\t- CovMat_ErrorMu == True\n",
    "\t- Template = np.genfromtxt('Template_phase_mu_tau_FromR.dat')\n",
    "\t- CovMatrix_Mu = CovMatResidualMu + Cov_appmag # Total covariance matrix -before- computing\n",
    "\t- CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag + Cov_pecvel # Total covariance matrix -before- computing\n",
    "\t- sigma2_mu = (1/Denominator_ErrorMu) # Variance mu\n",
    "\t\n",
    "    \n",
    "- Method 6:\n",
    "    - So far, equal to method 5 but now normalizing the template, then fit it to determine the apparent \n",
    "    magnitude at T_Bmax, then subtract the absolute magnitude at T_Bmax to determine the photometric\n",
    "    distance modulus.\n",
    "    - I take the regular template constructed in the absolute magnitude frame then I normalize it here in this \n",
    "    notebook, so that \n",
    "    at T_Bmax I set the magnitude to be equal zero.\n",
    "    \n",
    "- Method 7:\n",
    "    - I used a normalized template that was normalized by construction in the hierarchical-Bayesian-R script.\n",
    "    - The rest, same than Method 6.\n",
    "    - The notebook has to be run twice. The first run is to determine the NIR apparent magnitude at t_Bmax only\n",
    "      by fitting the template to the apparent-magnitude light curves, then using the relation, \n",
    "      AbsMag_s = appMag_TBmax - mu_LCDM, it is determined the NIR absolute magnitude at t_Bmax, AbsMag_s, for\n",
    "      each SN. In this run it is created a value of the distance modulus but it is not relevant/reliable. \n",
    "      After the main loop, there is a section to determine <Average_NIRAbsMag_TBmax> from the collection of \n",
    "      {Average_NIRAbsMag_TBmax}\n",
    "      \n",
    "      In the second run is computed final distance modulus from: \n",
    "              mu_photo_Analytic = appMag_TBmax - <Average_NIRAbsMag_TBmax>\n",
    "      In the second run the following quantities are again re-computed like in the first run: \n",
    "      (appMag_TBmax, error_appMagTBmax, mu_LCDM, sigma_muLCDM_vPec, AbsMagTBmax, error_AbsMagTBmax, chi2_dof),\n",
    "      so, their values are -exactly- the same as those obtained during the first run. In the second run, the only \n",
    "      new quantities compared with run 1 are: (mu_photo_Analytic, stdDev_mu, mu_resid)\n",
    "\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import quad as intquad\n",
    "from scipy.optimize import fmin as simplex\n",
    "\n",
    "import os\n",
    "import glob # To read the name of the files in a given directory\n",
    "\n",
    "4+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the name of this ipython notebook\n",
    "To print it in the output text files as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_DistanceMu_HubbleDiagram.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(NotebookName)\n",
    "# 11_DistanceMu_HubbleDiagram_v2_17.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "import datetime \n",
    "\n",
    "# Read the time and date now\n",
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the functions (FlatPrior): 17.0 , 49\n"
     ]
    }
   ],
   "source": [
    "#- Function to convert from index to days (phase)\n",
    "\n",
    "if TempType=='MWA': shiftNum = 24\n",
    "else: shiftNum = 71\n",
    "    \n",
    "#- Function to convert from index to days (phase).\n",
    "def index2day(index):\n",
    "    day = (index-shiftNum)/2.\n",
    "    return day\n",
    "\n",
    "#- Function to convert from days (phase) to index.\n",
    "def day2index(day):\n",
    "    index = 2*day + shiftNum\n",
    "    return index\n",
    "\n",
    "print 'Testing the functions (%s):'%TempType, index2day(105), ',', day2index(-11)\n",
    "\n",
    "#--------------------------------\n",
    "# Converting phases to indices\n",
    "\n",
    "index_LowerPhase = day2index(PhaseMinTemp)\n",
    "index_UpperPhase = day2index(PhaseMaxTemp)\n",
    "\n",
    "LowerLabel = str(PhaseMinTemp)\n",
    "UpperLabel = str(PhaseMaxTemp)\n",
    "\n",
    "#--------------------------------\n",
    "# OLD. Testing the functions (GP): 42 , 155\n",
    "# Testing the functions (MWA): 40.5 , 2\n",
    "# Testing the functions (FlatPrior): 17.0 , 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Settings:\n",
    "\n",
    "if BandName == 'J':\n",
    "    # For overplotting the template to the fitted LC.\n",
    "    # MinMagTempPlot = minimum value in the template plot\n",
    "    if Method==7: MinMagTempPlot = 3.2\n",
    "    else: MinMagTempPlot = -15\n",
    "    \n",
    "elif BandName == 'Y':\n",
    "    # For overplotting the template to the fitted LC.\n",
    "    # MinMagTempPlot = minimum value in the template plot\n",
    "    if Method==7: MinMagTempPlot = 2\n",
    "    else: MinMagTempPlot = -15.5\n",
    "    \n",
    "elif BandName == 'H':\n",
    "    # For overplotting the template to the fitted LC.\n",
    "    # MinMagTempPlot = minimum value in the template plot\n",
    "    if Method==7: MinMagTempPlot = 2\n",
    "    else: MinMagTempPlot = -15.5\n",
    "    \n",
    "elif BandName == 'K':\n",
    "    # For overplotting the template to the fitted LC.\n",
    "    # MinMagTempPlot = minimum value in the template plot\n",
    "    if Method==7: MinMagTempPlot = 2\n",
    "    else: MinMagTempPlot = -15.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining and creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir to save the outputs:\n",
      "/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/10Compute/TheTemplates/Y_band/Std_filters/4_HubbleDiagram_FlatPrior/AllSamples/Templ_AllSamples_z_gr_0/Phase-8_30_resid20_chi3_EBVh0.4_Method7_MinData3_vpec150/plots_HD/\n",
      " \n",
      "Template to be used to fit the LC data:\n",
      "/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/10Compute/TheTemplates/Y_band/Std_filters/3_Template_FlatPrior/AllSamples_vpec_0/z_gr_0/\n",
      " \n",
      "Dir where the LCs in APPARENT mag are located:\n",
      "/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/10Compute/TheTemplates/Y_band/Std_filters/1_AllData_InitialFit/AbsMag/AllSamples/\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Defining the directories\n",
    "\n",
    "DirMain_1 = '/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/\\\n",
    "10Compute/TheTemplates/' \n",
    "\n",
    "DirMain = (DirMain_1+BandName+'_band/'+FilterSyst)  \n",
    "\n",
    "DirHubbleDiag = DirMain+'4_HubbleDiagram_%s/'%(TempType)\n",
    "\n",
    "if CovMat_MeanMu == True:\n",
    "    # OLD. CovMatLabel_MeanMu = 'lkern%s'%(l_kern)+'_CovMat'\n",
    "    CovMatLabel_MeanMu = 'CovMatMu'\n",
    "elif CovMat_MeanMu == False:\n",
    "    CovMatLabel_MeanMu = 'NoCovMatMu'\n",
    "    \n",
    "if CovMat_ErrorMu == True:\n",
    "    CovMatLabel_ErrorMu = 'CovMatErrorMu'\n",
    "elif CovMat_ErrorMu == False:\n",
    "    CovMatLabel_ErrorMu = 'NoCovMatErrorMu'\n",
    "    \n",
    "# Old.\n",
    "# DirSaveOutput = (DirHubbleDiag + KindOfData4HD +'/Templ_'+KindOfTemp+'_'+\n",
    "#                  KindOfTempSubgroup+'/Phase'+LowerLabel+'_'+UpperLabel+'_'+residualMax_Label+'_'+\n",
    "#                  chi2_dof_Max_Label+'_EBVh%r'%EBVhostMax+'_Method%r'%Method+\n",
    "#                  '_'+CovMatLabel_MeanMu+'_'+CovMatLabel_ErrorMu+\n",
    "#                  '_MinData%r'%MinNumOfDataInLC+'_vpec%r'%vpecFix+'/')\n",
    "\n",
    "DirSaveOutput = (DirHubbleDiag + KindOfData4HD +'/Templ_'+KindOfTemp+'_'+\n",
    "                 KindOfTempSubgroup+'/Phase'+LowerLabel+'_'+UpperLabel+'_'+residualMax_Label+'_'+\n",
    "                 chi2_dof_Max_Label+'_EBVh%r'%EBVhostMax+'_Method%r'%Method+\n",
    "                 '_MinData%r'%MinNumOfDataInLC+'_vpec%r'%vpecFix+'/plots_HD/')\n",
    "\n",
    "# old. DirAppMag = DirMain+'1_AllData_InitialFit/AppMag/'\n",
    "DirAppMag = DirMain+'1_AllData_InitialFit/AbsMag/AllSamples/'\n",
    "\n",
    "# Dir template:\n",
    "DirTemplate = DirMain+'3_Template_%s/'%(TempType)+KindOfTemp+'_vpec_0/'+KindOfTempSubgroup+'/'\n",
    "\n",
    "#- Force the creation of the directory to save the outputs.\n",
    "#- \"If the subdirectory does not exist then create it\"\n",
    "import os # To use command line like instructions\n",
    "if not os.path.exists(DirSaveOutput): os.makedirs(DirSaveOutput)\n",
    "\n",
    "# Dir to save the plots of each fitted SNe\n",
    "if NotebookToPlotOnly == False:\n",
    "    if not os.path.exists(DirSaveOutput+'Plot_Fits/'): os.makedirs(DirSaveOutput+'Plot_Fits/')\n",
    "    if not os.path.exists(DirSaveOutput+'Plot_Fits/AfterCutoffs_z001/'): os.makedirs(DirSaveOutput+'Plot_Fits/AfterCutoffs_z001/')\n",
    "    if not os.path.exists(DirSaveOutput+'Plot_Fits/AfterCutoffs_z0/'): os.makedirs(DirSaveOutput+'Plot_Fits/AfterCutoffs_z0/')\n",
    "    if not os.path.exists(DirSaveOutput+'Plot_Fits/OutCutoffs/'): os.makedirs(DirSaveOutput+'Plot_Fits/OutCutoffs/')\n",
    "\n",
    "# Visualizing the directories\n",
    "print 'Dir to save the outputs:'\n",
    "print DirSaveOutput\n",
    "print ' '\n",
    "\n",
    "print 'Template to be used to fit the LC data:'\n",
    "print DirTemplate\n",
    "print ' '\n",
    "\n",
    "print 'Dir where the LCs in APPARENT mag are located:'\n",
    "print DirAppMag\n",
    "print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    import os # To use command line like instructions\n",
    "    import glob # To read the files in my directory\n",
    "\n",
    "    # Change the working directory where the data files are located\n",
    "    os.chdir(DirAppMag)\n",
    "\n",
    "    #--- Reading the data files in the app mag folder \n",
    "    if KindOfData4HD == 'CfA':\n",
    "        list_SNe2 = glob.glob('*'+'CfA_'+BandName+'.txt')\n",
    "    elif KindOfData4HD == 'CSP':\n",
    "        list_SNe2 = glob.glob('*'+'CSP_'+BandName+'.txt')\n",
    "    elif KindOfData4HD == 'Others':\n",
    "        list_SNe2 = glob.glob('*'+'Others_'+BandName+'.txt')\n",
    "    elif KindOfData4HD == 'AllSamples':\n",
    "        list_SNe2 = glob.glob('*'+BandName+'.txt')\n",
    "\n",
    "    print '# Number of -%s- SNe in the APPARENT mag list (%s):'%(\n",
    "        KindOfData4HD,TempType), len(list_SNe2)\n",
    "\n",
    "    # Number of SNe in APPARENT mag list: 132\n",
    "    # Number of -AllSamples- SNe in the APPARENT mag list (MWA): 142\n",
    "    # Number of -AllSamples- SNe in the APPARENT mag list (FlatPrior): 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "\n",
    "    #     CREATE &/or READ THE NAME OF THE SNe FROM THE TEXT FILE\n",
    "\n",
    "    # Change the working directory where the data files are located\n",
    "    os.chdir(DirSaveOutput)\n",
    "    # Reading the data files in that folder \n",
    "    Textfiles = glob.glob('ListSNe_AppMag*.txt')\n",
    "\n",
    "    # Reset the variable\n",
    "    list_SNe = np.array([0])\n",
    "\n",
    "    if 'ListSNe_AppMag_Notes_.txt' in Textfiles:\n",
    "        list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_Notes_.txt', dtype=['S33', int])\n",
    "        print '# Reading the existing < ListSNe_AppMag_Notes_.txt > file.'\n",
    "        print \"# %s SNe file names in this list and uploaded to RAM memory.\"%len(list_SNe)\n",
    "\n",
    "    elif 'ListSNe_AppMag_.txt' in Textfiles:\n",
    "        list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_.txt', dtype=['S33', int])\n",
    "        print '# Reading the existing < ListSNe_AppMag_.txt > file.'\n",
    "        print \"# %s SNe file names in this list and uploaded to RAM memory.\"%len(list_SNe)\n",
    "\n",
    "    #--------------------------------------------------\n",
    "\n",
    "    # if ListSNe_AppMag_.txt doesn't exist, then create it and read it.\n",
    "\n",
    "    else: \n",
    "        # Create a list text file with the name of the SNe of the apparent mag LCs.\n",
    "        list_SNe_file = open(DirSaveOutput+'ListSNe_AppMag_.txt', 'w')\n",
    "\n",
    "        list_SNe_file.write('# SN list of LCs to be used to \\\n",
    "construct the Hubble diagram \\n')\n",
    "        list_SNe_file.write('# I m NOT applying any quality cutoff yet: These \\\n",
    "SNe are ALL those located in: \\n')\n",
    "        list_SNe_file.write('# %s \\n'%DirAppMag)\n",
    "\n",
    "        #------\n",
    "        now = datetime.datetime.now() # Read the time and date right now\n",
    "        text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd)\")\n",
    "        text_Date   = '# On date: %s \\n'%text_timenow\n",
    "        text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "        text_script = '# Script used: %s \\n'%NotebookName\n",
    "        text_line = '#'+'-'*50 + '\\n'\n",
    "\n",
    "        list_SNe_file.write(text_line); \n",
    "        list_SNe_file.write(text_Author); list_SNe_file.write(text_Date); list_SNe_file.write(text_script);\n",
    "        list_SNe_file.write(text_line);\n",
    "        #------\n",
    "\n",
    "        # Upload the list of repeated SNe between CfA and CSP\n",
    "        DirRepeatedSNe = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "        RepeatedSNeList = np.genfromtxt(DirRepeatedSNe+'RepeatedSNe_between_CfA_CSP.txt',\n",
    "                                       dtype=['S10', int])\n",
    "\n",
    "        # Upload the list of SNe to discard from the Hubble diagrams\n",
    "        DirSNeWithIssues = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "        SNeWithIssuesList = np.genfromtxt(DirRepeatedSNe+'SNeWithIssues.txt',\n",
    "                                       dtype=['S30', 'S150'])\n",
    "\n",
    "        for name in list_SNe2:\n",
    "            snname_int =    '%s'%name[0:8]\n",
    "            subsample_int = '%s'%name[-9:-6]\n",
    "            # print snname_int, subsample_int\n",
    "\n",
    "            if snname_int not in SNeWithIssuesList['f0']:\n",
    "                if snname_int not in RepeatedSNeList['f0']:\n",
    "                    # SNe to be NO commented:\n",
    "                    list_SNe_file.write('%-32s  0 \\n'%name)\n",
    "\n",
    "                # Comment automatically the repeated SNe.\n",
    "                elif snname_int in RepeatedSNeList['f0']:\n",
    "                    for i1 in range(len(RepeatedSNeList['f0'])):\n",
    "                        if snname_int == RepeatedSNeList['f0'][i1]:\n",
    "                            if RepeatedSNeList['f1'][i1] == 1 and subsample_int =='CSP':\n",
    "                                list_SNe_file.write('%-32s    1 ## Repeated. CfA selected. \\n'%name)\n",
    "                            elif RepeatedSNeList['f1'][i1] == 2 and subsample_int =='CfA':\n",
    "                                list_SNe_file.write('%-32s    1 ## Repeated. CSP selected. \\n'%name)\n",
    "                            else:\n",
    "                                list_SNe_file.write('%-32s  0 \\n'%name)\n",
    "\n",
    "            elif snname_int in SNeWithIssuesList['f0']:\n",
    "                for i2 in range(len(SNeWithIssuesList['f0'])):\n",
    "                    if snname_int == SNeWithIssuesList['f0'][i2]:\n",
    "                        list_SNe_file.write('%-32s    1 ## %s \\n'%(\n",
    "                            name, SNeWithIssuesList['f1'][i2]))\n",
    "\n",
    "        list_SNe_file.write(text_line)\n",
    "        list_SNe_file.write('# %s SNe in total in this list. \\n'%(len(list_SNe2)))\n",
    "        list_SNe_file.close()\n",
    "\n",
    "        #--------------------------------------\n",
    "\n",
    "        # Read the list I've just created:\n",
    "\n",
    "        list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_.txt', dtype=['S33', int])\n",
    "        print '# Reading: < ListSNe_AppMag_.txt >'\n",
    "\n",
    "    print '# %s SNe in total in this list.'%len(list_SNe)\n",
    "    print '# %s SNe masked in the list.'%sum(list_SNe['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading: <ListSNe_AppMag_.txt>\n",
    "# Number of SNe in the list = 163\n",
    "# Number of masked SNe in the list:  0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolating the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "\n",
    "    from scipy.interpolate import interp1d # To interpolate\n",
    "\n",
    "    if TempType == 'MWA':\n",
    "        Template = np.genfromtxt(DirTemplate+MWATempTypeFile) \n",
    "        # Index of max abs mag in template. It doesn't need to be very precise; \n",
    "        # it is just to define the plot limit in y-axis\n",
    "        indexMaxTempl = 17 # --> phase = -3.5\n",
    "        indexLowerPhase = index_LowerPhase-1\n",
    "        indexUpperPhase = index_UpperPhase\n",
    "        #-- Interpolating the template\n",
    "        MTemplInt       = interp1d(Template[indexLowerPhase:indexUpperPhase,0] , \n",
    "                                   Template[indexLowerPhase:indexUpperPhase,1] , \n",
    "                                   kind='linear')\n",
    "        error_MTemplInt = interp1d(Template[indexLowerPhase:indexUpperPhase,0] , \n",
    "                                   np.sqrt(Template[indexLowerPhase:indexUpperPhase,3]) , \n",
    "                                   kind='linear')\n",
    "\n",
    "    else:\n",
    "        #OLD. if Use_CovMat_PecVel == True: Template = np.genfromtxt(DirTemplate + \n",
    "        # 'Template_phase_mu_stdError_FromR.dat')\n",
    "        #OLD. else: Template = np.genfromtxt(DirTemplate+'Template_phase_mu_tau_FromR.dat') \n",
    "\n",
    "        if Method==1 or Method==2 or Method==3: TemplateFile = 'Template_phase_mu_stdError_FromR.dat'\n",
    "        elif Method==4 or Method==5 or Method==6: TemplateFile = 'Template_phase_mu_tau_FromR.dat'\n",
    "        elif Method==7: TemplateFile = 'Template_phase_mu_tau_FromR_Norma.dat'\n",
    "\n",
    "        Template = np.genfromtxt(DirTemplate+TemplateFile)\n",
    "\n",
    "        # Index of max abs mag in template. It doesn't need to be very precise, \n",
    "        # it is just to define the plot limit in y-axis.\n",
    "        indexMaxTempl = 64 # --> phase = -3.5\n",
    "\n",
    "        #--- Interpolating the template ---\n",
    "\n",
    "        indexLowerPhase = index_LowerPhase-1\n",
    "        indexUpperPhase = index_UpperPhase\n",
    "\n",
    "\n",
    "        if Method==6: # Normalizing the template\n",
    "            Average_NIRAbsMag_TBmax = Template[(day2index(0)-1),1] # Abs mag at T_Bmax in the template.\n",
    "            # old. Average_NIRAbsMag_TBmax_stdDev = Template[(day2index(0)-1),2] # Population standard deviation of the abs mag at T_Bmax in the template.\n",
    "\n",
    "            MTemplInt       = interp1d(Template[indexLowerPhase:indexUpperPhase,0] , \n",
    "                                       Template[indexLowerPhase:indexUpperPhase,1]-Average_NIRAbsMag_TBmax , kind='linear') \n",
    "\n",
    "            TemplateError = np.genfromtxt(DirTemplate+'Template_phase_mu_stdError_FromR.dat')\n",
    "            error_Average_NIRAbsMag_TBmax = TemplateError[(day2index(0)-1),2] # Uncertainty int the abs mag at T_Bmax in the template.\n",
    "\n",
    "        else:\n",
    "            MTemplInt       = interp1d(Template[indexLowerPhase:indexUpperPhase,0] , \n",
    "                                       Template[indexLowerPhase:indexUpperPhase,1] , kind='linear')\n",
    "\n",
    "        error_MTemplInt = interp1d(Template[indexLowerPhase:indexUpperPhase,0] , \n",
    "                                   Template[indexLowerPhase:indexUpperPhase,2] , kind='linear')\n",
    "\n",
    "    print '# Test (%s). Value of the template at phase = -1.2: (%.6f, %.6f). %s band'%(\n",
    "        TempType, MTemplInt(-1.2), error_MTemplInt(-1.2), BandName)\n",
    "\n",
    "    # OLD. Test (FlatPrior). Value of the template at phase = -1.2:  -0.0739400198048 0.0268277891928 # J band\n",
    "    # Test (FlatPrior). Value of the template at phase = -1.2: (-0.066778, 0.016821). J band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # Checking the range of interpolation\n",
    "    Template[indexLowerPhase:indexUpperPhase,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    # Checking the range of interpolation\n",
    "    print Template[indexLowerPhase][0], Template[indexUpperPhase-1][0]\n",
    "    # -8.0 31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # Checking the interpolation at T_Bmax\n",
    "    print MTemplInt(0)\n",
    "    # 0.0\n",
    "    # -0.000032300235868e-05\n",
    "    # -8.17052766133e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "\n",
    "    if Method==6 or Method==7:\n",
    "        print 'Average_NIRAbsMag_TBmax = ', Average_NIRAbsMag_TBmax\n",
    "        print 'error_Average_NIRAbsMag_TBmax', error_Average_NIRAbsMag_TBmax\n",
    "\n",
    "# J band:\n",
    "# Average_NIRAbsMag_TBmax =  -18.3805198211\n",
    "# error_Average_NIRAbsMag_TBmax 0.0247540912503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mu_{\\rm \\Lambda CDM}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the functions work well: 33.0773926577\n"
     ]
    }
   ],
   "source": [
    "# Inverse of the dimensionless Hubble parameter\n",
    "def InvEHubblePar(z, OmM, wde):\n",
    "    \"Dimensionless Hubble parameter\"\n",
    "    InvEHubbleParInt = 1.0/(np.sqrt(OmM*(1.0+z)**3.0 + (1.0-OmM)*(1.+z)**(3.*(1.+wde))))\n",
    "    return InvEHubbleParInt\n",
    "\n",
    "# ---- The luminosity distance ----\n",
    "def LumDistanceVec(z, OmM, wde, Ho):\n",
    "    \"Luminosity distance\"\n",
    "    LumDistanceVecInt = 0.\n",
    "    LumDistanceVecInt = c*(1.+z)*intquad(InvEHubblePar, 0., z, args=(OmM, wde))[0]/Ho \n",
    "    return LumDistanceVecInt\n",
    "\n",
    "# ---- Distance modulus scalar ----\n",
    "def DistanceMu(z, OmM, wde, Ho):\n",
    "    \"Distance modulus\"     \n",
    "    DistanceMuInt = 5.0*np.log10(LumDistanceVec(z, OmM, wde, Ho)) + 25.0\n",
    "    return DistanceMuInt\n",
    "\n",
    "# ---- Distance modulus Vector ----\n",
    "def DistanceMuVector(z, OmM, wde, Ho):\n",
    "    \"Distance modulus\"     \n",
    "    DistanceMuInt= []\n",
    "    for i in range(len(z)):\n",
    "        DistanceMuInt += [5.0*np.log10(LumDistanceVec(z[i], OmM, wde, Ho)) + 25.0] \n",
    "    return DistanceMuInt\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "ztest1 = 0.01\n",
    "\n",
    "print 'Checking that the functions work well:', DistanceMu(ztest1, OmMFix, wFix, HoFix)\n",
    "# Checking that the functions work well: 33.1141460988 # Ho=72\n",
    "# Checking that the functions work well: 33.0773926577 # Ho=73.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of an array of redshift vs theoretical distance modulus (for Pete Challis)\n",
    "\"\"\" \n",
    "z1 = np.linspace(0.01, 0.7, 501)\n",
    "DistMu_array = DistanceMuVector(z1, OmMFix, wFix, HoFix)\n",
    "\n",
    "DirSaveOutput = '/Users/arturo/Dropbox/Research/Articulos/0_LCDM/'\n",
    "textfile = open(DirSaveOutput+'DistanceModulus.txt', 'w')\n",
    "textfile.write('# Cosmology: flat Universe, Om_matter = %r, Om_Lambda = %r, Ho = %r km/s/Mpc \\n'%(OmMFix, 1-OmMFix, HoFix))\n",
    "textfile.write('# z        Distance modulus  \\n')\n",
    "\n",
    "for i in range(len(z1)):\n",
    "    textfile.write('%.6f   %.6f \\n'%(z1[i], DistMu_array[i]))\n",
    "    \n",
    "textfile.close()\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty in distance modulus due to the peculiar-velocity uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052125037354329877"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigma^2_mu from the peculiar velocity uncertainty\n",
    "# This function is used to determine in the sections \"Intrinsic dispersion\" and \"Optical RMS\", to\n",
    "# determine the intrinsic dispersion.\n",
    "\n",
    "def sigma2_pec(zcmb, err_zcmb, vpec):\n",
    "    sigma2_pecInt = ((5/(zcmb*np.log(10)))*np.sqrt((vpec/c)**2 + err_zcmb**2))**2\n",
    "    return sigma2_pecInt\n",
    "\n",
    "# Test\n",
    "sigma2_pec(0.0109942726, 0.0010420420, 150)\n",
    "# 0.052125037354329877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify string or number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Function to identify if a string is an integer number or a letter.\n",
    "# This will be used in the dictionary construction to properly read some SN names.\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Tests\n",
    "print is_number('5'), is_number('e')\n",
    "# True False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cepheid distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 13 SNe with Cepheid distances in Andy's compilation. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sn1981B', 'sn1998aq', 'sn2001el', 'sn2002fk', 'sn2003du',\n",
       "       'sn2005cf', 'sn2007af', 'sn2007sr', 'sn2009ig', 'sn2011by',\n",
       "       'sn2011fe', 'sn2012cg', 'sn2012fr'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DirSNeWithCepheid = '/Users/arturo/Dropbox/Research/SoftwareResearch/Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "\n",
    "# From the Cepheid SNe list the only part that I use in the entire\n",
    "# notebook is the first column, i.e., the SN Name column.\n",
    "ListSNeCepheid = np.genfromtxt(DirSNeWithCepheid+'SNeWithCepheidDistances.txt', dtype=['S10', \n",
    "                                                float,float,float,float,float,float])\n",
    "\n",
    "print \"# %s SNe with Cepheid distances in Andy's compilation. \"%len(ListSNeCepheid['f0'])\n",
    "ListSNeCepheid['f0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 12 SNe with Cepheid distances in Andy's compilation\n",
    "Out[50]:\n",
    "array(['sn1998aq', 'sn2001el', 'sn2002fk', 'sn2003du', 'sn2005cf',\n",
    "       'sn2007af', 'sn2007sr', 'sn2009ig', 'sn2010ai', 'sn2011by',\n",
    "       'sn2011fe', 'sn2012cg'], \n",
    "      dtype='|S10')\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to determine $c z_{\\rm cmb}$ from Cepheid $\\mu$\n",
    "\n",
    "These functions are NOT used during any part of the computations in the notebook; I have written here just as part of my library of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sn2003du (data from Riess+16):\n",
      "# (0.009369742003029419, 0.00035135265754374572, 2808.977985914033, 105.33287682987176)\n",
      "\n",
      "# sn2005cf (data from Riess+16):\n",
      "# (0.006926720004322207, 0.00036461514433908711, 2076.578415973525, 109.3088703454397)\n"
     ]
    }
   ],
   "source": [
    "def cz_CMB_Cepheid(mu, err_mu, Ho, err_Ho):\n",
    "    \n",
    "    # Determine cz_cmb, z_cmb:\n",
    "    cz_int =  Ho * 10**((mu-25)/5)  # cz_cmb\n",
    "    zcmb_int = cz_int/c  # z_cmb\n",
    "    \n",
    "    # Determine error_cz_cmb, error_z_cmb:\n",
    "    error_cz_int = cz_int * np.sqrt((err_Ho/Ho)**2 + (np.log(10)*err_mu/5)**2) # error_cz_cmb\n",
    "    error_zcmb_int = error_cz_int/c  # error_z_cmb\n",
    "    \n",
    "    # (z_cmb, error_z_cmb, cz_cmb, error_cz_cmb)\n",
    "    return zcmb_int, error_zcmb_int, cz_int, error_cz_int\n",
    "\n",
    "    \n",
    "# TEST:\n",
    "print '# sn2003du (data from Riess+16):'\n",
    "print '#',cz_CMB_Cepheid(32.919, 0.063, 73.24, 1.74)\n",
    "\n",
    "print ''\n",
    "print '# sn2005cf (data from Riess+16):'\n",
    "print '#',cz_CMB_Cepheid(32.263, 0.102, 73.24, 1.74)\n",
    "\n",
    "# sn2003du (data from Riess+16):\n",
    "# (0.009369742003029419, 0.00035135265754374572, 2808.977985914033, 105.33287682987176)\n",
    "\n",
    "# sn2005cf (data from Riess+16):\n",
    "# (0.006926720004322207, 0.00036461514433908711, 2076.578415973525, 109.3088703454397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    HoNew = 72.0; err_HoNew = 1.74\n",
    "\n",
    "    # err_HoNew = 1.74 comes from assuming the same uncertainty than the \n",
    "    # case of  Ho=73.24 +/- 1.74 km/s/Mpc  (Riess+2016).\n",
    "\n",
    "    print '# sn2003du (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(32.919, 0.063, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2005cf (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(32.263, 0.102, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2002fk (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(32.523, 0.055, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2001el (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(31.311, 0.045, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2007sr (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(31.290, 0.112, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2007af (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(31.786, 0.046, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2009ig (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(32.497, 0.081, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# sn2011by (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(31.587, 0.070, HoNew, err_HoNew)\n",
    "\n",
    "    print ''\n",
    "    print '# 2011fe (data from Riess+16):'\n",
    "    print '#',cz_CMB_Cepheid(29.135, 0.045, HoNew, err_HoNew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sn2003du (data from Riess+16):\n",
    "# (0.009211106283699049, 0.00034780399672242258, 2761.420193689383, 104.269015079639)\n",
    "\n",
    "# sn2005cf (data from Riess+16):\n",
    "# (0.006809446208508997, 0.00035970803370978462, 2041.4206164676925, 107.83775558820318)\n",
    "\n",
    "# sn2002fk (data from Riess+16):\n",
    "# (0.007675590444195331, 0.00026870678361360224, 2301.08412586663, 80.556267140795939)\n",
    "\n",
    "# sn2001el (data from Riess+16):\n",
    "# (0.004392500236022846, 0.00013983623152753925, 1316.838442522869, 41.921847567098084)\n",
    "\n",
    "# sn2007sr (data from Riess+16):\n",
    "# (0.00435022573745372, 0.00024778376284622327, 1304.164866686113, 74.283703316158338)\n",
    "\n",
    "# sn2007af (data from Riess+16):\n",
    "# (0.005466530725939691, 0.00017567735913141312, 1638.8246830619842, 52.666747308955081)\n",
    "\n",
    "# sn2009ig (data from Riess+16):\n",
    "# (0.007584235213199466, 0.00033708985696221771, 2273.6965166152218, 101.05699678557166)\n",
    "\n",
    "# sn2011by (data from Riess+16):\n",
    "# (0.004987831728307585, 0.00020095452262929847, 1495.314333919719, 60.244650285254004)\n",
    "\n",
    "# 2011fe (data from Riess+16):\n",
    "# (0.0016125448162764855, 5.1335726388381935e-05, 483.428774106686, 15.390063597188481)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: I can skip these cells if I want to compute the optimal phase range only.\n",
    "\n",
    "### Preeliminary writting of  text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "\n",
    "    # Creation of the datatable text file of (z_CMB, dist_mu, dist_mu_error, delta_mu) \n",
    "\n",
    "    InfoSN_NumLinesSkip = 8 # Number info lines in LC files\n",
    "\n",
    "    # Mean Absolute magnitude determined from histogram of 'appMagTmax_s - mu_s'?:\n",
    "    # If so it is generated the final 'DistanceMu_Good_AfterCutoffs_Main_.txt' text file, otherwise\n",
    "    # generate temporal text files.\n",
    "    if  AbsMagFromHisto == True: textPrefix = ''; underline = ''\n",
    "    else: textPrefix = 'TMP'; underline = '_' # 'TMP' stands for 'temporal' file.\n",
    "\n",
    "    textfileMain = open(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_%s%s.txt'%(textPrefix, underline), 'w')\n",
    "    textfile = open(DirSaveOutput+textPrefix+underline+'DistanceMu_All_BeforeCutoffs_.txt', 'w')\n",
    "    textfil3 = open(DirSaveOutput+textPrefix+underline+'DistanceMu_Good_AfterCutoffs_z001_.txt', 'w')\n",
    "    textfil4 = open(DirSaveOutput+textPrefix+underline+'RMS_tmp.txt', 'w')\n",
    "    textfil5 = open(DirSaveOutput+textPrefix+underline+'DistanceMu_SNe_OutCutoffs_.txt', 'w')\n",
    "    textfil6 = open(DirSaveOutput+textPrefix+underline+'DistanceMu_Good_AfterCutoffs_Main_NamesOnly_.txt', 'w')\n",
    "\n",
    "    #------------------------------------------------------------------------------------\n",
    "\n",
    "    #       Defining the text\n",
    "\n",
    "    text_001 = '#    %s band  (template method) \\n'%BandName\n",
    "    text01b = '# MAIN DATA TABLE. Used to make further computations and plots \\n'\n",
    "\n",
    "    now = datetime.datetime.now() # Read the time and date right now\n",
    "    text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd)\")\n",
    "    text_Date   = '# On date: %s \\n'%text_timenow\n",
    "    text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "    text_script = '# Script used: %s \\n'%NotebookName\n",
    "    text_line = '#'+'-'*70 + '\\n'\n",
    "\n",
    "    text02 = '# This datatable is for information only. It is NOT used to compute or plot something else. \\n'\n",
    "\n",
    "    text01 = '# Apparent mag data used to construct the Hubble diagram: %s \\n'%KindOfData4HD\n",
    "    text1 = '# Template used: \\n'\n",
    "    text2 = '# %s \\n'%DirTemplate[78:]\n",
    "    text3 = '# Cosmology used to compute residuals: (Omega_M=%r, Omega_L=%r, w=%r, Ho=%r) \\n'%(OmMFix, OmLFix, wFix, HoFix)\n",
    "\n",
    "    text3_0_0 = '# 0.01 < z_cmb < %r \\n'%zcmbUpperLim\n",
    "    text3_0_1 = '# Cutoffs: z_cmb<%r | %r<dm15<%r | %r<EBVhost<%r | EBV_mw<%r | chi2_dof<%r | Residual<%r \\n'%(zcmbUpperLim,\n",
    "        dm15LowerLim,  dm15UpperLim, EBVhostMin, EBVhostMax, EBVMWLim, chi2_dof_Max, residualMax)\n",
    "    text3_3 = '# Phase range used of the template: (%r, %r) days \\n'%(PhaseMinTemp, PhaseMaxTemp)\n",
    "    text3_4 = '# Minimal number of data in LC to be considered for the Hubble diagram: %r \\n'%MinNumOfDataInLC\n",
    "    text3_5 = '# Assumed uncertainty in the peculiar velocity: %r km/s \\n'%vpecFix\n",
    "    text4 = '# SN name                        z_CMB         error_zcmb        mu          error_mu       mu_residual    chi2_dof     (1=CfA,2=CSP)   appMag_TBmax  error_appMagTBmax  mu_LCDM  sigma_muLCDM_vPec AbsMagTBmax error_AbsMagTBmax  TBmax       Error_TBmax  PhaseB zhelio        err_zhelio   dm15         error_dm15      EBVhost      error_EBVhost   EBV_MW   error_EBV_MW  Alamb       err_Alamb      R_F          mu_Snoopy     error_muSnoopy   TBmax      Error_TBmax  appMag_TBmax  error_appMagTBmax  Notes   \\n' \n",
    "\n",
    "    # text4 = '# SN name                        z_CMB     error_zcmb        mu          error_mu      \\\n",
    "    # mu_residual     chi2_dof   (1=CfA,2=CSP)   appMag_TBmax   error_appMagTBmax   mu_LCDM   sigma_muLCDM_vPec  \n",
    "    # dm15       error_dm15        EBVhost    error_EBVhost      \\\n",
    "    # EBV_MW     error_EBV_MW   mu_Snoopy   error_mu_Snoopy    TBmax     Error_TBmax    Notes \\n' \n",
    "\n",
    "    #------------------------------------------------------------------ \n",
    "\n",
    "    textMethod = '# Method to determine the distance modulus?: %s \\n'%Method \n",
    "    text_CorrMatrix = '# Use the correlation (exponential kernel) matrix in the template to compute the distance moduli?: (answer in the lines below) \\n'\n",
    "    text_CovMat_MeanMu  = '# CovMat_MeanMu = %s  # correlation matrix to compute the -mean-  distance moduli? \\n'%CovMat_MeanMu\n",
    "    text_CovMat_ErrorMu = '# CovMat_ErrorMu = %s # correlation matrix to compute the -error- distance moduli? \\n'%CovMat_ErrorMu\n",
    "    text_lkernel = '# l_kernel = %r. Lenght scale of the kernel in the covariance matrix for the residual. \\n'%(l_kern)\n",
    "    text_Template = \"# Template = %s \\n\"%TemplateFile\n",
    "    text_CovMatrix_MeanMu_1  = '# Total CovMat to compute Mean_mu:  CovMatrix_MeanMu = CovMatCorrData_4MeanMu  + Cov_appmag \\n'\n",
    "    text_CovMatrix_MeanMu_2  = '# Total CovMat to compute Mean_mu:  CovMatrix_MeanMu = CovMatCorrData_4MeanMu  + Cov_appmag + Cov_pecvel \\n'\n",
    "    text_CovMatrix_ErrorMu_1 = '# Total CovMat to compute Error_mu: CovMatrix_ErrorMu= CovMatCorrData_4ErrorMu + Cov_appmag + Cov_pecvel \\n'\n",
    "    text_CovMatrix_ErrorMu_2 = '# Total CovMat to compute Error_mu: CovMatrix_ErrorMu= CovMatCorrData_4ErrorMu + Cov_appmag \\n'\n",
    "    text_sigma2mu_1 = '# Variance mu: sigma2_mu = (1/Denominator_ErrorMu) \\n'\n",
    "    text_sigma2mu_2 = '# Variance mu: sigma2_mu = (1/Denominator_ErrorMu) +  sigma2_pec(zcmbInt, err_zcmb, vpecFix) \\n'\n",
    "    # text_IntrinsicDisp_1 = '# Intrinsic dispersion for the case (0 < z < %s) and used to obtain the total photometric \\\n",
    "    # distance modulus uncertainty:\\n'%zcmbUpperLim\n",
    "    # text_IntrinsicDisp_2 = '# Intrinsic dispersion = %s \\n'%IntrinsicDisp\n",
    "\n",
    "    #=====================================================================================\n",
    "\n",
    "    #       Writting the text\n",
    "\n",
    "    # 'DistanceMu_Good_AfterCutoffs_Main_.txt'\n",
    "\n",
    "    textfileMain.write(text_001); textfileMain.write(text01b)\n",
    "\n",
    "    textfileMain.write(text_line); \n",
    "    textfileMain.write(text_Author); textfileMain.write(text_Date); textfileMain.write(text_script);\n",
    "    textfileMain.write(text_line); \n",
    "\n",
    "    textfileMain.write(text01); textfileMain.write(text1); textfileMain.write(text2); textfileMain.write(text3)\n",
    "    textfileMain.write(text3_0_1)\n",
    "    textfileMain.write(text3_3); textfileMain.write(text3_4); textfileMain.write(text3_5);\n",
    "    # if CovMat_MeanMu == True: textfileMain.write(text_lkernel)\n",
    "    textfileMain.write(text_line); \n",
    "    textfileMain.write(textMethod); \n",
    "    textfileMain.write(text_CorrMatrix); \n",
    "    textfileMain.write(text_CovMat_MeanMu); textfileMain.write(text_CovMat_ErrorMu); textfileMain.write(text_lkernel)\n",
    "    textfileMain.write(text_Template)\n",
    "    if Method==1:\n",
    "        textfileMain.write(text_CovMatrix_MeanMu_1); textfileMain.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfileMain.write(text_sigma2mu_1); \n",
    "    elif  Method==2:\n",
    "        textfileMain.write(text_CovMatrix_MeanMu_1); textfileMain.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfileMain.write(text_sigma2mu_2); \n",
    "    elif  Method==3:\n",
    "        textfileMain.write(text_CovMatrix_MeanMu_2); textfileMain.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfileMain.write(text_sigma2mu_1); \n",
    "    elif Method==4:\n",
    "        textfileMain.write(text_CovMatrix_MeanMu_1); textfileMain.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfileMain.write(text_sigma2mu_1);\n",
    "    elif Method==5 or Method==6:\n",
    "        textfileMain.write(text_CovMatrix_MeanMu_1); textfileMain.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfileMain.write(text_sigma2mu_1); \n",
    "    elif Method==7:\n",
    "        textfileMain.write('#       Distance modulus determination: \\n')\n",
    "        textfileMain.write('# CovMatrix_MeanMu = CovMatCorrData_4MeanMu + Cov_appmag \\n')\n",
    "        textfileMain.write('# appMag_TBmax = Numerator_MeanMu/Denominator_MeanMu \\n')\n",
    "        textfileMain.write('# mu_photo_Analytic = appMag_TBmax - <Average_NIRAbsMag_TBmax> \\n')\n",
    "        textfileMain.write('#       Uncertainty in the distance modulus determination: \\n')\n",
    "        textfileMain.write('# CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag \\n')\n",
    "        textfileMain.write('# error_appMag_TBmax = np.sqrt(1/Denominator_ErrorMu)  \\n')\n",
    "        textfileMain.write('# sigma2_mu = (1/Denominator_ErrorMu) \\n')\n",
    "    if Method==6 or Method==7: \n",
    "        textfileMain.write('# Using a NORMALIZED template. Distance mu = m_TBmax - M_TBmax. \\n')\n",
    "        textfileMain.write('#       Assumed values for Average_NIRAbsMag_TBmax and error_Average_NIRAbsMag_TBmax: \\n')\n",
    "        textfileMain.write('# <Average_NIRAbsMag_TBmax> = %r. %s \\n'%(Average_NIRAbsMag_TBmax, Notes1))\n",
    "        textfileMain.write('# error_<Average_NIRAbsMag_TBmax> = %r. %s \\n'%(error_Average_NIRAbsMag_TBmax, Notes1))\n",
    "        # textfileMain.write(text_IntrinsicDisp_1); textfileMain.write(text_IntrinsicDisp_2);\n",
    "\n",
    "    textfileMain.write(text_line); \n",
    "    textfileMain.write(text4)\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    # 'DistanceMu_Good_AfterCutoffs_Main_NamesOnly_.txt'\n",
    "\n",
    "    textfil6.write('# SN name \\n')\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    # 'DistanceMu_All_BeforeCutoffs_.txt'\n",
    "\n",
    "    textfile.write(text_001); textfile.write(text02)\n",
    "    textfile.write(text_line); \n",
    "    textfile.write(text_Author); textfile.write(text_Date); textfile.write(text_script);\n",
    "    textfile.write(text_line); \n",
    "    textfile.write(text01); textfile.write(text1); textfile.write(text2); textfile.write(text3)\n",
    "    textfile.write('# No restrictions on z_cmb, dm15, EBVhost, EBV_mw, chi2_dof, residuals \\n')\n",
    "    textfile.write(text3_3); textfile.write(text3_4); textfile.write(text3_5)\n",
    "    # if CovMat_MeanMu == True: textfile.write(text_lkernel)\n",
    "    textfile.write(text_line); \n",
    "    textfile.write(textMethod)\n",
    "    textfile.write(text_CorrMatrix); \n",
    "    textfile.write(text_CovMat_MeanMu); textfile.write(text_CovMat_ErrorMu); textfile.write(text_lkernel)\n",
    "    textfile.write(text_Template)\n",
    "    if Method==1:\n",
    "        textfile.write(text_CovMatrix_MeanMu_1); textfile.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfile.write(text_sigma2mu_1); \n",
    "    elif  Method==2:\n",
    "        textfile.write(text_CovMatrix_MeanMu_1); textfile.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfile.write(text_sigma2mu_2); \n",
    "    elif  Method==3:\n",
    "        textfile.write(text_CovMatrix_MeanMu_2); textfile.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfile.write(text_sigma2mu_1); \n",
    "    elif Method==4:\n",
    "        textfile.write(text_CovMatrix_MeanMu_1); textfile.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfile.write(text_sigma2mu_1);\n",
    "    elif Method==5 or Method==6:\n",
    "        textfile.write(text_CovMatrix_MeanMu_1); textfile.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfile.write(text_sigma2mu_1); \n",
    "    elif Method==7:\n",
    "        textfile.write('#       Distance modulus determination: \\n')\n",
    "        textfile.write('# CovMatrix_MeanMu = CovMatCorrData_4MeanMu + Cov_appmag \\n')\n",
    "        textfile.write('# appMag_TBmax = Numerator_MeanMu/Denominator_MeanMu \\n')\n",
    "        textfile.write('# mu_photo_Analytic = appMag_TBmax - <Average_NIRAbsMag_TBmax> \\n')\n",
    "        textfile.write('#       Uncertainty in the distance modulus determination: \\n')\n",
    "        textfile.write('# CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag \\n')\n",
    "        textfile.write('# error_appMag_TBmax = np.sqrt(1/Denominator_ErrorMu)  \\n')\n",
    "        textfile.write('# sigma2_mu = (1/Denominator_ErrorMu) \\n')\n",
    "    if Method==6 or Method==7: \n",
    "        textfile.write('# Using a NORMALIZED template. Distance mu = m_TBmax - M_TBmax. \\n')\n",
    "        textfile.write('#       Assumed values for Average_NIRAbsMag_TBmax and error_Average_NIRAbsMag_TBmax: \\n')\n",
    "        textfile.write('# <Average_NIRAbsMag_TBmax> = %r. %s \\n'%(Average_NIRAbsMag_TBmax, Notes1))\n",
    "        textfile.write('# error_<Average_NIRAbsMag_TBmax> = %r. %s \\n'%(error_Average_NIRAbsMag_TBmax, Notes1))\n",
    "        # textfile.write(text_IntrinsicDisp_1); textfile.write(text_IntrinsicDisp_2);\n",
    "\n",
    "    textfile.write(text_line); \n",
    "    textfile.write(text4)\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    textfil3.write(text02); textfil3.write(text01); textfil3.write(text1); textfil3.write(text2) \n",
    "    textfil3.write(text3)\n",
    "    textfil3.write(text3_0_0); textfil3.write(text3_0_1)\n",
    "    textfil3.write(text3_3); textfil3.write(text3_4); textfil3.write(text3_5)\n",
    "    # if CovMat_MeanMu == True: textfil3.write(text_lkernel)\n",
    "    textfil3.write(text_line); \n",
    "    textfil3.write(textMethod); \n",
    "    textfil3.write(text_CorrMatrix); \n",
    "    textfil3.write(text_CovMat_MeanMu); textfil3.write(text_CovMat_ErrorMu); textfil3.write(text_lkernel)\n",
    "    textfil3.write(text_Template)\n",
    "    if Method==1:\n",
    "        textfil3.write(text_CovMatrix_MeanMu_1); textfil3.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfil3.write(text_sigma2mu_1); \n",
    "    elif  Method==2:\n",
    "        textfil3.write(text_CovMatrix_MeanMu_1); textfil3.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfil3.write(text_sigma2mu_2); \n",
    "    elif  Method==3:\n",
    "        textfil3.write(text_CovMatrix_MeanMu_2); textfil3.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfil3.write(text_sigma2mu_1); \n",
    "    elif Method==4:\n",
    "        textfil3.write(text_CovMatrix_MeanMu_1); textfil3.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfil3.write(text_sigma2mu_1); \n",
    "    textfil3.write(text_line); \n",
    "    textfil3.write(text4)\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    textfil4.write(text_line), textfil4.write('# <- Template range -> \\n')\n",
    "    textfil4.write('# Phase_min  Phase_max   RMS    # SNe   RMS(z>0.01)  # SNe  \\n')\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    textfil5.write('# SNe that are OUTSIDE the following cutoffs-criteria: \\n')  \n",
    "    textfil5.write(text3_0_0); textfil5.write(text3_0_1)\n",
    "    textfil5.write(text02); textfil5.write(text01); textfil5.write(text1); textfil5.write(text2)\n",
    "    textfil5.write(text3); \n",
    "    textfil5.write(text3_3); textfil5.write(text3_4); textfil5.write(text3_5)\n",
    "    # if CovMat_MeanMu == True: textfil5.write(text_lkernel)\n",
    "    textfil5.write(text_line); \n",
    "    textfil5.write(textMethod)\n",
    "    textfil5.write(text_CorrMatrix); \n",
    "    textfil5.write(text_CovMat_MeanMu); textfil5.write(text_CovMat_ErrorMu); textfil5.write(text_lkernel)\n",
    "    textfil5.write(text_Template)\n",
    "    if Method==1:\n",
    "        textfil5.write(text_CovMatrix_MeanMu_1); textfil5.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfil5.write(text_sigma2mu_1); \n",
    "    elif  Method==2:\n",
    "        textfil5.write(text_CovMatrix_MeanMu_1); textfil5.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfil5.write(text_sigma2mu_2); \n",
    "    elif  Method==3:\n",
    "        textfil5.write(text_CovMatrix_MeanMu_2); textfil5.write(text_CovMatrix_ErrorMu_1); \n",
    "        textfil5.write(text_sigma2mu_1); \n",
    "    elif Method==4:\n",
    "        textfil5.write(text_CovMatrix_MeanMu_1); textfil5.write(text_CovMatrix_ErrorMu_2); \n",
    "        textfil5.write(text_sigma2mu_1); \n",
    "    textfil5.write(text_line); \n",
    "    textfil5.write(text4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "textfile.close()\n",
    "textfileMain.close()\n",
    "textfil3.close()\n",
    "textfil4.close()\n",
    "textfil5.close()\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop\n",
    "\n",
    "### Moving the template up or down to match the LC data. The amount of moving up or down corresponds to the photometric distance modulus.\n",
    "\n",
    "####  In this loop it is used ALL the apparent mag LCs located in \"~/1_AllData_InitialFit/AppMag/\" through the text file \"ListSNe_AppMag_.txt\" created and read above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # Initializing some quantities\n",
    "    countGoodSNe = 0; countGoodSNe_z001 = 0; # Counters\n",
    "    countCfA = 0;     countCSP = 0;     countOthers=0;  countSNe = 0 # Counters\n",
    "    countCfA_z001= 0; countCSP_z001= 0; countOthers_z001=0 # Counters\n",
    "    countNoCommented = 0; countCommented = 0;\n",
    "    countBadSNe = 0; \n",
    "\n",
    "    # To be used to compute the RMS:\n",
    "    mu_resid_array = []; mu_resid_z001_array = []; \n",
    "    chi2_list = []; chi2_z001_list = []; \n",
    "    SNeName_list = []; SNeName_z001_list = []; \n",
    "\n",
    "    # The phase range of the template to be used to determine the distance modulus\n",
    "    lowerPhase = Template[indexLowerPhase][0]\n",
    "    upperPhase = Template[indexUpperPhase-1][0]\n",
    "\n",
    "    ############ THE LOOP ############################\n",
    "\n",
    "    for j in range(len(list_SNe)): # loop over the SNe\n",
    "    # for j in range(7):\n",
    "    # for j in range(10):\n",
    "    # for j in range(20, 40):\n",
    "\n",
    "        # Upload the apparent magnitude data for a given SN\n",
    "        magData = np.genfromtxt(DirAppMag+list_SNe[j][0])\n",
    "        name = list_SNe[j][0]\n",
    "        mask = list_SNe[j][1]\n",
    "\n",
    "        zcmbInt = magData[0,0]\n",
    "        dm15Int = magData[1,0]\n",
    "        EBV_MW = magData[3,0]\n",
    "        EBVhost = magData[4,0]\n",
    "\n",
    "        err_zcmb = magData[0,1]\n",
    "        err_dm15 = magData[1,1]\n",
    "        err_EBVMW = magData[3,1]\n",
    "        err_EBVhost = magData[4,1]\n",
    "\n",
    "\n",
    "\n",
    "        # These quantities are not used to compute anything, they are just to be\n",
    "        # written int the output file\n",
    "        muSnoopy     = magData[2,0]\n",
    "        err_muSnoopy = magData[2,1]\n",
    "        TBmax      = magData[5,0]\n",
    "        err_TBmax  = magData[5,1]\n",
    "        zhelio     = magData[0,2]\n",
    "        err_zhelio = magData[0,3]\n",
    "        Alamb      = magData[3,2] \n",
    "        err_Alamb  = magData[3,3] \n",
    "        R_F        = magData[3,4]\n",
    "\n",
    "        #-------- Peculiar velocity uncertainty -----------------        \n",
    "        # Create the variable \"snName\" containing the first 8 (or 7) letters of the SNe file name\n",
    "        # I use \"snName\" to compare with the SNe names in 'SNeWithCepheidDistances.txt', so that\n",
    "        # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "        try:\n",
    "            if   name[7] == '_': snName = name[:7] # To read correctly, e.g., \"sn2011B_\"\n",
    "            elif name[7] != '_':\n",
    "                if is_number(name[7]): snName = name[:15] # To read correctly, e.g., \"snf20080514-002\"\n",
    "                else: snName = name[:8]  # To read correctly, e.g., \"sn1998bu\" \n",
    "        except: snName = name[:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "\n",
    "        sigma_pecInt = 0 # Reset its value:\n",
    "        # If this SNe has Cepheid distance, then use vpecFix=0 for it: \n",
    "        if snName in ListSNeCepheid['f0']: sigma_pecInt = np.sqrt(sigma2_pec(zcmbInt, err_zcmb, 0))\n",
    "        else: sigma_pecInt = np.sqrt(sigma2_pec(zcmbInt, err_zcmb, vpecFix))\n",
    "\n",
    "        #---------------------------\n",
    "        # If there are at least 3 photometric points in the app mag LC text file, then compute. \n",
    "        if len(magData) >= InfoSN_NumLinesSkip + MinNumOfDataInLC:\n",
    "\n",
    "            #---------------------------\n",
    "            # Find out if there are at least one datum inside the interpolated phase range of the template\n",
    "            NumDataInRange = 0\n",
    "            for i in range(InfoSN_NumLinesSkip, len(magData)): # Loop over all the phases for a given SNe\n",
    "                if magData[i,0] >= lowerPhase and magData[i,0] <= upperPhase:\n",
    "                    NumDataInRange = NumDataInRange + 1\n",
    "\n",
    "            #---------------------------\n",
    "            # Fit the LCs with at least one data point within the phase range defined for the template.\n",
    "            if NumDataInRange > 0:\n",
    "\n",
    "                # Analytical minimization of chi2 to find the best estimate for distance modulus\n",
    "                # and computing the uncertainty of distance modulus (analytic expression)\n",
    "\n",
    "                # Resetting some quantities\n",
    "                Numerator_MeanMu  = 0; Denominator_MeanMu= 0\n",
    "                Numerator_ErrorMu = 0; Denominator_ErrorMu= 0\n",
    "                mu_photo_Analytic=0; sigma2_mu=0; stdDev_mu=0\n",
    "                appMag_TBmax=0; error_appMag_TBmax=0;\n",
    "                AbsMag_s=0; error_AbsMag_s=0;\n",
    "                mu_LCDM=0;\n",
    "\n",
    "                CovMatrix_MeanMu = 0; InvCovMatrix_MeanMu = 0;\n",
    "                CovMatrix_ErrorMu = 0; InvCovMatrix_ErrorMu =0;\n",
    "                OffsetToMatchAppMagData = 0; appMag_TBmax = 0;\n",
    "\n",
    "                #---------------------------    \n",
    "                # Using the covariance matrix of the photometry to determine the distance modulus:\n",
    "\n",
    "                # Create arrays for the data that is inside the interpolation \n",
    "                # range & within the range (lowerPhase, upperPhase).\n",
    "                mag_array = [] # apparent magnitude data\n",
    "                MagTemp_array = [] # template mean value (absolute magnitude)\n",
    "                error2_appmag = [] # app magnitud errors\n",
    "                error_temp = [] # population standard deviation of the template at different phases.\n",
    "                phases = [] # phases inside the interpolation range & within the range (lowerPhase, upperPhase).\n",
    "                phaseInt = 0\n",
    "                countGoodPhases = 0; countLowerPhase = 0; \n",
    "\n",
    "                for i in range(InfoSN_NumLinesSkip, len(magData)): # Loop over all the photometry for a given SNe\n",
    "                    if magData[i,0] >= lowerPhase: # Ignore data outside the phase interpolation range:\n",
    "                        if magData[i,0] <= upperPhase:\n",
    "                            phaseInt = magData[i,0]\n",
    "                            mag_array += [magData[i,3]]\n",
    "                            error2_appmag += [magData[i,4]**2]\n",
    "                            MagTemp_array += [MTemplInt(phaseInt)]\n",
    "                            error_temp += [error_MTemplInt(phaseInt)]\n",
    "                            phases += [phaseInt]\n",
    "                            countGoodPhases = countGoodPhases + 1\n",
    "                    else: countLowerPhase = countLowerPhase + 1\n",
    "\n",
    "                error_temp = np.array(error_temp)\n",
    "\n",
    "\n",
    "                #-------- Some covariance matrices --------\n",
    "\n",
    "                # Diagonal variance matrix of the photometric data.\n",
    "                Cov_appmag = np.diag(error2_appmag)\n",
    "\n",
    "                # Square covariance matrix of the peculiar velocity uncertainty\n",
    "                Cov_pecvel = np.ones((countGoodPhases,countGoodPhases))*(sigma_pecInt**2)\n",
    "\n",
    "\n",
    "                #--------- MEAN photometric distance modulus -------------\n",
    "\n",
    "                # Covariance matrix of the light-curve photometric data:\n",
    "                CovMatCorrData_4MeanMu = np.zeros(shape=(countGoodPhases,countGoodPhases)) # Empty array\n",
    "                for i in range(countGoodPhases):\n",
    "                    if CovMat_MeanMu == True:\n",
    "                        for k in range(countGoodPhases):\n",
    "                            CovMatCorrData_4MeanMu[i,k] = error_temp[i]*error_temp[k]*np.exp( -(((phases[i] - phases[k])/l_kern)**2)/2 ) \n",
    "                    elif CovMat_MeanMu == False:\n",
    "                        CovMatCorrData_4MeanMu[i,i] = error_temp[i]*error_temp[i]\n",
    "\n",
    "                # Total covariance matrix\n",
    "                if Method==1 or Method==2 or Method==4 or Method==5 or Method==6 or Method==7: \n",
    "                    CovMatrix_MeanMu = CovMatCorrData_4MeanMu + Cov_appmag\n",
    "                elif Method==3: CovMatrix_MeanMu = CovMatCorrData_4MeanMu + Cov_appmag + Cov_pecvel\n",
    "\n",
    "                # Inverse of the total covariance matrix\n",
    "                InvCovMatrix_MeanMu = np.linalg.inv(CovMatrix_MeanMu)\n",
    "\n",
    "                #---Computing the best estimated photometric distance modulus ---\n",
    "                # Loop over all the photometry for a given SNe\n",
    "                # Ignore data outside the interpolation range (lowerPhase, upperPhase):\n",
    "                for i in range(countGoodPhases): \n",
    "                    # Ignore data outside the interpolation range:\n",
    "                    Numerator_MeanMu = Numerator_MeanMu + (mag_array[i] - MagTemp_array[i])*np.sum(InvCovMatrix_MeanMu[i,:])\n",
    "                    Denominator_MeanMu = Denominator_MeanMu + np.sum(InvCovMatrix_MeanMu[i,:])\n",
    "\n",
    "                # Best estimated distance modulus:\n",
    "                if Method==6 or Method==7: \n",
    "                    appMag_TBmax = Numerator_MeanMu/Denominator_MeanMu\n",
    "                    mu_photo_Analytic = appMag_TBmax - Average_NIRAbsMag_TBmax\n",
    "\n",
    "                else: \n",
    "                    appMag_TBmax = 0\n",
    "                    mu_photo_Analytic = Numerator_MeanMu/Denominator_MeanMu   \n",
    "\n",
    "                #--------- UNCERTAINTY in the photometric distance modulus -------------\n",
    "\n",
    "                # Covariance matrix of the light-curve photometric data to compute ERROR_MU\n",
    "                CovMatCorrData_4ErrorMu = np.zeros(shape=(countGoodPhases,countGoodPhases)) # Empty array\n",
    "                for i in range(countGoodPhases):\n",
    "                    if CovMat_ErrorMu == True:\n",
    "                        for k in range(countGoodPhases):\n",
    "                            CovMatCorrData_4ErrorMu[i,k] = error_temp[i]*error_temp[k]*np.exp( -(((phases[i] - phases[k])/l_kern)**2)/2 ) \n",
    "                    elif CovMat_ErrorMu == False:\n",
    "                        CovMatCorrData_4ErrorMu[i,i] = error_temp[i]*error_temp[i]            \n",
    "\n",
    "                # Total covariance matrix\n",
    "                if Method==1 or Method==3 or Method==5 : \n",
    "                    CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag + Cov_pecvel\n",
    "                elif Method==2 or Method==4 or Method==6 or Method==7: \n",
    "                    CovMatrix_ErrorMu = CovMatCorrData_4ErrorMu + Cov_appmag                   \n",
    "\n",
    "                # Inverse of the total covariance matrix\n",
    "                InvCovMatrix_ErrorMu = np.linalg.inv(CovMatrix_ErrorMu)            \n",
    "\n",
    "                #--- Uncertainty of the best estimated distance modulus---\n",
    "                # Loop over all the photometry for a given SNe\n",
    "                # Ignore data outside the interpolation range (lowerPhase, upperPhase):\n",
    "                for i in range(countGoodPhases): \n",
    "                    # Ignore data outside the interpolation range:\n",
    "                    Numerator_ErrorMu = Numerator_ErrorMu + (mag_array[i] - MagTemp_array[i])*np.sum(InvCovMatrix_ErrorMu[i,:])\n",
    "                    Denominator_ErrorMu = Denominator_ErrorMu + np.sum(InvCovMatrix_ErrorMu[i,:])            \n",
    "\n",
    "                if Method==7: # uncertainty in the estimated apparent magnitude at T_Bmax\n",
    "                    error_appMag_TBmax = np.sqrt(1/Denominator_ErrorMu)\n",
    "                else: error_appMag_TBmax = 0\n",
    "\n",
    "\n",
    "                # Uncertainty in the estimated distance modulus\n",
    "                if Method==1 or Method==3 or Method==4 or Method==5 or Method==6: \n",
    "                    sigma2_mu = (1/Denominator_ErrorMu)\n",
    "                elif Method==2: \n",
    "                    sigma2_mu = (1/Denominator_ErrorMu) +  (sigma_pecInt**2)\n",
    "\n",
    "                elif Method==7: \n",
    "                    # old1. sigma2_mu = (1/Denominator_ErrorMu) + error_Average_NIRAbsMag_TBmax**2\n",
    "                    # old2. sigma2_mu = (1/Denominator_ErrorMu) + IntrinsicDisp**2\n",
    "                    sigma2_mu = 1/Denominator_ErrorMu\n",
    "\n",
    "                stdDev_mu = np.sqrt(sigma2_mu)               \n",
    "\n",
    "                #------------------------------------------------------\n",
    "                # The chi2 function: I define it just to compute the goodness-of-fit to data once \n",
    "                # I have computed the best estimated photometric distance modulus.\n",
    "                # Note that the following definition need the value of \"mu_photo_Analytic\" computed above.\n",
    "                chi2Int=0; mu_int=0;\n",
    "\n",
    "                if Method==6 or Method==7: mu_int = appMag_TBmax\n",
    "                else: mu_int = mu_photo_Analytic\n",
    "\n",
    "                for i in range(countGoodPhases):\n",
    "                    product1=0;\n",
    "                    for k in range(countGoodPhases): \n",
    "                        product1 = product1 + InvCovMatrix_MeanMu[i,k]*(mag_array[k] - MagTemp_array[k] - mu_int)\n",
    "                    chi2Int = chi2Int + (mag_array[i] - MagTemp_array[i] - mu_int)*product1\n",
    "\n",
    "                # In case of considering the case where I have just one datum in the LC:\n",
    "                if countGoodPhases==1: chi2_dof_Int = chi2Int/(countGoodPhases) \n",
    "                else: chi2_dof_Int = chi2Int/(countGoodPhases-1)\n",
    "\n",
    "                #------------------------------------------------------\n",
    "\n",
    "                # Compute the residual and absolute magnitude value\n",
    "\n",
    "                mu_LCDM = DistanceMu(magData[0,0], OmMFix, wFix, HoFix)\n",
    "                mu_resid = mu_photo_Analytic - mu_LCDM\n",
    "\n",
    "                AbsMag_s = appMag_TBmax - mu_LCDM \n",
    "                error_AbsMag_s = np.sqrt(error_appMag_TBmax**2 + sigma_pecInt**2)\n",
    "\n",
    "                #------------------------------------------------------\n",
    "\n",
    "                # Defining the subsample label\n",
    "\n",
    "                if list_SNe[j][0][-9:-6] == 'CfA':\n",
    "                    indexSample = 1\n",
    "                elif list_SNe[j][0][-9:-6] == 'CSP':\n",
    "                    indexSample = 2\n",
    "                elif list_SNe[j][0][-12:-6] == 'Others':\n",
    "                    indexSample = 3\n",
    "\n",
    "                #######################################################\n",
    "\n",
    "                # WRITTING THE RESULTS TO A TEXT FILE\n",
    "\n",
    "                # Comment the masked SNe in ListSNe_AppMag_.txt:\n",
    "                if mask==0: commentText = ''\n",
    "                else: commentText = '##  '\n",
    "\n",
    "                # Write the distance modulus for -all- the SNe, no matter any cutoffs.\n",
    "                # This data will be used to write down the \"DistanceMu_All_BeforeCutoffs_.txt\" text file\n",
    "\n",
    "                textfile.write('%s%-30s   \\\n",
    "%.10f  %.10f  %.10f  %.10f  %13.10f  %12.10f        \\\n",
    "%1.f          %.10f  %.10f  \\\n",
    "%.10f  %.10f  \\\n",
    "%.10f  %.10f  %.6f  %.6f      0.00   \\\n",
    "%.10f  %.8f  %.10f  %.10f  \\\n",
    "%13.10f  %.10f  %10.7f  %.7f  %.10f  %.10f  %.10f  \\\n",
    "%.10f  %.10f    \\\n",
    "%.6f  %.6f  %.10f  %.10f # \\n'%\n",
    "                               (commentText, list_SNe[j][0][:-4],\n",
    "                                zcmbInt, err_zcmb, mu_photo_Analytic, stdDev_mu, mu_resid, chi2_dof_Int, \n",
    "                                indexSample, appMag_TBmax, error_appMag_TBmax, \n",
    "                                mu_LCDM, sigma_pecInt,\n",
    "                                AbsMag_s, error_AbsMag_s, TBmax, err_TBmax,\n",
    "                                zhelio, err_zhelio, dm15Int, err_dm15, \n",
    "                                EBVhost, err_EBVhost, EBV_MW, err_EBVMW, Alamb, err_Alamb, R_F,\n",
    "                                muSnoopy, err_muSnoopy,\n",
    "                                TBmax, err_TBmax, appMag_TBmax, error_appMag_TBmax ))                        \n",
    "\n",
    "                countSNe = countSNe + 1 # Counter\n",
    "\n",
    "                # ------- QUALITY CUTOFFS:  -------\n",
    "                # This data will be used to write down the \"DistanceMu_Good_AfterCutoffs_Main_.txt\" text file\n",
    "\n",
    "                if (zcmbInt < zcmbUpperLim and dm15Int > dm15LowerLim and dm15Int < dm15UpperLim and \n",
    "                    EBVhost > EBVhostMin and EBVhost < EBVhostMax and EBV_MW < EBVMWLim and \n",
    "                    chi2_dof_Int < chi2_dof_Max and mu_resid < residualMax):\n",
    "                    textfileMain.write('%s%-30s   \\\n",
    "%.10f  %.10f  %.10f  %.10f  %13.10f  %12.10f        \\\n",
    "%1.f          %.10f  %.10f  \\\n",
    "%.10f  %.10f  \\\n",
    "%.10f  %.10f  %.6f  %.6f      0.00   \\\n",
    "%.10f  %.8f  %.10f  %.10f  \\\n",
    "%13.10f  %.10f  %10.7f  %.7f  %.10f  %.10f  %.10f  \\\n",
    "%.10f  %.10f    \\\n",
    "%.6f  %.6f  %.10f  %.10f # \\n'%\n",
    "                               (commentText, list_SNe[j][0][:-4],\n",
    "                                zcmbInt, err_zcmb, mu_photo_Analytic, stdDev_mu, mu_resid, chi2_dof_Int, \n",
    "                                indexSample, appMag_TBmax, error_appMag_TBmax, \n",
    "                                mu_LCDM, sigma_pecInt,\n",
    "                                AbsMag_s, error_AbsMag_s, TBmax, err_TBmax,\n",
    "                                zhelio, err_zhelio, dm15Int, err_dm15, \n",
    "                                EBVhost, err_EBVhost, EBV_MW, err_EBVMW, Alamb, err_Alamb, R_F,\n",
    "                                muSnoopy, err_muSnoopy,\n",
    "                                TBmax, err_TBmax, appMag_TBmax, error_appMag_TBmax ))  \n",
    "\n",
    "                    textfil6.write('%s \\n'%list_SNe[j][0][:-6])\n",
    "\n",
    "                    mu_resid_array += [mu_resid]\n",
    "                    chi2_list += [chi2_dof_Int]\n",
    "                    SNeName_list += [list_SNe[j][0][:-4]]\n",
    "\n",
    "                    countGoodSNe = countGoodSNe + 1\n",
    "                    if mask==0: countNoCommented = countNoCommented + 1;\n",
    "                    else: countCommented = countCommented + 1; \n",
    "\n",
    "                    if indexSample == 1: countCfA =  countCfA + 1\n",
    "                    elif indexSample == 2: countCSP =  countCSP + 1\n",
    "                    elif indexSample == 3: countOthers =  countOthers + 1\n",
    "\n",
    "                    #---- Cutoff redshift: z_CMB > 0.01 ---\n",
    "                    # This data will be used to write down the \"DistanceMu_Good_AfterCutoffs_z001_.txt\"\n",
    "\n",
    "                    if zcmbInt > 0.01: \n",
    "                        textfil3.write('%s%-30s   \\\n",
    "%.10f  %.10f  %.10f  %.10f  %13.10f  %12.10f        \\\n",
    "%1.f          %.10f  %.10f  \\\n",
    "%.10f  %.10f  \\\n",
    "%.10f  %.10f  %.6f  %.6f      0.00   \\\n",
    "%.10f  %.8f  %.10f  %.10f  \\\n",
    "%13.10f  %.10f  %10.7f  %.7f  %.10f  %.10f  %.10f  \\\n",
    "%.10f  %.10f    \\\n",
    "%.6f  %.6f  %.10f  %.10f # \\n'%\n",
    "                               (commentText, list_SNe[j][0][:-4],\n",
    "                                zcmbInt, err_zcmb, mu_photo_Analytic, stdDev_mu, mu_resid, chi2_dof_Int, \n",
    "                                indexSample, appMag_TBmax, error_appMag_TBmax, \n",
    "                                mu_LCDM, sigma_pecInt,\n",
    "                                AbsMag_s, error_AbsMag_s, TBmax, err_TBmax,\n",
    "                                zhelio, err_zhelio, dm15Int, err_dm15, \n",
    "                                EBVhost, err_EBVhost, EBV_MW, err_EBVMW, Alamb, err_Alamb, R_F,\n",
    "                                muSnoopy, err_muSnoopy,\n",
    "                                TBmax, err_TBmax, appMag_TBmax, error_appMag_TBmax ))                                        \n",
    "\n",
    "                        mu_resid_z001_array += [mu_resid]\n",
    "                        chi2_z001_list += [chi2_dof_Int]\n",
    "                        SNeName_z001_list += [list_SNe[j][0][:-4]]\n",
    "                        countGoodSNe_z001 = countGoodSNe_z001 + 1\n",
    "\n",
    "                        if indexSample == 1: countCfA_z001 =  countCfA_z001 + 1\n",
    "                        elif indexSample == 2: countCSP_z001 =  countCSP_z001 + 1\n",
    "                        elif indexSample == 3: countOthers_z001 =  countOthers_z001 + 1\n",
    "\n",
    "                else:\n",
    "                    # This data will be used to write down the \"DistanceMu_SNe_OutCutoffs_.txt\"\n",
    "                    textfil5.write('%s%-30s   \\\n",
    "%.10f  %.10f  %.10f  %.10f  %13.10f  %12.10f        \\\n",
    "%1.f          %.10f  %.10f  \\\n",
    "%.10f  %.10f  \\\n",
    "%.10f  %.10f  %.6f  %.6f      0.00   \\\n",
    "%.10f  %.8f  %.10f  %.10f  \\\n",
    "%13.10f  %.10f  %10.7f  %.7f  %.10f  %.10f  %.10f  \\\n",
    "%.10f  %.10f    \\\n",
    "%.6f  %.6f  %.10f  %.10f # \\n'%\n",
    "                               (commentText, list_SNe[j][0][:-4],\n",
    "                                zcmbInt, err_zcmb, mu_photo_Analytic, stdDev_mu, mu_resid, chi2_dof_Int, \n",
    "                                indexSample, appMag_TBmax, error_appMag_TBmax, \n",
    "                                mu_LCDM, sigma_pecInt,\n",
    "                                AbsMag_s, error_AbsMag_s, TBmax, err_TBmax,\n",
    "                                zhelio, err_zhelio, dm15Int, err_dm15, \n",
    "                                EBVhost, err_EBVhost, EBV_MW, err_EBVMW, Alamb, err_Alamb, R_F,\n",
    "                                muSnoopy, err_muSnoopy,\n",
    "                                TBmax, err_TBmax, appMag_TBmax, error_appMag_TBmax ))                               \n",
    "\n",
    "                    countBadSNe = countBadSNe + 1\n",
    "\n",
    "\n",
    "                #######################################################\n",
    "                #\n",
    "                # Plotting the LC data and the fit with the template for a given SN\n",
    "\n",
    "                # Offset to displace the template to match apparent magnitude data\n",
    "                if Method==7: OffsetToMatchAppMagData = appMag_TBmax\n",
    "                else: OffsetToMatchAppMagData = mu_photo_Analytic\n",
    "\n",
    "\n",
    "                # Some definitions to plot the template in the range phase\n",
    "                x = Template[indexLowerPhase:indexUpperPhase,0] \n",
    "                y_pred = Template[indexLowerPhase:indexUpperPhase,1] + OffsetToMatchAppMagData\n",
    "\n",
    "                if TempType == 'MWA':\n",
    "                    sigma = np.sqrt(Template[indexLowerPhase:indexUpperPhase,3])\n",
    "                else: \n",
    "                    sigma = Template[indexLowerPhase:indexUpperPhase,2]\n",
    "\n",
    "                # Creating the plot \n",
    "                plt.figure()\n",
    "\n",
    "                # Standard deviation\n",
    "                plt.fill(np.concatenate([x, x[::-1]]),\n",
    "                        np.concatenate([y_pred - 1*sigma,\n",
    "                                      (y_pred + 1*sigma)[::-1]]),\n",
    "                        # np.concatenate([y_pred - 1 * sigma,\n",
    "                        #                (y_pred + 1 * sigma)[::-1]]),\n",
    "                        alpha=0.3, fc='g', ec='None')\n",
    "\n",
    "                # PLOT GP TEMPLATE mean\n",
    "                plt.plot(x, y_pred, 'k-', lw=2, alpha=0.4)\n",
    "\n",
    "                #-------------------\n",
    "\n",
    "                # Plot the photometric LC data (app mag) for the given SNe \n",
    "\n",
    "                plt.errorbar(magData[InfoSN_NumLinesSkip:,0], magData[InfoSN_NumLinesSkip:,3], \n",
    "                             magData[InfoSN_NumLinesSkip:,4], ls='', fmt='r.', alpha=1,  markersize=8)\n",
    "\n",
    "                #-------------------\n",
    "\n",
    "                plt.grid(True)\n",
    "\n",
    "                #-- Defining the y-limits for plotting\n",
    "                y_lowerlim = MinMagTempPlot + OffsetToMatchAppMagData\n",
    "                y_upperlim = Template[indexMaxTempl,1]+ OffsetToMatchAppMagData\n",
    "\n",
    "                plt.ylim(y_lowerlim+0.7, y_upperlim-0.5)\n",
    "                plt.xlim(x_RangePlots)\n",
    "\n",
    "                if Method==6 or Method==7:\n",
    "                    plt.text(-7, y_lowerlim-0.7, 'Best fit: $m_{T_{Bmax}}$ = %r $\\pm$ %r'%(round(appMag_TBmax,3), \n",
    "                                                                              round(np.sqrt(error_appMag_TBmax),3))) \n",
    "\n",
    "                plt.text(-7, y_lowerlim-0.5, '$\\mu$ = %r $\\pm$ %r'%(round(mu_photo_Analytic,3), \n",
    "                                                                              round(np.sqrt(sigma2_mu),3)))  \n",
    "                plt.text(-7, y_lowerlim-0.3, '$z_{CMB}$ = %r'%round(magData[0,0],5))\n",
    "                plt.text(-7, y_lowerlim-0.1, '$\\Delta \\mu$ = %r'%round(mu_resid,3))\n",
    "                if Chi2dofPrint == True:\n",
    "                    plt.text(-7, y_lowerlim+0.1, '$\\chi^2_{dof}$ = %r'%round(chi2_dof_Int,2))\n",
    "\n",
    "                plt.title(list_SNe[j][0][:-4])\n",
    "\n",
    "                plt.xlabel(r'phase = (MJD-$T_{Bmax}$)/(1+$z_{\\rm hel}$)')\n",
    "                plt.ylabel('apparent magnitude')\n",
    "\n",
    "                if (zcmbInt < zcmbUpperLim and dm15Int > dm15LowerLim and dm15Int < dm15UpperLim and \n",
    "                    EBVhost > EBVhostMin and EBVhost < EBVhostMax and EBV_MW < EBVMWLim and\n",
    "                    chi2_dof_Int < chi2_dof_Max and mu_resid < residualMax):\n",
    "                    if zcmbInt > 0.01:\n",
    "                        plt.savefig(DirSaveOutput+'Plot_Fits/AfterCutoffs_z001/'+'%s_FitMu.png'%(list_SNe[j][0][:-4]))\n",
    "                    else:\n",
    "                        plt.savefig(DirSaveOutput+'Plot_Fits/AfterCutoffs_z0/'+'%s_FitMu.png'%(list_SNe[j][0][:-4]))\n",
    "                else:\n",
    "                    plt.savefig(DirSaveOutput+'Plot_Fits/OutCutoffs/'+'%s_FitMu.png'%(list_SNe[j][0][:-4]))\n",
    "\n",
    "                plt.close()\n",
    "\n",
    "                # <--- End plotting data ----\n",
    "\n",
    "                print 'Done:  %s'%list_SNe[j][0]\n",
    "                # print ''\n",
    "\n",
    "    # <--- End loop\n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    #     RMS computation\n",
    "\n",
    "    rms = np.sqrt(np.mean(np.square(mu_resid_array)))\n",
    "    rms_z001 = np.sqrt(np.mean(np.square(mu_resid_z001_array)))\n",
    "    # rms_z001_chi2_Res = np.sqrt(np.mean(np.square(mu_resid_z001_chi2_Res_array)))\n",
    "\n",
    "    # Write to the RMS text file\n",
    "    textfil4.write('%6.2f       %5.2f      %.4f  %3.f     %.4f      %3.f  \\n'%(lowerPhase, upperPhase, \n",
    "                                                      rms, countGoodSNe, rms_z001, countGoodSNe_z001))\n",
    "\n",
    "    #=======================================================\n",
    "\n",
    "    # text7 = '# Total number of SNe in this list: %r (CfA=%r, CSP=%r, Others=%r) \\n'%\n",
    "\n",
    "    text7 = '# Total number of SNe in this list: %r (CfA=%r, CSP=%r, Others=%r) \\n'%(\n",
    "        countGoodSNe, countCfA, countCSP, countOthers)\n",
    "    text8 = '# Total number of SNe with z >0.01: %r (CfA=%r, CSP=%r, Others=%r) \\n'%(\n",
    "        countGoodSNe_z001, countCfA_z001, countCSP_z001, countOthers_z001)\n",
    "    text_08_01 = \"# %s SNe no commented automatically (##). \\n\"%countNoCommented \n",
    "    text_08_02 = \"# %s SNe were commented automatically (##). \\n\"%countCommented \n",
    "    text_22 = \"# %s SNe were commented automatically (##). \\n\"%countCommented \n",
    "\n",
    "    text9  = '# RMS: %r (all the SNe in this file) \\n'%round(rms,4)\n",
    "    text10 = '# RMS: %r (SNe z > 0.01) \\n'%round(rms_z001,4)\n",
    "\n",
    "    text11 = '# Largest chi2: %r, SNe: %s \\n'%(\n",
    "        round(max(chi2_list),4), SNeName_list[chi2_list.index(max(chi2_list))]   )\n",
    "    text12 = '# Largest chi2 (z>0.01): %r, SNe: %s \\n'%(\n",
    "        round(max(chi2_z001_list),4),\n",
    "        SNeName_z001_list[chi2_z001_list.index(max(chi2_z001_list))] )\n",
    "    # text12_1 = '# Largest chi2: %r, SNe: %s \\n'%(round(max(chi2_z001_chi2_Res_list),4), \n",
    "    #   SNeName_z001_chi2_Res_list[chi2_z001_chi2_Res_list.index(max(chi2_z001_chi2_Res_list))] )\n",
    "\n",
    "    text13 = '# Largest upper residual: %r, SNe: %s \\n'%(\n",
    "        round(max(mu_resid_array),4), SNeName_list[mu_resid_array.index(max(mu_resid_array))]   )\n",
    "    text14 = '# Largest lower residual: %r, SNe: %s \\n'%(\n",
    "        round(min(mu_resid_array),4),SNeName_list[mu_resid_array.index(min(mu_resid_array))]  )\n",
    "\n",
    "    text15 = '# Largest upper residual (z>0.01): %r, SNe: %s  \\n'%(\n",
    "        round(max(mu_resid_z001_array),4),\n",
    "        SNeName_z001_list[mu_resid_z001_array.index(max(mu_resid_z001_array))]   )\n",
    "    # text15_1 = '# Largest upper residual: %r, SNe: %s  \\n'%(\n",
    "    #    round(max(mu_resid_z001_chi2_Res_array),4), \n",
    "    #   SNeName_z001_chi2_Res_list[mu_resid_z001_chi2_Res_array.index(max(mu_resid_z001_chi2_Res_array))]   )\n",
    "\n",
    "    text16 = '# Largest lower residual (z>0.01): %r, SNe: %s  \\n'%(\n",
    "        round(min(mu_resid_z001_array),4), \n",
    "        SNeName_z001_list[mu_resid_z001_array.index(min(mu_resid_z001_array))]   )\n",
    "    # text16_1 = '# Largest lower residual: %r, SNe: %s  \\n'%(\n",
    "    #  round(min(mu_resid_z001_chi2_Res_array),4), \n",
    "    #  SNeName_z001_chi2_Res_list[mu_resid_z001_chi2_Res_array.index(min(mu_resid_z001_chi2_Res_array))]   )\n",
    "\n",
    "\n",
    "    textfile.write('# Total number of SNe in this file: %r \\n'%countSNe)\n",
    "\n",
    "    #--------------------\n",
    "    textfileMain.write(text_line);\n",
    "    textfileMain.write(text7); textfileMain.write(text8); \n",
    "    textfileMain.write(text_08_01); textfileMain.write(text_08_02); \n",
    "    textfileMain.write(text9); textfileMain.write(text10)\n",
    "    textfileMain.write(text11); textfileMain.write(text12); textfileMain.write(text13); \n",
    "    textfileMain.write(text14); textfileMain.write(text15); textfileMain.write(text16);\n",
    "    #--------------------\n",
    "\n",
    "    textfil3.write(text8); textfil3.write(text10); textfil3.write(text12); textfil3.write(text15)\n",
    "    textfil3.write(text16)\n",
    "\n",
    "    # textfil3_1.write(text8_1); textfil3_1.write(text10_1); textfil3_1.write(text12_1); textfil3_1.write(text15)\n",
    "    # textfil3_1.write(text16)\n",
    "\n",
    "    textfil5.write('# Total number of SNe in this file: %r \\n'%countBadSNe)\n",
    "\n",
    "    textfile.close()\n",
    "    textfileMain.close()\n",
    "    textfil3.close()\n",
    "    textfil4.close()\n",
    "    textfil5.close()\n",
    "    textfil6.close()\n",
    "\n",
    "    print ' '\n",
    "    print '--- All done smoothly, DistanceModuli_*.txt created ---'\n",
    "    print 'Number of SNe before cutoffs = ', countSNe\n",
    "    print 'Number of SNe after cutoffs = ', countGoodSNe\n",
    "    print 'Number of SNe after cutoffs AND 0.01 < z < 0.06 = ', countGoodSNe_z001\n",
    "    print text7, text_08_01, text_22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the datatable I've just created above\n",
    "\n",
    "#### This will be used to determine the cut based on $\\chi^2$ and to determine the mean absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'DistMu_array' resetted.\n",
      "# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_.txt >\n",
      "# Number of SNe in the file =  29\n"
     ]
    }
   ],
   "source": [
    "import os # To use command line like instructions\n",
    "import glob # To read the files in my directory\n",
    "\n",
    "#-- Array of minimum redshift to consider --\n",
    "zCMB_Min = np.array([0, 0.01])\n",
    "zCMB_Min_Label = ['z0', 'z001']\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# Change the working directory where the data files are located\n",
    "os.chdir(DirSaveOutput)\n",
    "\n",
    "# Reset the main array container to avoid using the one from \n",
    "# the previous run.\n",
    "DistMu_array = np.array([0])\n",
    "print \"# 'DistMu_array' resetted.\"\n",
    "\n",
    "# Reading the data files in that folder \n",
    "DistanceMuFiles = glob.glob('DistanceMu_Good_After*.txt')\n",
    "\n",
    "# Check if 'DistanceModuli_Notes_.txt' is already there, otherwise read\n",
    "# the 'DistanceModuli_.txt' file.\n",
    "if 'DistanceMu_Good_AfterCutoffs_Main_Notes_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+\n",
    "                        'DistanceMu_Good_AfterCutoffs_Main_Notes_.txt', \n",
    "                                 dtype=['S30',\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float])\n",
    "    print 'Reading the file:  < DistanceMu_Good_AfterCutoffs_Main_Notes_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+\n",
    "                        'DistanceMu_Good_AfterCutoffs_Main_.txt',\n",
    "                                 dtype=['S30',\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+\n",
    "                        'DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt',\n",
    "                                 dtype=['S30',\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_TMP_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+\n",
    "                        'DistanceMu_Good_AfterCutoffs_Main_TMP_.txt',\n",
    "                                 dtype=['S30',\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float,float,float,float,float,float,float,float,\n",
    "               float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_TMP_.txt >'\n",
    "\n",
    "else: print '# < DistanceMu_Good_AfterCutoffs_Main_.txt > file not found!!!'\n",
    "\n",
    "print '# Number of SNe in the file = ', len(DistMu_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_.txt >\n",
    "# Number of SNe in the file =  63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\chi^2_{d.o.f.}$ histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 2 lists: for z<0 and z<0.01\n",
    "\n",
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    chi2dof_z0_list = []\n",
    "    chi2dof_z001_list = []\n",
    "\n",
    "    for i in range(len(DistMu_array)):\n",
    "\n",
    "        name = DistMu_array[i][0]\n",
    "        zcmbInt = DistMu_array[i][1]\n",
    "        chi2dof_z0_list += [DistMu_array[i][6]]\n",
    "\n",
    "        if zcmbInt > 0.01:\n",
    "            chi2dof_z001_list += [DistMu_array[i][6]]\n",
    "\n",
    "\n",
    "    print 'len(chi2dof_z0_list) = ', len(chi2dof_z0_list)\n",
    "    print 'len(chi2dof_z001_list) = ', len(chi2dof_z001_list)\n",
    "    # len(chi2dof_z001_list) =  78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the histogram of chi2_dof\n",
    "\n",
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # countChi2dofPlot = countChi2dofPlot + 1\n",
    "    fontsizeText = 15\n",
    "\n",
    "    BinSize = 45\n",
    "\n",
    "    for zz in zCMB_Min:\n",
    "        fig = plt.figure()\n",
    "\n",
    "        if zz==0.0: plt.hist(chi2dof_z0_list, BinSize, histtype=u'barstacked')\n",
    "        elif zz==0.01: plt.hist(chi2dof_z001_list, BinSize, histtype=u'barstacked')        \n",
    "\n",
    "        plt.xlabel(r'$\\chi^2_{\\rm{d.o.f}}$', fontsize=fontsizeText+2)\n",
    "        plt.ylabel('Frequency', fontsize=fontsizeText)\n",
    "        plt.title(r'Histogram $\\chi^2_{\\rm{d.o.f}}$ (%r<z<%r)'%(zz, zcmbUpperLim), fontsize=fontsizeText)\n",
    "        plt.text(15, 10, 'Bin size = %r'%BinSize)\n",
    "\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.savefig('Plot_histo_chi2dof_BinSize%r_z%r_.png'%(BinSize, zz))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False: plt.close(); plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the values of chi2dof as lines\n",
    "\n",
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # Array of zeros just for the y-axis values.\n",
    "    zero_z0_np = np.zeros(len(chi2dof_z0_list))\n",
    "    zero_z001_np = np.zeros(len(chi2dof_z001_list))\n",
    "\n",
    "    for zz in zCMB_Min:\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "        if  zz==0.0:\n",
    "            plt.plot(chi2dof_z0_list, zero_z0_np, ls='None', marker='|', ms=30, markeredgewidth=2, color='r',  alpha=1)\n",
    "        elif zz==0.01:\n",
    "            # plt.plot(chi2dof_z001_list, zero_np, ls='None', marker='o', ms=12, color='r',  alpha=0.3)\n",
    "            plt.plot(chi2dof_z001_list, zero_z001_np, ls='None', marker='|', ms=30, markeredgewidth=2, color='r',  alpha=1)\n",
    "\n",
    "        plt.xlabel(r'$\\chi^2_{\\rm{d.o.f}}$', fontsize=fontsizeText+2)\n",
    "        plt.ylabel('No meaning', fontsize=fontsizeText)\n",
    "        plt.title(r'$\\chi^2_{\\rm{d.o.f}}$ (%r<z<%r)'%(zz,zcmbUpperLim), fontsize=fontsizeText)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.ylim(-1, 1)\n",
    "\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.savefig('Plot_histo_chi2dof_Points_z%r_.png'%(zz))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False: plt.close(); plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining average Absolute magnitude  of the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the histogram with the Gaussian estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the histogram with the Gaussian estimation\n",
    "\n",
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    from scipy.stats import norm\n",
    "    import matplotlib.mlab as mlab\n",
    "    \n",
    "    # best fit of data.\n",
    "    # 'norm.fit' simply compute the mean and standard devation of the sample.\n",
    "    (Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax) = norm.fit(DistMu_array['f12'])\n",
    "\n",
    "    #------ Plot -----------\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(DistMu_array['f12'], 20, normed=True, facecolor='green', alpha=0.5)\n",
    "    # n, bins, patches = plt.hist(DistMu_array['f12'], 20, normed=False, facecolor='green', alpha=0.5)\n",
    "\n",
    "\n",
    "    # add a 'best fit' Gaussian line\n",
    "    y = mlab.normpdf(bins, Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax )\n",
    "    l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "    plt.xlabel(r'$\\hat{m}_{\\rm Bmax} - \\mu_{\\Lambda{\\rm CDM}}$')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(r'Histogram. (mean=%.2f, std dev = %.2f)' %(Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax))\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.savefig(DirSaveOutput+'Plot_histo_AbsMag_.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False: plt.close(); plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NotebookToPlotOnly == False:\n",
    "    \n",
    "    # The results that I will use now.\n",
    "    # NOTE: This value is independent of what I have assume about \"Average_NIRAbsMag_TBmax\" and\n",
    "    # \"error_Average_NIRAbsMag_TBmax\" at the top of the notebook in the User section.\n",
    "    # NOTE: The values of \"Average_NIRAbsMag_TBmax\" and \"error_Average_NIRAbsMag_TBmax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    # ------------------------------\n",
    "    now = datetime.datetime.now() # Read the time and date right now\n",
    "    text_timenow = now.strftime(\"%Y-%m-%d; %H:%M hrs.\")\n",
    "    text_Date   = '# On date: %s \\n'%text_timenow\n",
    "    # ------------------------------\n",
    "\n",
    "    print '#', '-'*30\n",
    "    print '#  ', BandName, 'band | vpecFix =', vpecFix, 'km/s | 0 < z <', zcmbUpperLim\n",
    "    # print '# (mean abs mag, std deviation)\\n' \n",
    "    # print \"\"\n",
    "\n",
    "    print \"# Average_NIRAbsMag_TBmax = %s;  # %s\"%(Average_NIRAbsMag_TBmax, text_timenow)\n",
    "    print \"# error_Average_NIRAbsMag_TBmax = %s;\"%(error_Average_NIRAbsMag_TBmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse-variance weights array\n",
    "\n",
    "if NotebookToPlotOnly == False:\n",
    "\n",
    "    WeightsInvVar = 1/np.square(DistMu_array['f13'])\n",
    "\n",
    "    # Inverse-variance weighted average\n",
    "    WeightedAbsMag = np.average(DistMu_array['f12'], weights=WeightsInvVar )\n",
    "\n",
    "    # Useful definitions to determine the weighted population standard deviation\n",
    "    V1 = np.sum(WeightsInvVar)\n",
    "    V2 = np.sum(np.square(WeightsInvVar))\n",
    "\n",
    "    product2 = 0\n",
    "    # Computing the unbiased weighted population standard deviation\n",
    "    for i in range(len(DistMu_array['f12'])):\n",
    "        # print i\n",
    "        absMagInt = DistMu_array['f12'][i]\n",
    "        product2 = product2 + WeightsInvVar[i]*(absMagInt-WeightedAbsMag)**2\n",
    "\n",
    "    error_WeightedAbsMag = np.sqrt(product2/(V1 - (V2/V1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute some other values\n",
    "\n",
    "# print '#'+'-'*30\n",
    "# print '#   ', BandName, 'band   Pec velocity =', vpecFix, 'km/s'\n",
    "# print '#', np.mean(DistMu_array['f12']), '= mean abs mag'\n",
    "# print '#', np.median(DistMu_array['f12']), '= median' \n",
    "# print '#', WeightedAbsMag, '= Weighted Abs Mag'\n",
    "# print '#', np.sqrt(1/np.sum(WeightsInvVar) ), '= uncertainty in the weighted average'\n",
    "# print '#', np.std(DistMu_array['f12']), '= population standard deviation'\n",
    "# print '#', error_WeightedAbsMag, '= unbiased weighted population standard deviation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUBBLE DIAGRAM PLOTS\n",
    "\n",
    "- Note that in all the rest of the the following cells, it is NOT computed or used at all the values of (Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax).\n",
    "\n",
    "\n",
    "-  (SEE UPDATED INFORMATION BELOW) If I need to remove an outlier in any of the \"any YJHK\", YJHK, YJH or JHK Gaussian-Process or template Hubble diagrams, then: \n",
    "\n",
    "\n",
    "1. first I need to \"comment\" that SN in 'DistanceMu_Good_AfterCutoffs_Main_.txt' in all the bands, \n",
    "2. then, rerun the \"13_TotalDistanceMu_vXX.ipynb\" iPython notebook to recompute the covariance matrices and their inverse matrix from the remaining SNe.\n",
    "3. plot the Hubble diagram using \"11_DistanceMu_HubbleDiagram_vXX.ipynb\" notebook (this section).\n",
    "\n",
    "UPDATED INFORMATION ABOUT THE CASE OF REMOVING OUTLIERS IN THE \"any YJHK\", YJHK, YJH or JHK Gaussian-Process or template Hubble diagrams:\n",
    "\n",
    "The process described above is the correct to remove outliers, however, for simplicity when making different experiments removing a lot of SNe (specially when comparing the NIR vs SALT2 Hubble diagrams from SNe that pass SALT2 cutoffs) I'm recalibrating the Hubble diagram residual by simply determining the value that allows to minimize the weighted *average* in the Hubble residual plot (exactly as done for the SALT2 Hubble diagram). This is done by using the simple single instruction:\n",
    "\n",
    "elif BandMax == 'NIRmax' and PlotTotalMu == True:\n",
    "\n",
    "     delta_Mo = SimplexResult_1[0]\n",
    "\n",
    "If I want to use the correct procedure to remove outliers in the \"GP NIR any band HD\", I simply have to follow the instructions indicated and comment the instruction above.\n",
    "The drawback of this method is that the uncertainties are less consistent with scatter in the Hubble diagram, i.e., chi^2_dof is not close to one.\n",
    "\n",
    "\n",
    "'DistanceModuli_Notes_.txt': The advantage of having a text file listing all the SNe is that I can easily \"comment\" the outliers SNe in the Hubble diagram and residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting just to label the plots accordingly.\n",
    "\n",
    "# Band to use as the reference peak maximum? Options: (NIRmax, Bmax).\n",
    "# For the template method to determine the distance modulus I use BandMax = 'Bmax'\n",
    "# For the GP method to determine the distance modulus I use BandMax = 'NIRmax'\n",
    "# \"Bmax_GP\": Determine the distance moduli at B-band max but using the GP method.\n",
    "\n",
    "# WATCH OUT!: Everytime I change between (NIRmax, Bmax, Snoopy, SALT2) Hubble diagrams,\n",
    "# I must reset this notebook because in each case it is used different values for \n",
    "# (Ho, Omega_matter, w).\n",
    "\n",
    "BandMax = 'NIRmax'  # (NIRmax, Bmax_GP, Bmax, Snoopy, SALT2).\n",
    "\n",
    "#   LABELS IN THE PLOT'S TITLE\n",
    "#      LOW-Z\n",
    "if BandMax == 'SALT2': BandName = 'Optical'\n",
    "if BandMax == 'Snoopy': BandName = 'BVR'  # ORIGINAL\n",
    "# if BandMax == 'Snoopy': BandName = 'Optical+NIR'  # TEMPORAL\n",
    "# if BandMax == 'Snoopy': BandName = 'NIR'  # TEMPORAL\n",
    "# if BandMax == 'Snoopy': BandName = 'Y'  # TEMPORAL\n",
    "\n",
    "\n",
    "#    RAISINs\n",
    "# if BandMax == 'Snoopy': BandName = 'Optical' # RAISINs\n",
    "# if BandMax == 'Snoopy': BandName = 'Opt+NIR' # RAISINs\n",
    "\n",
    "#------- \"Total\" distance modulus ---------\n",
    "\n",
    "# Plot the \"total\" distance modulus derived from the three distance modulus computed \n",
    "# from each band?\n",
    "# To put TRUE, first I need to have already computed the distance moduli for each SNe \n",
    "# in the YJHK bands!\n",
    "\n",
    "PlotTotalMu = False    # True, False\n",
    "\n",
    "# \"PlotTotalMu = True\"  is only valid when BandMax = NIRmax, Bmax, Bmax_GP.\n",
    "# \"PlotTotalMu = False\" if I'm plotting the SNoopy or SALT2 distance moduli.\n",
    "if BandMax == 'Snoopy' or BandMax == 'SALT2':\n",
    "    PlotTotalMu = False\n",
    "\n",
    "# - \"AllBands\": If there is not distance mu estimation for a given SN, then \n",
    "# use the 3, 2 or 1 band that it was observed\n",
    "# - \"YJH\": Consider the SNe that have distance mu estimation in these \n",
    "# 3 bands ONLY, and so on.\n",
    "\n",
    "if PlotTotalMu == True: BandsCombination = 'AllBands'   # (AllBands, JH, YJH, JHK,  YJHK)\n",
    "else: BandsCombination = ''\n",
    "    \n",
    "#####################################################\n",
    "\n",
    "#    Plot RAISINs?\n",
    "\n",
    "# Set the limits and labels in the plot if I'm plotting RAISINs.\n",
    "# False = plot the low-z sample.\n",
    "plot_raisins = False\n",
    "\n",
    "if plot_raisins == True:\n",
    "    zcmbUpperLim = 0.65  # (0.6, 0.65, anything else)\n",
    "    xlimPlots = 0.2, zcmbUpperLim+0.003 # \n",
    "    ylimPlots = 40.0, 44.5\n",
    "    \n",
    "#####################################################\n",
    "\n",
    "#    PLOT OPTIONS\n",
    "# Resolution in the Hubble diagram plots\n",
    "ResolutionPlot_HD = 150  # dpi\n",
    "\n",
    "# Settings error bars:\n",
    "MyPointSize = 6  \n",
    "MyLineWidth = 1  \n",
    "MyCapeSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hubble diagram type: NIRmax\n",
      "# PlotTotalMu? (when combined YJHK bands only) = False \n",
      "\n",
      "# Ho = 73.24 km/s/Mpc.\n",
      "# Omega_Matter = 0.28\n",
      "# Omega_Lambda = 0.72\n"
     ]
    }
   ],
   "source": [
    "# Apparent magnitude, determined from GP interpolation, template, snoopy.?\n",
    "    \n",
    "if BandMax == 'Bmax':\n",
    "    AppMag_method = 'Template to compute the app mags'  \n",
    "    HoFix = 73.24 # Valued used by default in the low-z paper\n",
    "    OmMFix = 0.28 # Omega_Matter\n",
    "    OmLFix = 0.72 # Omega_Lambda\n",
    "    wFix = -1 # Dark energy EoS\n",
    "    \n",
    "elif BandMax == 'Bmax_GP':\n",
    "    AppMag_method = 'Gaussian Process to compute the app mags'  \n",
    "    HoFix = 73.24 # Valued used by default in the low-z paper\n",
    "    OmMFix = 0.28 # Omega_Matter\n",
    "    OmLFix = 0.72 # Omega_Lambda\n",
    "    wFix = -1 # Dark energy EoS\n",
    "    \n",
    "elif BandMax == 'NIRmax':\n",
    "    AppMag_method = 'Gaussian Process to compute app mags'\n",
    "    HoFix = 73.24 # Valued used by default in the low-z paper\n",
    "    OmMFix = 0.28 # Omega_Matter\n",
    "    OmLFix = 0.72 # Omega_Lambda\n",
    "    wFix = -1 # Dark energy EoS\n",
    "elif BandMax == 'Snoopy':\n",
    "    AppMag_method = 'SNooPy fit'\n",
    "    # Redefing some variables: \n",
    "    HoFix = 72 # km/s. Ho=72 is Snoopy's default value\n",
    "    OmMFix = 0.28 # Omega_Matter\n",
    "    OmLFix = 0.72 # Omega_Lambda\n",
    "    wFix = -1 # Dark energy EoS\n",
    "elif BandMax == 'SALT2':\n",
    "    AppMag_method = 'SALT2 fit'\n",
    "    HoFix = 73.24 # Valued used by default in the low-z paper\n",
    "    OmMFix = 0.28 # Omega_Matter\n",
    "    OmLFix = 0.72 # Omega_Lambda\n",
    "    wFix = -1 # Dark energy EoS\n",
    "\n",
    "#----------------------------------------------\n",
    "\n",
    "print \"# Hubble diagram type: %s\"%BandMax\n",
    "print \"# PlotTotalMu? (when combined YJHK bands only) = %s \\n\"%PlotTotalMu\n",
    "print \"# Ho = %s km/s/Mpc.\"%HoFix\n",
    "print \"# Omega_Matter = %s\"%OmMFix\n",
    "print \"# Omega_Lambda = %s\"%OmLFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading the datafile with the TOTAL distance modulus inferred from\n",
    "# the distance moduli coming from each band.\n",
    "\n",
    "if PlotTotalMu and BandMax == 'NIRmax': Method_folder = 'GaussianProcess'\n",
    "if PlotTotalMu and BandMax == 'Bmax': Method_folder = 'Template'\n",
    "if PlotTotalMu and BandMax == 'Bmax_GP': Method_folder = 'GP_Bmax'\n",
    "\n",
    "if PlotTotalMu: \n",
    "    # Change the working directory where the datafiles are located\n",
    "    DirSaveOutput = DirMain_1+'AllBands/Plots/HubbleDiagram/%s/%s/'%(\n",
    "        Method_folder, BandsCombination)\n",
    "    if not os.path.exists(DirSaveOutput): os.makedirs(DirSaveOutput)\n",
    "    \n",
    "    DirDataTotalMu = DirMain_1+'AllBands/Plots/HubbleDiagram/'+Method_folder+'/'\n",
    "    os.chdir(DirDataTotalMu)\n",
    "\n",
    "    try:\n",
    "        DistMu_array = np.genfromtxt('Table_TotalMu_%s_Notes_.txt'%BandsCombination,\n",
    "                                    dtype=['S30', float,float,float,float,float,float,float])\n",
    "    except: \n",
    "        DistMu_array = np.genfromtxt('Table_TotalMu_%s_.txt'%BandsCombination,\n",
    "                                    dtype=['S30', float,float,float,float,float,float,float])\n",
    "        \n",
    "    BandName = 'All'\n",
    "    \n",
    "    print '# Number of SNe in PlotTotalMu file: %s.'%len(DistMu_array)\n",
    "# Number of SNe in PlotTotalMu file: 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the value needed to have a weighted average of zero in the Hubble residual \n",
    "\n",
    "Used for SALT2 Hubble diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the average in the absolute value of the residual\n",
    "# These functions are going to be minimized.\n",
    "\n",
    "# AbsResidual values\n",
    "mu_1_np = DistMu_array['f3']\n",
    "z_1_np  = DistMu_array['f1']\n",
    "res_mu_np_int = mu_1_np - DistanceMuVector(z_1_np, OmMFix, wFix, HoFix)\n",
    "\n",
    "err_mu_1_np = DistMu_array['f4']\n",
    "\n",
    "# Inverse-variance weighted average function to be minimized \n",
    "def WeightedAbsResidual_fun(deltaMo, UpLimit, LowLimit, AbsResidual_Roof):\n",
    "    residuals_int = res_mu_np_int +  deltaMo\n",
    "    WeightedAbsResidual_int = np.average(residuals_int, weights=err_mu_1_np )\n",
    "    \n",
    "    if deltaMo < UpLimit and deltaMo > LowLimit:  \n",
    "        # For some unknown reason, simplex is search the maximum instead of\n",
    "        # the minimimum, so I had to define the average absolute mag as 1/WeightedAbsResidual\n",
    "        # WeightedAbsResidual_final = 1/WeightedAbsResidual_int\n",
    "        WeightedAbsResidual_final = WeightedAbsResidual_int\n",
    "        \n",
    "    else: WeightedAbsResidual_final = AbsResidual_Roof\n",
    "        \n",
    "    return abs(WeightedAbsResidual_final)\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Simple average function to be minimized \n",
    "def AverageAbsResidual_fun(deltaMo, UpLimit, LowLimit, AbsResidual_Roof):\n",
    "    residuals_int = res_mu_np_int + deltaMo\n",
    "    # AverageAbsResidual_int = np.mean(residuals_int)\n",
    "    AverageAbsResidual_int = np.sum(residuals_int)/len(residuals_int)\n",
    "     \n",
    "    if deltaMo < UpLimit and deltaMo > LowLimit: \n",
    "        # For some unknown reason, simplex is search the maximum instead of\n",
    "        # the minimimum, so I had to define the average absolute mag as 1/AverageAbsResidual_int\n",
    "        # AverageAbsResidual_final = 1/AverageAbsResidual_int\n",
    "        AverageAbsResidual_final = AverageAbsResidual_int\n",
    "        \n",
    "    else: AverageAbsResidual_final = AbsResidual_Roof\n",
    "\n",
    "    return abs(AverageAbsResidual_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 1.1444956596785391e-10\n",
      "    nfev: 30\n",
      "     nit: 29\n",
      " success: True\n",
      "       x: -0.080272338684177602\n",
      "# [-0.080272338684177602]  = value of delta_Mo that minimize the Hubble residual.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine the value of the constant deltaMo in order to obtain a\n",
    "# weighted average value of zero in the Hubble residual\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "# Search limits:\n",
    "# UpLimit = 0.2; LowLimit = -0.2\n",
    "UpLimit = 3; LowLimit = -3\n",
    "\n",
    "# Assume this value for deltaMo in case of the search is outside the range\n",
    "# indicated above.\n",
    "Residual_Roof = 10 \n",
    "\n",
    "WeightedAbsResidual_Out = scipy.optimize.minimize_scalar(WeightedAbsResidual_fun, \n",
    "                                                    args=(UpLimit, LowLimit, Residual_Roof))\n",
    "\n",
    "AverageAbsResidual_Out = scipy.optimize.minimize_scalar(AverageAbsResidual_fun, \n",
    "                                                    args=(UpLimit, LowLimit, Residual_Roof))\n",
    "\n",
    "# Redefining the values:\n",
    "SimplexResult_1 = [WeightedAbsResidual_Out['x'] ]\n",
    "SimplexResult_2 = [AverageAbsResidual_Out['x'] ]\n",
    "\n",
    "print WeightedAbsResidual_Out\n",
    "print '#', SimplexResult_1, ' = value of delta_Mo that minimize the Hubble residual.'\n",
    "print \n",
    "\n",
    "# print AverageAbsResidual_Out\n",
    "# print '#', SimplexResult_2, ' = value of delta_Mo that minimize the Hubble residual.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "     fun: 1.482459899373599e-12\n",
    "    nfev: 33\n",
    "     nit: 32\n",
    " success: True\n",
    "       x: 5.0906660693874514e-07\n",
    "# [5.0906660693874514e-07]  = value of delta_Mo that minimize the Hubble residual.\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# delta_Mo = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Add a value to the theoretical distance modulus so that the weighted \n",
    "# average of the Hubble residual is zero. This is only for the SALT2 Hubble diagram.\n",
    "\n",
    "if BandMax == 'SALT2': # ORIGINAL\n",
    "# if BandMax == 'SALT2' or BandMax == 'Snoopy': # FOR RAISINS OPTICAL FITS\n",
    "    delta_Mo = SimplexResult_1[0] \n",
    "\n",
    "else: \n",
    "    delta_Mo_int1 = np.array([0.])\n",
    "    delta_Mo = delta_Mo_int1[0]\n",
    "    \n",
    "print '# delta_Mo = %s'%delta_Mo\n",
    "# print '# type of variable: %s'%type(delta_Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-- Array of minimum redshift to consider --\n",
    "\n",
    "# zCMB_Min = np.array([0, 0.01])\n",
    "# zCMB_Min_Label = ['z0', 'z001']\n",
    "\n",
    "zCMB_Min = np.array([0])\n",
    "zCMB_Min_Label = ['z0']\n",
    "\n",
    "#--------------------------\n",
    "#   Color array\n",
    "# ColorSamples = [True, False]\n",
    "ColorSamples = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Hubble diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To display where the currently active matplotlibrc file was loaded from, \n",
    "# one can do the following:\n",
    "\n",
    "# import matplotlib\n",
    "#  matplotlib.matplotlib_fname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# u'/Users/arturo/anaconda2/lib/python2.7/site-packages/matplotlib/mpl-data/matplotlibrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fontsizePlot = 10.5\n",
    "\n",
    "# To plot the theoretical (spectroscopic) distance modulus\n",
    "nbins1= 51\n",
    "z1 = np.linspace(xlimPlots[0], xlimPlots[1], nbins1)  \n",
    "mu1 = DistanceMuVector(z1, OmMFix, wFix, HoFix) +delta_Mo # ORIGINAL\n",
    "# FOR RAISINS SNOOPY FIT:\n",
    "# mu1 = DistanceMuVector(z1, OmMFix, wFix, HoFix) -delta_Mo \n",
    "\n",
    "# Count number of SNe for each subsample\n",
    "count_CfA = 0; count_CSP = 0; count_all = 0\n",
    "\n",
    "#---------------------------------\n",
    "# Plot\n",
    "\n",
    "for k in range(len(ColorSamples)): # Loop over the colors\n",
    "    \n",
    "    for j in range(len(zCMB_Min)):  # Loop over the 'zCMB_Min' array\n",
    "\n",
    "        #------- Plotting the data -------\n",
    "        fig = plt.figure()\n",
    "        # fig = plt.figure(figsize=(8,6), dpi=80)\n",
    "        # OLD. fig = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # loop over 'DistanceMu_Good_AfterCutoffs_Main_.txt'\n",
    "        for i in range(len(DistMu_array)): \n",
    "\n",
    "            zzInt = DistMu_array[i][1] # z_CMB for a given SNe\n",
    "            # chi2dofInt = DistMu_array[i][6] # chi2 by d.o.f.\n",
    "            # residInt = abs(DistMu_array[i][5]) # absolute value of the residual value\n",
    "            sampleFlag = DistMu_array[i][7]  # Subsample           \n",
    "                \n",
    "            # Create the variable \"snName\" containing the first 8 \n",
    "            # (or 7) letters of the SNe file name\n",
    "            # I use \"snName\" to compare with the SNe names in \n",
    "            # 'SNeWithCepheidDistances.txt', so that\n",
    "            # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "            try:\n",
    "                if   DistMu_array[i][0][7] == '_': \n",
    "                    snName = DistMu_array[i][0][:7] # To read correctly, e.g., \"sn2011B_\"\n",
    "                elif DistMu_array[i][0][7] != '_':\n",
    "                    # To read correctly, e.g., \"snf20080514-002\":\n",
    "                    if is_number(DistMu_array[i][0][7]): snName = DistMu_array[i][0][:15] \n",
    "                    else: snName = DistMu_array[i][0][:8]  # To read correctly, e.g., \"sn1998bu\"   \n",
    "            except: snName = DistMu_array[i][0][:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "                \n",
    "                \n",
    "            # Make special symbol for SNe with Cepheid.\n",
    "            if snName in ListSNeCepheid['f0']: fmt_int = '*'\n",
    "            else: fmt_int = '.'\n",
    "            \n",
    "            if ColorSamples[k] and KindOfData4HD == 'AllSamples':\n",
    "                # CSP data\n",
    "                if sampleFlag == 2 and zzInt > zCMB_Min[j]:   \n",
    "                    plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                        fmt=fmt_int, color='blue', ms=MyPointSize, \n",
    "                        elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                # CfA data\n",
    "                elif sampleFlag == 1 and zzInt > zCMB_Min[j]: \n",
    "                    plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                        fmt=fmt_int, color='red', ms=MyPointSize, \n",
    "                        elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                # Others data\n",
    "                elif sampleFlag == 3 and zzInt > zCMB_Min[j]: \n",
    "                    plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                        fmt=fmt_int, color='green', ms=MyPointSize, \n",
    "                        elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                    \n",
    "            else:\n",
    "                if zzInt > zCMB_Min[j]:  \n",
    "                    if KindOfData4HD == 'CfA' and sampleFlag == 1:\n",
    "                        plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                            fmt=fmt_int, color='red', ms=MyPointSize, \n",
    "                            elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                        # count_CfA = count_CfA + 1 # Counter\n",
    "                    elif KindOfData4HD == 'CSP'  and sampleFlag == 2:\n",
    "                        plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                            fmt=fmt_int, color='blue', ms=MyPointSize, \n",
    "                            elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                        # count_CSP = count_CSP + 1 # Counter\n",
    "                    elif KindOfData4HD == 'Others'  and sampleFlag == 3:\n",
    "                        plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                            fmt=fmt_int, color='green', ms=MyPointSize, \n",
    "                            elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                    elif KindOfData4HD == 'AllSamples':\n",
    "                        plt.errorbar(zzInt, DistMu_array[i][3], yerr=DistMu_array[i][4], \n",
    "                            fmt=fmt_int, color='black', ms=MyPointSize, \n",
    "                            elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                        # count_all = count_all + 1 # Counter    \n",
    "             \n",
    "        # Plotting the theory line\n",
    "        plt.plot(z1, mu1, color='black')\n",
    "\n",
    "        plt.xlim(xlimPlots)\n",
    "        plt.ylim(ylimPlots)\n",
    "\n",
    "        plt.xlabel('Redshift', fontsize=fontsizePlot)\n",
    "        plt.ylabel(r'Distance modulus $\\mu$', fontsize=fontsizePlot)\n",
    "        \n",
    "        #--- Plot Title ---\n",
    "        if PlotTotalMu == False:\n",
    "            plt.title('Hubble diagram (%s band)'%(BandName), fontsize=fontsizePlot+2)\n",
    "        elif PlotTotalMu == True:\n",
    "            if BandsCombination == 'AllBands':\n",
    "                plt.title('Hubble diagram (all YJHK bands)', fontsize=fontsizePlot+2)\n",
    "            else: plt.title('Hubble diagram (%s bands)'%(BandsCombination), fontsize=fontsizePlot+2)\n",
    "        \n",
    "        # plt.legend(loc='lower right')\n",
    "        # plt.tick_params(labelsize=fontsizePlot)\n",
    "        plt.tick_params(axis='x', labelsize=fontsizePlot)\n",
    "        plt.tick_params(axis='y', labelsize=fontsizePlot+2)        \n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "                \n",
    "        # if   PlotTotalMu == True:  \n",
    "        #     NIRbandsText_1 = BandsCombination+'_'\n",
    "        #     NIRbandsText_2 = BandsCombination+'/'\n",
    "        # elif PlotTotalMu == False: \n",
    "        #     NIRbandsText_1 = ''; NIRbandsText_2 = ''\n",
    "            \n",
    "        if   PlotTotalMu == True:  NIRbandsText = BandsCombination+'_'\n",
    "        elif PlotTotalMu == False: NIRbandsText = ''\n",
    "\n",
    "        if ColorSamples[k] and KindOfData4HD == 'AllSamples':\n",
    "            plt.savefig(DirSaveOutput+'Plot_HD_%s_%s_%s_%s_%s_%s_Color_%s.png'%(\n",
    "                KindOfData4HD, KindOfTemp,\n",
    "                              KindOfTempSubgroup, \n",
    "                                   chi2_dof_Max_Label, residualMax_Label, \n",
    "                                      zCMB_Min_Label[j], NIRbandsText)\n",
    "                             , dpi=ResolutionPlot_HD, format='png'\n",
    "                       )\n",
    "        else:\n",
    "            plt.savefig(DirSaveOutput+'Plot_HD_%s_%s_%s_%s_%s_%s_%s.png'%(\n",
    "                KindOfData4HD, KindOfTemp,\n",
    "                                  KindOfTempSubgroup,\n",
    "                                    chi2_dof_Max_Label, residualMax_Label, \n",
    "                                       zCMB_Min_Label[j], NIRbandsText) \n",
    "                                        , dpi=ResolutionPlot_HD, format='png'\n",
    "                        )\n",
    "        plt.close()\n",
    "\n",
    "# print 'Number SNe from CfA: ', count_CfA\n",
    "# print 'Number SNe from CSP: ', count_CSP\n",
    "# print 'Number SNe from all: ', count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To display where the currently active matplotlibrc file was loaded from, one can do the following:\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.matplotlib_fname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of arrays for mu_residuals.\n",
    "\n",
    "mu_resid_z0_np = np.zeros(len(DistMu_array))\n",
    "sigma2_appMagTBmax_z0_np = np.zeros(len(DistMu_array))\n",
    "sigma2_pec_z0_np = np.zeros(len(DistMu_array))\n",
    "\n",
    "mu_resid_z001 = []\n",
    "sigma2_appMagTBmax_z001 = []\n",
    "sigma2_pec_z001 = []\n",
    "\n",
    "for i in range(len(DistMu_array)): # loop over 'DistanceMu_Good_AfterCutoffs_Main_.txt'\n",
    "    \n",
    "    zcmbInt     = DistMu_array[i][1]  # zcmb\n",
    "    err_zcmbInt = DistMu_array[i][2]  # error_zcmb\n",
    "    mu_resid_z0_np[i]   = DistMu_array[i][5] +delta_Mo  # Delta_mu\n",
    "    \n",
    "    # Create the variable \"snName\" containing the first 8 (or 7) letters of the SNe file name\n",
    "    # I use \"snName\" to compare with the SNe names in 'SNeWithCepheidDistances.txt', so that\n",
    "    # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "    try:\n",
    "        if   DistMu_array[i][0][7] == '_': \n",
    "            snName = DistMu_array[i][0][:7]  # To read correctly, e.g., \"sn2011B_\"\n",
    "        elif DistMu_array[i][0][7] != '_':\n",
    "            # To read correctly, e.g., \"snf20080514-002\":\n",
    "            if is_number(DistMu_array[i][0][7]): snName = DistMu_array[i][0][:15] \n",
    "            else: snName = DistMu_array[i][0][:8]  # To read correctly, e.g., \"sn1998bu\"  \n",
    "    except: snName = DistMu_array[i][0][:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "    \n",
    "    \n",
    "    #--- Determine the uncertainty in distance modulus from the peculiar velocity uncertainty.---\n",
    "    \n",
    "    #-----------   For z > 0: --------------\n",
    "    \n",
    "    if PlotTotalMu == True: # For 'PlotTotalMu' *compute* \"sigma_mu_pecVel\"\n",
    "        if snName in ListSNeCepheid['f0']: \n",
    "            sigma2_pec_z0_np[i] = sigma2_pec(zcmbInt, err_zcmbInt, 0)\n",
    "        else: sigma2_pec_z0_np[i] = sigma2_pec(zcmbInt, err_zcmbInt, vpecFix)\n",
    "    else: # For 'NIRmax', 'Bmax' 'Snoopy', 'SALT2' *reads* \"sigma_mu_pecVel\"\n",
    "        sigma2_pec_z0_np[i] = (DistMu_array[i][11])**2   # (sigma_mu_pecVel)^2\n",
    "    \n",
    "    # Read the apparent-magnitude uncertainty at either T_Bmax or T_NIRmax:\n",
    "    if PlotTotalMu==False and (BandMax == 'NIRmax' or \n",
    "                               BandMax == 'Bmax' or BandMax == 'Bmax_GP' or\n",
    "                               BandMax == 'SALT2' or BandMax == 'Snoopy'):\n",
    "        # error variance of the app mag at TBmax or TNIRmax:\n",
    "        sigma2_appMagTBmax_z0_np[i] = (DistMu_array[i][9])**2  \n",
    "    \n",
    "    \n",
    "    #-----------   For z > 0.01: --------------\n",
    "    \n",
    "    if zcmbInt > 0.01:\n",
    "        mu_resid_z001 += [DistMu_array[i][5]]  # Delta_mu  \n",
    "        \n",
    "        if PlotTotalMu == True:\n",
    "            if snName in ListSNeCepheid['f0']: \n",
    "                sigma2_pec_z001 += [sigma2_pec(zcmbInt, err_zcmbInt, 0)]\n",
    "            else: sigma2_pec_z001 += [sigma2_pec(zcmbInt, err_zcmbInt, vpecFix)]\n",
    "        else:  # For NIRmax', 'Bmax' 'Snoopy', 'SALT2' \n",
    "            sigma2_pec_z001 += [(DistMu_array[i][11])**2]  # (sigma_mu_pecVel)^2        \n",
    "        \n",
    "        # Read the apparent-magnitude uncertanty at either T_Bmax or T_NIRmax:\n",
    "        if PlotTotalMu==False and (BandMax == 'NIRmax' or \n",
    "                                   BandMax == 'Bmax'  or BandMax == 'Bmax_GP' or\n",
    "                                   BandMax == 'SALT2'  or BandMax == 'Snoopy'):\n",
    "            # error variance of the app mag at TBmax or TNIRmax:\n",
    "            sigma2_appMagTBmax_z001 += [(DistMu_array[i][9])**2]  \n",
    "        \n",
    "# Convert the list to np.arrays:\n",
    "mu_resid_z001_np = np.array(mu_resid_z001)\n",
    "sigma2_appMagTBmax_z001_np = np.array(sigma2_appMagTBmax_z001)\n",
    "sigma2_pec_z001_np = np.array(sigma2_pec_z001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma2_appMagTBmax_z0_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma2_appMagTBmax_z001_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print 'Number of SNe with z>0 :', len(mu_resid_z0_np)\n",
    "# print 'Number of SNe with z>0.01 :', len(mu_resid_z001_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 29 29 29\n",
      "# 26 26 26\n"
     ]
    }
   ],
   "source": [
    "# Checking the sized of the arrays: the left and right numbers have to be the same\n",
    "# in a given row printed below.\n",
    "\n",
    "print '#', len(mu_resid_z0_np),   len(sigma2_appMagTBmax_z0_np),   len(sigma2_pec_z0_np)\n",
    "print '#', len(mu_resid_z001_np), len(sigma2_appMagTBmax_z001_np), len(sigma2_pec_z001_np)\n",
    "\n",
    "# 119 119 119\n",
    "# 95 95 95\n",
    "\n",
    "# 63 63 63\n",
    "# 49 49 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -91.622139\n",
      "         Iterations: 13\n",
      "         Function evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -86.810125\n",
      "         Iterations: 13\n",
      "         Function evaluations: 26\n",
      "\n",
      "Best estimated value of sigma^2_Pred (z>0) = [ 0.00678693]\n",
      "Best estimated value of sigma_Pred (z>0) = [ 0.08238281]\n",
      "\n",
      "Best estimated value of sigma^2_Pred (z>0.01) = [ 0.00527893]\n",
      "Best estimated value of sigma_Pred (z>0.01) = [ 0.07265625]\n"
     ]
    }
   ],
   "source": [
    "# Finding the best estimated value for sigma2Pred by minimizing the -2ln(Likelihood) function.\n",
    "\n",
    "# Defining the function to compute the intrinsic dispersion (sigmaPred) instead\n",
    "# of the square of the intrinsic dispersion (sigma2Pred): for the case of determining\n",
    "# the instrisic dispersion.\n",
    "# I obtain an error due to a very small value of sigmaPred, so that during minimizing \n",
    "# the likelihood function to determine sigmaPred, it is sampled some negative values.\n",
    "\n",
    "# Likelihood to determine the intrinsic dispersion\n",
    "# -2ln(Likelihood) function, Eq. (B.6) of Blondin et al 2011\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.6) of Blondin et al 2011\n",
    "def neg2lnLikeFull(sigmaPred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum1 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum1 = (sum1 + np.log(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i]) +  \n",
    "                (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i]) )  \n",
    "    return sum1\n",
    "\n",
    "#----\n",
    "\n",
    "# The truncated version.\n",
    "def neg2lnLike(sigmaPred, mu_resid_np, sigma2_pec_np):\n",
    "    sum1 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum1 = (sum1 + np.log(sigmaPred**2 + sigma2_pec_np[i]) + \n",
    "                (mu_resid_np[i]**2)/(sigmaPred**2 + sigma2_pec_np[i]) ) \n",
    "    return sum1\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "from scipy.optimize import fmin as simplex\n",
    "\n",
    "InitialGuess = 0.15\n",
    "\n",
    "if Method==7 and PlotTotalMu==False and (BandMax == 'NIRmax' or BandMax == 'Bmax' or BandMax == 'Bmax_GP' #):\n",
    "                                         or BandMax == 'SALT2' or BandMax == 'Snoopy'): # ORIGINAL\n",
    "                                         # or BandMax == 'SALT2'): # FOR RAISINS SNOOPY FIT\n",
    "    SimplexResult_z0_2 = simplex(neg2lnLikeFull, InitialGuess, \n",
    "                                   args=(mu_resid_z0_np, sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np))\n",
    "\n",
    "    SimplexResult_z001_2 = simplex(neg2lnLikeFull, InitialGuess, \n",
    "                                   args=(mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np))\n",
    "\n",
    "    \n",
    "elif PlotTotalMu==True: # ORIGINAL\n",
    "# elif PlotTotalMu==True or BandMax == 'Snoopy' or BandMax == 'SALT2': # FOR RAISINS SNOOPY FIT\n",
    "    SimplexResult_z0_2 = simplex(neg2lnLike, InitialGuess, \n",
    "                              args=(mu_resid_z0_np,   sigma2_pec_z0_np))\n",
    "    \n",
    "    SimplexResult_z001_2 = simplex(neg2lnLike, InitialGuess, \n",
    "                              args=(mu_resid_z001_np, sigma2_pec_z001_np))\n",
    "\n",
    "SimplexResult_z0 = SimplexResult_z0_2**2\n",
    "SimplexResult_z001 = SimplexResult_z001_2**2\n",
    "\n",
    "# print 'Best estimated value of sigma_Pred (z>0) =', SimplexResult_z0_2\n",
    "# print 'Best estimated value of sigma_Pred (z>0.01) =', SimplexResult_z001_2\n",
    "\n",
    "print \n",
    "print 'Best estimated value of sigma^2_Pred (z>0) =', SimplexResult_z0\n",
    "print 'Best estimated value of sigma_Pred (z>0) =', SimplexResult_z0_2\n",
    "\n",
    "print \n",
    "print 'Best estimated value of sigma^2_Pred (z>0.01) =', SimplexResult_z001\n",
    "print 'Best estimated value of sigma_Pred (z>0.01) =', SimplexResult_z001_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of sigma^2_pred (z>0) = 1.3e-05\n",
      "Variance of sigma^2_pred (z>0.01) = 1e-05\n",
      "\n",
      "Error_sigma_pred (z>0) = 0.022\n",
      "Error_sigma_pred (z>0.01) = 0.022\n"
     ]
    }
   ],
   "source": [
    "# Computing the uncertainty on sigma_pred\n",
    "\n",
    "# Define the Fisher information matrix, Eq. (B.7) of Blondin et al 2011\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.7) of Blondin et al 2011\n",
    "def FisherFuncFull(sigmaPred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum2 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum2 = (sum2 + (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i])**3 -\n",
    "               1/(2*(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i])**2)  )\n",
    "    return sum2\n",
    "\n",
    "#--------\n",
    "\n",
    "def FisherFunc(sigmaPred, mu_resid_np, sigma2_pec_np):\n",
    "    sum2 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum2 = (sum2 + (mu_resid_np[i]**2)/(sigmaPred**2 + sigma2_pec_np[i])**3 -\n",
    "               1/(2*(sigmaPred**2 + sigma2_pec_np[i])**2)  )\n",
    "    return sum2\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# The variance error of sigma^2_pred:\n",
    "if Method==7 and PlotTotalMu==False and (BandMax == 'NIRmax' or BandMax == 'Bmax' or \n",
    "                                         BandMax == 'Bmax_GP' or\n",
    "                                        BandMax == 'SALT2'  or BandMax == 'Snoopy'):\n",
    "    Var_sigma2_pred_z0 =   1/FisherFuncFull(SimplexResult_z0_2[0],   \n",
    "                                            mu_resid_z0_np,   sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np)\n",
    "    Var_sigma2_pred_z001 = 1/FisherFuncFull(SimplexResult_z001_2[0], \n",
    "                                            mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np)\n",
    "    \n",
    "elif PlotTotalMu==True:\n",
    "    Var_sigma2_pred_z0 =   1/FisherFunc(SimplexResult_z0_2[0],   mu_resid_z0_np,   sigma2_pec_z0_np)\n",
    "    Var_sigma2_pred_z001 = 1/FisherFunc(SimplexResult_z001_2[0], mu_resid_z001_np, sigma2_pec_z001_np)\n",
    "    \n",
    "error_sigma_pred_z0   = np.sqrt(Var_sigma2_pred_z0  /(4*SimplexResult_z0[0]))\n",
    "error_sigma_pred_z001 = np.sqrt(Var_sigma2_pred_z001/(4*SimplexResult_z001[0]))\n",
    "\n",
    "print 'Variance of sigma^2_pred (z>0) =', round(Var_sigma2_pred_z0,6)\n",
    "print 'Variance of sigma^2_pred (z>0.01) =', round(Var_sigma2_pred_z001,6)\n",
    "print '\\nError_sigma_pred (z>0) =', round(error_sigma_pred_z0,3)\n",
    "print 'Error_sigma_pred (z>0.01) =', round(error_sigma_pred_z001,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the intrinsic dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------\n",
      "# Intrinsic dispersion = 0.0823828125 +/- 0.0215651882723\n",
      " \n",
      "# Gaussian Process to compute app mags | Date: 2018-07-23; 00:17 hrs. \n",
      "# IntrinsicDisp = 0.08238 # Y | vpecFix=150 km/s | 0<z<0.04.\n"
     ]
    }
   ],
   "source": [
    "print '#'+'-'*50\n",
    "# print \"# %s band, vpecFix = %s km/s\"%(Band, vpecFix)\n",
    "# print \"# Intrinsic dispersion for the case (0 < z < %s):\"%(zcmb_Max)\n",
    "print '# Intrinsic dispersion = %s +/- %s'%(np.sqrt(SimplexResult_z0[0]), error_sigma_pred_z0)\n",
    "\n",
    "# ------------------------------\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d; %H:%M hrs.\")\n",
    "text_Date   = '# On date: %s \\n'%text_timenow\n",
    "# ------------------------------\n",
    "\n",
    "print ' '\n",
    "print '# %s | Date: %s '%(AppMag_method, text_timenow)\n",
    "print \"# IntrinsicDisp = %.5f # %s | vpecFix=%s km/s | 0<z<%s.\"%(\n",
    "    np.sqrt(SimplexResult_z0[0]), BandName, vpecFix, zcmbUpperLim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Intrinsic dispersion = 0.07517578125 +/- 0.0629356479937\n",
    " \n",
    "# Gaussian Process to compute app mags | Date: 2018-05-02; 17:04 hrs. \n",
    "# IntrinsicDisp = 0.07518 # K | vpecFix=150 km/s | 0<z<0.04.\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Intrinsic dispersion = 0.12017578125 +/- 0.016725821387\n",
    " \n",
    "# Gaussian Process to compute app mags | Date: 2018-02-22; 16:49 hrs. \n",
    "# IntrinsicDisp = 0.12018 # J | vpecFix=150 km/s | 0<z<0.04."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\chi^2_{\\rm d.o.f.}$\n",
    "\n",
    "#### Checking the consistency between the error bars of the residual distance modulus vs the scatter in the Hubble-diagram residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------\n",
      "# Y band | vpecFix = 150 km/s | 0 < z < 0.04\n",
      "# Gaussian Process to compute app mags.\n",
      "# chi^2 = 31.2389298696 | Number of data = 29\n",
      "# chi^2_dof = 1.07720447826\n"
     ]
    }
   ],
   "source": [
    "ratio_int = 0;  \n",
    "\n",
    "for i in range(len(DistMu_array)):\n",
    "    # print i\n",
    "    \n",
    "    mu_resid  = DistMu_array[i][5] +delta_Mo\n",
    "    \n",
    "    if   BandMax == 'Bmax':   IntrinsicDisp_int = np.sqrt(SimplexResult_z0[0])\n",
    "    elif BandMax == 'NIRmax': IntrinsicDisp_int = np.sqrt(SimplexResult_z0[0])\n",
    "    elif BandMax == 'Bmax_GP': IntrinsicDisp_int = np.sqrt(SimplexResult_z0[0])\n",
    "    elif BandMax == 'SALT2':  IntrinsicDisp_int = np.sqrt(SimplexResult_z0[0])\n",
    "    elif BandMax == 'Snoopy': IntrinsicDisp_int = np.sqrt(SimplexResult_z0[0])\n",
    "     \n",
    "    if  PlotTotalMu == False and (BandMax == 'NIRmax' or BandMax == 'Bmax' or \n",
    "                                  BandMax == 'Bmax_GP' or\n",
    "                                  BandMax == 'SALT2'  or BandMax == 'Snoopy'): \n",
    "        sigma_pecVel = DistMu_array[i][11]\n",
    "        error_appMag = DistMu_array[i][9]\n",
    "        ratio_int = ratio_int + ((mu_resid**2) / (error_appMag**2 + \n",
    "                                                  sigma_pecVel**2 + \n",
    "                                                  IntrinsicDisp_int**2) )\n",
    "        \n",
    "        # ratio_int = ratio_int + ((mu_resid**2) / (error_appMag**2 + \n",
    "        #                                         sigma_pecVel**2 ) )\n",
    "    \n",
    "    elif PlotTotalMu == True:  \n",
    "        sigma_pecVel = np.sqrt(sigma2_pec(zcmbInt, err_zcmbInt, vpecFix))\n",
    "        error_mu = DistMu_array[i][4]   # error_mu\n",
    "        ratio_int = ratio_int + ((mu_resid**2) / (error_mu**2 + sigma_pecVel**2) )  \n",
    "    \n",
    "chi2_dof_HD    = ratio_int / len(DistMu_array)\n",
    "\n",
    "\n",
    "print '#'+'-'*40\n",
    "print \"# %s band | vpecFix = %s km/s | 0 < z < %s\"%(BandName, vpecFix, zcmbUpperLim)\n",
    "print '# %s.'%AppMag_method\n",
    "print '# chi^2 =', ratio_int, '| Number of data =', len(DistMu_array)\n",
    "print '# chi^2_dof =', chi2_dof_HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the summary of values to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (BandMax != 'NIRmax' or PlotTotalMu == True):\n",
    "    textfile_1 = open(DirSaveOutput+\"Summary_HDScatter_RMS_.txt\", 'w')\n",
    "\n",
    "    now = datetime.datetime.now() # Read the time and date right now\n",
    "    text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd).\")\n",
    "    text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "    text_Date   = '# On date: %s \\n'%text_timenow\n",
    "    text_script = '# Script used: %s \\n'%NotebookName\n",
    "    text_line = '#'+'-'*50 + '\\n'\n",
    "\n",
    "    textfile_1.write(\"# Summary of the scatter in the Hubble residual \\n\")\n",
    "    textfile_1.write(\"# %s band \\n\"%BandName)\n",
    "\n",
    "    textfile_1.write(text_line)\n",
    "    textfile_1.write(text_Author); textfile_1.write(text_Date); \n",
    "    textfile_1.write(text_script); \n",
    "    textfile_1.write(text_line)\n",
    "\n",
    "    if (BandMax == 'Bmax' and PlotTotalMu == False):\n",
    "        \n",
    "        try: \n",
    "            # This section is for the case that I've used 11.ipynb to compute\n",
    "            # the distance moduli, so that the values above were previously defined\n",
    "            # during the creation of the \"DistanceMu_Good_AfterCutoffs_Main_.txt\"\n",
    "            # text file.\n",
    "            textfile_1.write(text01); textfile_1.write(text1); textfile_1.write(text2);\n",
    "            textfile_1.write(text3); textfile_1.write(text3_0_1); textfile_1.write(text3_3);\n",
    "            textfile_1.write(text3_4); textfile_1.write(text3_5); \n",
    "            textfile_1.write(text_line)\n",
    "            \n",
    "        except:\n",
    "            # This section is for the case that I'm using 11.ipynb just to plot.\n",
    "            text01 = '# Apparent mag data used to construct the Hubble diagram: %s \\n'%KindOfData4HD\n",
    "            text1 = '# Template used: \\n'\n",
    "            text2 = '# %s \\n'%DirTemplate[78:]\n",
    "            text3 = '# Cosmology used to compute residuals: (Omega_M=%r, Omega_L=%r, w=%r, Ho=%r) \\n'%(OmMFix, OmLFix, wFix, HoFix)\n",
    "\n",
    "            text3_0_0 = '# 0.01 < z_cmb < %r \\n'%zcmbUpperLim\n",
    "            text3_0_1 = '# Cutoffs: z_cmb<%r | %r<dm15<%r | %r<EBVhost<%r | EBV_mw<%r | chi2_dof<%r | Residual<%r \\n'%(zcmbUpperLim,\n",
    "                dm15LowerLim,  dm15UpperLim, EBVhostMin, EBVhostMax, EBVMWLim, chi2_dof_Max, residualMax)\n",
    "            text3_3 = '# Phase range used of the template: (%r, %r) days \\n'%(PhaseMinTemp, PhaseMaxTemp)\n",
    "            text3_4 = '# Minimal number of data in LC to be considered for the Hubble diagram: %r \\n'%MinNumOfDataInLC\n",
    "            text3_5 = '# Assumed uncertainty in the peculiar velocity: %r km/s \\n'%vpecFix\n",
    "\n",
    "            textfile_1.write(text01); textfile_1.write(text1); textfile_1.write(text2);\n",
    "            textfile_1.write(text3); textfile_1.write(text3_0_1); textfile_1.write(text3_3);\n",
    "            textfile_1.write(text3_4); textfile_1.write(text3_5); \n",
    "            textfile_1.write(text_line)\n",
    "    \n",
    "    textfile_1.write('# %.5f # = delta_Mo. Valued ADDED to the theoretical distance \\n\\\n",
    "# modulus so that the weighted average of the Hubble residual is zero. \\n'%delta_Mo)\n",
    "        \n",
    "    textfile_1.write('# Intrinsic dispersion for the case (0 < z < %s) and used to obtain the \\n\\\n",
    "# total photometric distance modulus uncertainty: \\n'%zcmbUpperLim)\n",
    "    \n",
    "    textfile_1.write('%14.10f  %.10f  # Intrinsic dispersion and its uncertainty for the case \\\n",
    "0 < z_cmb < %s \\n'%(np.sqrt(SimplexResult_z0[0]), error_sigma_pred_z0, zcmbUpperLim))\n",
    "    textfile_1.write('%14.10f  %.10f  # Intrinsic dispersion and its uncertainty for the case \\\n",
    "0.01 < z_cmb < %s \\n'%(np.sqrt(SimplexResult_z001[0]), error_sigma_pred_z001, zcmbUpperLim))\n",
    "\n",
    "    textfile_1.write('%14.10f  %.10f  # (AverageAbsMag_atMax, err_AverageAbsMag_atMax) \\\n",
    "    \\n'%(Average_NIRAbsMag_TBmax, error_Average_NIRAbsMag_TBmax))\n",
    "\n",
    "    textfile_1.write('%14.10f  %-12.0f  # (chi^2, Number of SNe) for the case (0 < z < %s) \\\n",
    "    \\n'%(ratio_int, len(DistMu_array), zcmbUpperLim))\n",
    "    textfile_1.write('%14.10f  0             # chi^2_dof \\n'%chi2_dof_HD)\n",
    "\n",
    "    textfile_1.write(text_line)\n",
    "    textfile_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# textfile_1.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS (z > 0, color=True): 0.13682 (0.10807 WRMS)\n",
      " \n",
      "RMS CSP (z > 0, color=True): 0.13682 (0.10807 WRMS)\n",
      " \n",
      "RMS (z > 0, color=True): 0.13682 (0.10807 WRMS)\n",
      " \n",
      "RMS CSP (z > 0, color=True): 0.13682 (0.10807 WRMS)\n",
      " \n",
      "\n",
      " # All done.\n"
     ]
    }
   ],
   "source": [
    "# Plot error bars of the Hubble residuals?\n",
    "# This option sometimes is useful to better visualize any trend\n",
    "# in the Hubble residual plot. \n",
    "# NOTE: This only apply to Y-band data, I need to implement the\n",
    "# instruction in the other NIR bands.\n",
    "# plotErrorBars_list = [True, False]\n",
    "plotErrorBars_list = [True]\n",
    "\n",
    "fontsizePlot = 10.5\n",
    "\n",
    "# Label the outliers.\n",
    "# In one plot, print the name of those SNe with one value in \"label_array\"\n",
    "# and in another plot, print those SNe with the other value.\n",
    "label_array = np.array([0.23, 3])\n",
    "\n",
    "#---------------------------------\n",
    "#    Text files\n",
    "\n",
    "if   PlotTotalMu == False: textfile7 = open(DirSaveOutput+'Verbose_%s.txt'%BandName, 'w')\n",
    "elif PlotTotalMu == True:  textfile7 = open(DirSaveOutput+'Verbose_%s.txt'%BandsCombination, 'w')   \n",
    "\n",
    "# Append data to the already existing file 'Summary_HDScatter_.txt', but\n",
    "# if the file doesn't exist then create it:\n",
    "textfile_8 = open(DirSaveOutput+'Summary_HDScatter_RMS_.txt', 'a')\n",
    "\n",
    "textfile7.write('# RMS SUMMARY \\n')\n",
    "textfile7.write(' \\n')\n",
    "\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd)\")\n",
    "text_line = '#'+'-'*50 + '\\n'\n",
    "\n",
    "# Add a value to the theoretical distance modulus so that the weighted \n",
    "# average of the Hubble residual is zero. This is only for the SALT2 Hubble diagram.\n",
    "textfile7.write('%s # = delta_Mo. Valued ADDED to the theoretical distance modulus so that \\\n",
    "the weighted average of the Hubble residual is zero: \\n'%delta_Mo)\n",
    "\n",
    "textfile7.write('%s band | vpecFix = %s km/s \\n'%(BandName, vpecFix))\n",
    "textfile7.write(' \\n')\n",
    "\n",
    "textfile7.write('intrinsic dispersion sigma_Pred (z>0): %r +/- %r \\n'%\n",
    "                (np.sqrt(SimplexResult_z0[0]), error_sigma_pred_z0))\n",
    "textfile7.write('intrinsic dispersion sigma_Pred (z>0.01): %r +/- %r \\n'%\n",
    "                (np.sqrt(SimplexResult_z001[0]), error_sigma_pred_z001))\n",
    "\n",
    "textfile7.write('\\n Checking the consistency between the error bars of the residual \\\n",
    "distance modulus vs the scatter in the Hubble-diagram residual plot (case 0 < z < %s) \\n'%zcmbUpperLim)\n",
    "textfile7.write('chi^2 = %s | Number of data = %s \\n'%(ratio_int, len(DistMu_array)))\n",
    "textfile7.write('chi^2_dof = %s \\n'%chi2_dof_HD)\n",
    "textfile7.write(text_line)\n",
    "\n",
    "textfile7.write('# Data table created by: Arturo Avelino \\n')\n",
    "textfile7.write('# On date: %s \\n'%text_timenow)\n",
    "textfile7.write('# Script used: %s \\n'%NotebookName)\n",
    "textfile7.write(text_line)\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "#    Theoretical values\n",
    "\n",
    "# Array plot the -theoretical- (spectroscopic) distance modulus \n",
    "nbins1= 151\n",
    "# old. z1 = np.linspace(xlimPlots[0], xlimPlots[1], nbins1)\n",
    "z1 = np.linspace(xlimPlots[0], xlimPlots[1]+0.05, nbins1)\n",
    "mu0 = np.zeros(len(z1))\n",
    "\n",
    "# Array to plot the -theoretical- peculiar velocity uncertanty\n",
    "# old. error_z1 = 0.001 * np.ones(len(z1)) # 0.001 is the average error_zcmb in Andy's compilation\n",
    "error_z1 = err_zCMB_fix * np.ones(len(z1))\n",
    "sigma_pec_np = np.sqrt(sigma2_pec(z1, error_z1, vpecFix))\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "# Plot\n",
    "\n",
    "# Loop over plotting or not the error bars.\n",
    "for i3 in range(len(plotErrorBars_list)):\n",
    "    \n",
    "    plotErrorBars = plotErrorBars_list[i3]\n",
    "\n",
    "    for ll in label_array: # Loop to label the name of the outlier SNe\n",
    "        labelOutlierLim = ll # Label the outliers with residual >= this quantity \n",
    "\n",
    "        for k in range(len(ColorSamples)): # Loop over the colors\n",
    "\n",
    "            for j in range(len(zCMB_Min)):  # Loop over the 'zCMB_Min' array\n",
    "\n",
    "                # fig = plt.figure(figsize=(12, 8))\n",
    "                fig = plt.figure()\n",
    "\n",
    "                # Plotting theory: Flat Universe\n",
    "                plt.plot(z1, mu0, color='black', lw=2, alpha=0.5)\n",
    "\n",
    "                # Plot the peculiar velocity uncertainty\n",
    "\n",
    "                plt.plot(z1, sigma_pec_np, ls='--', color='black')\n",
    "                plt.plot(z1, -sigma_pec_np, ls='--', color='black') \n",
    "\n",
    "\n",
    "                # Reset all the values\n",
    "                # To be used to compute the RMS:\n",
    "                mu_resid_all = []; error_mu_all = []; sigma2_pec_all=[];\n",
    "                mu_resid_CSP = []; error_mu_CSP = []; sigma2_pec_CSP=[]; countCSP = 0;\n",
    "                mu_resid_CfA = []; error_mu_CfA = []; sigma2_pec_CfA=[]; countCfA = 0;\n",
    "                mu_resid_Others = []; error_mu_Others = []; sigma2_pec_Others=[]; countOthers = 0\n",
    "\n",
    "                mu_resid_all_np = 0;  error_mu_all_np = 0; sigma2_pec_all_np=0;\n",
    "                mu_resid_CSP_np = 0;  error_mu_CSP_np = 0; sigma2_pec_CSP_np=0;\n",
    "                mu_resid_CfA_np = 0;  error_mu_CfA_np = 0; sigma2_pec_CfA_np=0;\n",
    "                mu_resid_Others_np = 0;  error_mu_Others_np = 0; sigma2_pec_Others_np=0;\n",
    "\n",
    "                rms = 0;     ratio = 0;     rms_weight =0;\n",
    "                rms_CfA = 0; ratio_CfA = 0; rms_CfA_weight =0;\n",
    "                rms_CSP = 0; ratio_CSP = 0; rms_CSP_weight =0;\n",
    "                rms_Others = 0; ratio_Others = 0; rms_Others_weight =0;\n",
    "\n",
    "                #----  Plotting the data ----\n",
    "\n",
    "                for i in range(len(DistMu_array)): # loop over 'DistanceMu_Good_AfterCutoffs_Main_.txt'\n",
    "\n",
    "                    zzInt = DistMu_array[i][1] # z_CMB for a given SNe\n",
    "                    err_zz= DistMu_array[i][2] # z_CMB for a given SNe\n",
    "                    residInt = abs(DistMu_array[i][5]) # residual (absolute value)\n",
    "                    error_mu = DistMu_array[i][4] # uncertainty in the distance modulus, mu.\n",
    "                    mu_resid_int = DistMu_array[i][5]+delta_Mo # Delta_mu  \n",
    "\n",
    "                    # Create the variable \"snName\" containing the first 8 (or 7) letters of the SNe file name\n",
    "                    # I use \"snName\" to compare with the SNe names in 'SNeWithCepheidDistances.txt', so that\n",
    "                    # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "\n",
    "                    # ORIGINAL:\n",
    "                    try:\n",
    "                        if   DistMu_array[i][0][7] == '_': \n",
    "                            snName = DistMu_array[i][0][:7] # To read correctly, e.g., \"sn2011B_\"\n",
    "                        elif DistMu_array[i][0][7] != '_':\n",
    "                            # To read correctly, e.g., \"snf20080514-002\":\n",
    "                            if is_number(DistMu_array[i][0][7]): snName = DistMu_array[i][0][:15] \n",
    "                            else: snName = DistMu_array[i][0][:8]  # To read correctly, e.g., \"sn1998bu\"   \n",
    "                    except: snName = DistMu_array[i][0][:6] # To read correctly, e.g., \"sn2011B\"\n",
    "\n",
    "                    # FOR RAISINS SNOOPY\n",
    "                    # snName = DistMu_array[i][0]\n",
    "\n",
    "                    # ORIGINAL\n",
    "                    SNname = DistMu_array[i][0][2:8]\n",
    "                    # FOR RAISINS SNOOPY\n",
    "                    # SNname = DistMu_array[i][0]\n",
    "\n",
    "                    if PlotTotalMu == True:\n",
    "                        if snName in ListSNeCepheid['f0']: \n",
    "                            sigma2_pec_int = sigma2_pec(zzInt, err_zz, 0)\n",
    "                        else: sigma2_pec_int = sigma2_pec(zzInt, err_zz, vpecFix)\n",
    "                    else:\n",
    "                        sigma2_pec_int = (DistMu_array[i][11])**2  # (sigma_mu_pecVel)^2            \n",
    "\n",
    "                    sampleFlag = DistMu_array[i][7] # Distinguish between CfA or CSP\n",
    "\n",
    "\n",
    "                    # Make special symbol for SNe with Cepheid.\n",
    "                    if snName in ListSNeCepheid['f0']: fmt_int = '*'\n",
    "                    else: fmt_int = '.'\n",
    "\n",
    "                    #====================================================\n",
    "\n",
    "                    if ColorSamples[k] and KindOfData4HD == 'AllSamples':\n",
    "                        #--- CSP data:\n",
    "                        if sampleFlag == 2 and zzInt > zCMB_Min[j]: \n",
    "                            if plotErrorBars:\n",
    "                                plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                    fmt=fmt_int, color='blue', ms=MyPointSize, \n",
    "                                    elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                            else:\n",
    "                                plt.plot(zzInt, mu_resid_int,\n",
    "                                    marker=fmt_int, color='blue', ms=MyPointSize)\n",
    "\n",
    "                            mu_resid_CSP += [mu_resid_int]\n",
    "                            error_mu_CSP += [error_mu]\n",
    "                            sigma2_pec_CSP += [sigma2_pec_int]\n",
    "                            countCSP = countCSP + 1\n",
    "\n",
    "                            # Label the SNe with residual larger than a given value.\n",
    "                            if residInt > labelOutlierLim:\n",
    "                                plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                         fontsize=(fontsizePlot-4), color='blue')\n",
    "\n",
    "                        #--- CfA data\n",
    "                        elif sampleFlag == 1 and zzInt > zCMB_Min[j]: \n",
    "                            plt.errorbar(zzInt, mu_resid_int, yerr=error_mu,\n",
    "                                fmt=fmt_int, color='red',  ms=MyPointSize, \n",
    "                                elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                            mu_resid_CfA += [mu_resid_int]\n",
    "                            error_mu_CfA += [error_mu]\n",
    "                            sigma2_pec_CfA += [sigma2_pec_int]\n",
    "                            countCfA = countCfA + 1\n",
    "\n",
    "                            # Label the SNe with residual larger than a given value.\n",
    "                            if residInt > labelOutlierLim: \n",
    "                                plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                         fontsize=(fontsizePlot-4), color='red')\n",
    "\n",
    "                        #--- Others data\n",
    "                        elif sampleFlag == 3 and zzInt > zCMB_Min[j]: \n",
    "                            plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                fmt=fmt_int, color='green', ms=MyPointSize, \n",
    "                                elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                            mu_resid_Others += [mu_resid_int]\n",
    "                            error_mu_Others += [error_mu]\n",
    "                            sigma2_pec_Others += [sigma2_pec_int]\n",
    "                            countOthers = countOthers + 1\n",
    "\n",
    "                            # Label the SNe with residual larger than a given value.\n",
    "                            if residInt > labelOutlierLim: \n",
    "                                plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                         fontsize=(fontsizePlot-4), color='green')\n",
    "\n",
    "                    else:\n",
    "                        if  zzInt > zCMB_Min[j]: \n",
    "\n",
    "                            if KindOfData4HD == 'CfA' and sampleFlag == 1:\n",
    "                                plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                    fmt=fmt_int, color='red', ms=MyPointSize, \n",
    "                                elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                                mu_resid_all += [mu_resid_int]\n",
    "                                error_mu_all += [error_mu]\n",
    "                                sigma2_pec_all += [sigma2_pec_int]\n",
    "                                # Label the SNe with residual larger than a given value.\n",
    "                                if residInt > labelOutlierLim: \n",
    "                                    plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                             fontsize=(fontsizePlot-4), color='red')                        \n",
    "\n",
    "                            elif KindOfData4HD == 'CSP'  and sampleFlag == 2:\n",
    "                                plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                    fmt=fmt_int, color='blue', ms=MyPointSize, \n",
    "                                    elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                                mu_resid_all += [mu_resid_int]\n",
    "                                error_mu_all += [error_mu]\n",
    "                                sigma2_pec_all += [sigma2_pec_int]\n",
    "                                # Label the SNe with residual larger than a given value.\n",
    "                                if residInt > labelOutlierLim: \n",
    "                                    plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                             fontsize=(fontsizePlot-4), color='blue') \n",
    "\n",
    "                            elif KindOfData4HD == 'Others'  and sampleFlag == 3:\n",
    "                                plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                    fmt=fmt_int, color='green', ms=MyPointSize, \n",
    "                                    elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                                mu_resid_all += [mu_resid_int]\n",
    "                                error_mu_all += [error_mu]\n",
    "                                sigma2_pec_all += [sigma2_pec_int]\n",
    "                                # Label the SNe with residual larger than a given value.\n",
    "                                if residInt > labelOutlierLim: \n",
    "                                    plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                             fontsize=(fontsizePlot-4), color='green') \n",
    "\n",
    "                            elif KindOfData4HD == 'AllSamples':\n",
    "                                plt.errorbar(zzInt, mu_resid_int, yerr=error_mu, \n",
    "                                    fmt=fmt_int, color='black', ms=MyPointSize, \n",
    "                                    elinewidth=MyLineWidth, capsize=MyCapeSize)\n",
    "                                mu_resid_all += [mu_resid_int]\n",
    "                                error_mu_all += [error_mu]\n",
    "                                sigma2_pec_all += [sigma2_pec_int]\n",
    "                                # Label the SNe with residual larger than a given value.\n",
    "                                if residInt > labelOutlierLim: \n",
    "                                    plt.text(zzInt+0.0005, mu_resid_int-0.015, SNname, \n",
    "                                             fontsize=(fontsizePlot-4), color='black')                             \n",
    "\n",
    "                if ColorSamples[k] and KindOfData4HD == 'AllSamples':  \n",
    "                    mu_resid_all = mu_resid_CSP + mu_resid_CfA + mu_resid_Others  \n",
    "                    error_mu_all = error_mu_CSP + error_mu_CfA + error_mu_Others\n",
    "                    sigma2_pec_all = sigma2_pec_CSP + sigma2_pec_CfA + sigma2_pec_Others\n",
    "\n",
    "                #----- Computing the (RMS, WRMS) residuals --------\n",
    "\n",
    "                mu_resid_all_np = np.array(mu_resid_all)\n",
    "                error_mu_all_np = np.array(error_mu_all)\n",
    "                sigma2_pec_all_np = np.array(sigma2_pec_all)\n",
    "                if len(mu_resid_all) > 0:\n",
    "                    rms = np.sqrt(np.mean(np.square(mu_resid_all)))\n",
    "                    ratio = np.square(mu_resid_all_np)/(np.square(error_mu_all_np)+\n",
    "                                                        sigma2_pec_all_np)\n",
    "                    rms_weight = np.sqrt(np.sum(ratio)/np.sum(1/(np.square(error_mu_all_np)+\n",
    "                                                                 sigma2_pec_all_np)))\n",
    "                    textfile7.write('RMS all (z > %r) = %r (%r WRMS) \\n'%(zCMB_Min[j], \n",
    "                                            round(rms,5), round(rms_weight,5)))\n",
    "                    textfile7.write('   \\n')\n",
    "\n",
    "                    if ll == label_array[0] and k == 0:\n",
    "                        textfile_8.write(\"%.10f  %.10f # (wRMS, RMS) for all. Case: z > %s.\\n\"%\n",
    "                                     (rms_weight, rms, zCMB_Min[j]))\n",
    "                    print 'RMS (z > %r, color=%s): %r (%r WRMS)'%(zCMB_Min[j], \n",
    "                            ColorSamples[k], round(rms,5), round(rms_weight,5))\n",
    "                    print ' '\n",
    "\n",
    "                mu_resid_CSP_np = np.array(mu_resid_CSP) \n",
    "                error_mu_CSP_np = np.array(error_mu_CSP)\n",
    "                sigma2_pec_CSP_np = np.array(sigma2_pec_CSP)\n",
    "                if len(mu_resid_CSP) > 0:\n",
    "                    rms_CSP = np.sqrt(np.mean(np.square(mu_resid_CSP)))\n",
    "                    ratio_CSP = np.square(mu_resid_CSP_np)/(np.square(error_mu_CSP_np)+\n",
    "                                                            sigma2_pec_CSP_np)\n",
    "                    rms_CSP_weight = np.sqrt(np.sum(ratio_CSP)/np.sum(1/(np.square(error_mu_CSP_np)+\n",
    "                                                                         sigma2_pec_CSP_np)))\n",
    "                    textfile7.write('RMS CSP (z > %r) = %r (%r WRMS) \\n'%(zCMB_Min[j], \n",
    "                                            round(rms_CSP,5), round(rms_CSP_weight, 5)))\n",
    "                    textfile7.write('   \\n')\n",
    "                    if ll == label_array[0] and k == 0:\n",
    "                        textfile_8.write(\"%.10f  %.10f # (wRMS, RMS) for CSP subsample. Case: z > %s.\\n\"%\n",
    "                                     (rms_CSP_weight, rms_CSP, zCMB_Min[j]))\n",
    "                    print 'RMS CSP (z > %r, color=%s): %r (%r WRMS)'%(zCMB_Min[j], \n",
    "                            ColorSamples[k], round(rms_CSP,5), round(rms_CSP_weight, 5))\n",
    "                    print ' '\n",
    "\n",
    "                mu_resid_CfA_np = np.array(mu_resid_CfA)\n",
    "                error_mu_CfA_np = np.array(error_mu_CfA)\n",
    "                sigma2_pec_CfA_np = np.array(sigma2_pec_CfA)\n",
    "                if len(mu_resid_CfA) > 0:\n",
    "                    rms_CfA = np.sqrt(np.mean(np.square(mu_resid_CfA)))\n",
    "                    ratio_CfA = np.square(mu_resid_CfA_np)/(np.square(error_mu_CfA_np)+\n",
    "                                                            sigma2_pec_CfA_np)\n",
    "                    rms_CfA_weight = np.sqrt(np.sum(ratio_CfA)/np.sum(1/(np.square(error_mu_CfA_np)+\n",
    "                                                                         sigma2_pec_CfA_np)))\n",
    "                    textfile7.write('RMS CfA (z > %r) = %r (%r WRMS) \\n'%(zCMB_Min[j], \n",
    "                                            round(rms_CfA,5), round(rms_CfA_weight,5)))\n",
    "                    textfile7.write('   \\n')\n",
    "                    if ll == label_array[0] and k == 0:\n",
    "                        textfile_8.write(\"%.10f  %.10f # (wRMS, RMS) for CfA subsample. Case: z > %s.\\n\"%\n",
    "                                     (rms_CfA_weight, rms_CfA, zCMB_Min[j]))\n",
    "                    print 'RMS CfA (z > %r, color=%s): %r (%r WRMS)'%(zCMB_Min[j], \n",
    "                            ColorSamples[k], round(rms_CfA,5), round(rms_CfA_weight,5))\n",
    "\n",
    "                mu_resid_Others_np = np.array(mu_resid_Others)\n",
    "                error_mu_Others_np = np.array(error_mu_Others)\n",
    "                sigma2_pec_Others_np = np.array(sigma2_pec_Others)\n",
    "                if len(mu_resid_Others) > 0:\n",
    "                    rms_Others = np.sqrt(np.mean(np.square(mu_resid_Others)))\n",
    "                    ratio_Others = np.square(mu_resid_Others_np)/(np.square(error_mu_Others_np)+\n",
    "                                                                  sigma2_pec_Others_np)\n",
    "                    rms_Others_weight = np.sqrt(np.sum(ratio_Others)/np.sum(1/(np.square(error_mu_Others_np)+\n",
    "                                                                               sigma2_pec_Others_np)))\n",
    "                    textfile7.write('RMS Others (z > %r) = %r (%r WRMS)  \\n'%(zCMB_Min[j], \n",
    "                                            round(rms_Others,5), round(rms_Others_weight,5)))\n",
    "                    textfile7.write('   \\n')\n",
    "                    if ll == label_array[0] and k == 0:\n",
    "                        textfile_8.write(\"%.10f  %.10f # (wRMS, RMS) for Others subsamples. Case: z > %s.\\n\"%\n",
    "                                     (rms_Others_weight, rms_Others, zCMB_Min[j]))\n",
    "                    print 'RMS Others (z > %r, color=%s): %r (%r WRMS)'%(zCMB_Min[j], \n",
    "                            ColorSamples[k], round(rms_Others,5), round(rms_Others_weight,5))\n",
    "\n",
    "                #-----------------------------------------------------\n",
    "\n",
    "                if plot_raisins == True: plt.xlim(0.2, 0.65) \n",
    "                else: plt.xlim(xlimPlots) \n",
    "                plt.ylim(ylimPlots_residual)\n",
    "\n",
    "                #--- Labeling ----------------------------------------\n",
    "\n",
    "                # PRINTING THE WEIGHTED RMSs AND INTRINSIC DISPERSION IN THE PLOTS.\n",
    "\n",
    "                RightPlotLimitText_1 = 0.0135 # old: 0.05, 0.057\n",
    "                if WRMS_label == True and j==0:     \n",
    "                    plt.text(xlimPlots[0]+RightPlotLimitText_1-0.005, ylimPlots_residual[1]-0.15, \n",
    "                             r'%r SN, RMS=%.2f (%.2f WRMS), $\\sigma_{\\rm int}$=%.3f$\\pm$%.3f'%(len(mu_resid_all),\n",
    "                            rms, rms_weight, np.sqrt(SimplexResult_z0), error_sigma_pred_z0), \n",
    "                             fontsize=fontsizePlot-2)  \n",
    "\n",
    "                elif WRMS_label == True and j==1:\n",
    "                    plt.text(xlimPlots[0]+RightPlotLimitText_1-0.005, ylimPlots_residual[1]-0.15, \n",
    "                             r'%r SN, RMS=%.2f (%.2f WRMS), $\\sigma_{\\rm int}$=%.3f$\\pm$%.3f'%(len(mu_resid_all),\n",
    "                            rms, rms_weight, np.sqrt(SimplexResult_z001), error_sigma_pred_z001), \n",
    "                             fontsize=fontsizePlot-2)                              \n",
    "\n",
    "\n",
    "                RightPlotLimitText_2 = 0.0235 # old: 0.04, 0.047\n",
    "                if WRMS_label == True and WRMS_subsamples==True and ColorSamples[k] and KindOfData4HD == 'AllSamples':  \n",
    "                    if plot_raisins == True:\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[1]-0.25, \n",
    "                                 '%r DES, RMS=%.2f (%.2f WRMS)'%(countCfA, rms_CfA,rms_CfA_weight),\n",
    "                                 color='red', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[1]-0.35, \n",
    "                                 '%r PS1, RMS=%.2f (%.2f WRMS)'%(countCSP, rms_CSP, rms_CSP_weight), \n",
    "                                 color='blue', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+(RightPlotLimitText_2-0.001), ylimPlots_residual[1]-0.45, \n",
    "                                 '%r Others, RMS=%.2f (%.2f WRMS)'%(countOthers, rms_Others,rms_Others_weight), \n",
    "                                 color='green', fontsize=fontsizePlot-4)\n",
    "                    else: # plot the low-z:\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[1]-0.25, \n",
    "                                 '%r CfA, RMS=%.2f (%.2f WRMS)'%(countCfA, rms_CfA,rms_CfA_weight), \n",
    "                                 color='red', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[1]-0.35, \n",
    "                                 '%r CSP, RMS=%.2f (%.2f WRMS)'%(countCSP, rms_CSP, rms_CSP_weight), \n",
    "                                 color='blue', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+(RightPlotLimitText_2-0.001), ylimPlots_residual[1]-0.45, \n",
    "                                 '%r Others, RMS=%.2f (%.2f WRMS)'%(countOthers, rms_Others,rms_Others_weight), \n",
    "                                 color='green', fontsize=fontsizePlot-4) \n",
    "\n",
    "\n",
    "                RightPlotLimitText_3 = 0.0235  # old: 0.032  \n",
    "                # -NO- PRINTING THE WEIGHTED RMSs IN THE PLOTS.\n",
    "                if WRMS_label == False and RMS_simple==True:\n",
    "\n",
    "                    plt.text(xlimPlots[0]+RightPlotLimitText_3, ylimPlots_residual[1]- 0.15, # 0.12, \n",
    "                             '%r SN, RMS=%r'%(len(mu_resid_all),\n",
    "                            round(rms,3)), fontsize=fontsizePlot-4)\n",
    "\n",
    "                    if ColorSamples[k] and KindOfData4HD == 'AllSamples':\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_3, ylimPlots_residual[1]- 0.25, # 0.20, \n",
    "                                 '%r CfA, RMS=%r'%(countCfA, round(rms_CfA,3)), \n",
    "                                 color='red', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_3, ylimPlots_residual[1]- 0.35, # 0.28, \n",
    "                                 '%r CSP, RMS=%r'%(countCSP, round(rms_CSP,3)), \n",
    "                                 color='blue', fontsize=fontsizePlot-4)\n",
    "                        plt.text(xlimPlots[0]+RightPlotLimitText_3, ylimPlots_residual[1]- 0.45, # 0.36, \n",
    "                                 '%r Others, RMS=%r'%(countOthers, round(rms_Others,3)), \n",
    "                                 color='green', fontsize=fontsizePlot-4)\n",
    "\n",
    "                #-----------------------------------------------\n",
    "\n",
    "                #--- Print the peculiar velocity, method, chi2_dof: -------\n",
    "\n",
    "                # Peculiar velocity uncertainty\n",
    "                plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[0]+0.35, \n",
    "                         r'$\\sigma_{\\rm pec}$ = %r km/s'%(vpecFix), color='black', \n",
    "                         fontsize=fontsizePlot-3)\n",
    "\n",
    "                # chi2_dof: Consistency between error bars and scatter in the data\n",
    "                if zCMB_Min[j] == 0:\n",
    "                    plt.text(xlimPlots[0]+RightPlotLimitText_2, ylimPlots_residual[0]+0.25, \n",
    "                         r'$\\chi^2_{\\rm d.o.f.}$ = %.2f'%chi2_dof_HD, color='black', \n",
    "                             fontsize=fontsizePlot-3)\n",
    "\n",
    "                # Method to determine distance moduli\n",
    "                plt.text(xlimPlots[0]+RightPlotLimitText_2-0.01, ylimPlots_residual[0]+0.15, \n",
    "                         r'%s'%AppMag_method, color='black', fontsize=fontsizePlot-3)\n",
    "\n",
    "                #---- Label title and axes ------\n",
    "\n",
    "                if   BandMax == 'NIRmax': BandMaxText = '$T_{%s}$ max'%BandName \n",
    "                elif BandMax == 'Bmax' or BandMax == 'Bmax_GP':   BandMaxText = '$T_B$ max'\n",
    "                elif BandMax == 'Snoopy': BandMaxText = 'Snoopy'\n",
    "                elif BandMax == 'SALT2':  BandMaxText = 'SALT2'\n",
    "\n",
    "\n",
    "                plt.xlabel('Redshift', fontsize=fontsizePlot)\n",
    "                plt.ylabel(r'$\\mu - \\mu_{\\rm \\Lambda CDM}$', fontsize=fontsizePlot)            \n",
    "\n",
    "                #--- Plot Title ---\n",
    "\n",
    "                if PlotTotalMu == False:\n",
    "                    plt.title('%s-band Hubble Residual from %s'%(BandName, BandMaxText), \n",
    "                              fontsize=fontsizePlot+2)\n",
    "\n",
    "                elif PlotTotalMu == True:\n",
    "                    if BandsCombination == 'AllBands':\n",
    "                        if BandMax == 'Bmax' or BandMax == 'Bmax_GP':\n",
    "                            plt.title('Any YJHK bands Hubble Residual from %s'%(BandMaxText), \n",
    "                                      fontsize=fontsizePlot+2)\n",
    "                        elif BandMax == 'NIRmax':\n",
    "                            plt.title(r'Any YJHK bands Hubble Residual from $T_{\\rm NIR}$ max', \n",
    "                                      fontsize=fontsizePlot+2)\n",
    "                    else: \n",
    "                        if BandMax == 'Bmax' or BandMax == 'Bmax_GP':\n",
    "                            plt.title('%s bands Hubble Residual from %s'%(\n",
    "                                BandsCombination, BandMaxText), \n",
    "                                      fontsize=fontsizePlot+2)\n",
    "                        elif BandMax == 'NIRmax':\n",
    "                            plt.title(r'%s bands Hubble Residual from $T_{\\rm NIR}$ max'%(\n",
    "                                BandsCombination), fontsize=fontsizePlot+2)\n",
    "\n",
    "                #--- Axes ---\n",
    "                # plt.tick_params(axis='x', labelsize=fontsizePlot)\n",
    "                # plt.tick_params(axis='y', labelsize=fontsizePlot+2)\n",
    "\n",
    "                plt.grid(True)\n",
    "                # plt.tight_layout()\n",
    "\n",
    "                #----- Save the figures --------\n",
    "\n",
    "                # In the file name, append 'text' if the labeling the Hubble diagram outliers:\n",
    "                if labelOutlierLim < 0.7: textLabel = 'label_'\n",
    "                else: textLabel = '' \n",
    "\n",
    "                if   PlotTotalMu == True:  NIRbandsText = BandsCombination+'_'\n",
    "                elif PlotTotalMu == False: NIRbandsText = ''\n",
    "\n",
    "                Append_savetext_1 = '' # reset\n",
    "                if plotErrorBars: Append_savetext_1 = ''\n",
    "                else: Append_savetext_1 = 'NoBars_'\n",
    "\n",
    "                if ColorSamples[k] and KindOfData4HD == 'AllSamples':\n",
    "                    plt.savefig(DirSaveOutput+'Plot_Residual_%s_%s_%s_%s_%s_%s_Color_%s%s%s.png'%(KindOfData4HD, KindOfTemp,\n",
    "                                KindOfTempSubgroup, chi2_dof_Max_Label, residualMax_Label, zCMB_Min_Label[j], \n",
    "                                NIRbandsText, textLabel,Append_savetext_1), dpi=ResolutionPlot_HD)\n",
    "                else:\n",
    "                    plt.savefig(DirSaveOutput+'Plot_Residual_%s_%s_%s_%s_%s_%s_%s%s%s.png'%(KindOfData4HD, KindOfTemp,\n",
    "                                KindOfTempSubgroup, chi2_dof_Max_Label, residualMax_Label, zCMB_Min_Label[j], \n",
    "                                NIRbandsText, textLabel,Append_savetext_1), dpi=ResolutionPlot_HD)\n",
    "\n",
    "                plt.close()\n",
    "        \n",
    "textfile7.close()\n",
    "textfile_8.close()\n",
    "\n",
    "#----------------------\n",
    "\n",
    "print \"\\n # All done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close();plt.close();plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# All done.\n"
     ]
    }
   ],
   "source": [
    "print \"# All done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
