{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubble diagram from Gaussian Processes fitted apparent magnitude\n",
    "\n",
    "I have to run this notebook 3 times:\n",
    "\n",
    "1) The first time to determine:\n",
    "- the apparent magnitudes (and their uncertainties, sigma_m) at t_NIRmax infered from the GP fit\n",
    "- uncertainty in the photometric distance moduli of the SNe sample defined as: \n",
    "    error_mu_photometric^2 = sigma_m^2\n",
    "where sigma_m is the uncertainty in the apparent magnitude at t_Bmax computed in this first run.\n",
    "- the absolute magnitude for each SN from AbsMag = appMag - mu_LCDM(z)\n",
    "- the mean absolute magnitude at t_Bmax, mean_AbsMag, with its standard deviation of the SNe sample. Write down these values in (AverageAbsMag_atMax, err_AverageAbsMag_atMax).\n",
    "\n",
    "Run this notebook until the end of section \"Determining average Absolute magnitude of the sample\".\n",
    "Set: AbsMagFromHisto = False\n",
    "\n",
    "2) The second time to determine:\n",
    "- the photometric distance moduli of the SNe sample defined as mu_photometric = appMag - mean_AbsMag\n",
    "- the intrinsic dispersion of the Hubble-diagram residual, sigma_intrinsic. \n",
    "\n",
    "Run the entire notebook\n",
    "Set: AbsMagFromHisto = True\n",
    "\n",
    "    NOTES\n",
    "- When plotting the Hubble diagram and the residuals plots and computing the intrisic dispersion using 11_DistanceMu_HubbleDiagram_*.ipynb, it is NOT necessary to set the values of (AverageNIRMax_AbsMag, err_AverageNIRMax_AbsMag ) there, because in that section it is not necessary these values.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HoFix = 73.24 # 72  # Hubble constant (km/(s Mpc))\n",
    "# HoFix = 72.78 # # TEMPORAL: value reported by Dhawan et al 2017.\n",
    "\n",
    "vpecFix = 150     # Peculiar velocity. km/s. Options (150, 200, 300, 400)\n",
    "\n",
    "Band = 'K'    # What band to fit:(Y, J, H ,K)\n",
    "\n",
    "# Band to use as the reference peak maximum? Options: (NIRmax, Bmax)\n",
    "# In the low-z paper we use BandMax = 'NIRmax'\n",
    "# Options: (NIRmax, Bmax)\n",
    "BandMax = 'Bmax'\n",
    "\n",
    "# Mean Absolute magnitude determined from histogram of 'appMagTmax_s - mu_s'?:\n",
    "# First run the notebook with this option with setting the value to \"False\" \n",
    "# in order to determine the mean abs mag, then once I get that number, run a \n",
    "# second time the notebook with this option as \"True\" to compute the final \n",
    "# tables and results.\n",
    "# If \"True\" it is generated the final 'DistanceMu_Good_AfterCutoffs_Main_.txt' \n",
    "# text file, otherwise if \"False\" generate temporal text files.\n",
    "\n",
    "AbsMagFromHisto = True  \n",
    "\n",
    "NotebookName = '12_HubbleDiagram_GP.ipynb'\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# zcmb upper cutoff. Options: (0.04, 0.06, 0.09)\n",
    "zcmb_Max = 0.04    \n",
    "\n",
    "#-- EBV cutoff\n",
    "EBVhostMin = -0.4 # -0.4 # host galaxy\n",
    "EBVhostMax = 0.4 # 0.4 # host galaxy. \n",
    "EBVMWLim = 1 # Milky-Way galaxy\n",
    "\n",
    "#-- dm15 cutoff\n",
    "dm15LowerLim = 0.8 # I assume 0.79.\n",
    "dm15UpperLim = 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Characteristics of the fitting for each band\n",
    "\n",
    "# Directory where the \"Settings_GPFit_.txt\" file is located.\n",
    "# From it I read the value of the kernel 'length' hyperparameter.\n",
    "# DirSettings = '/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/\\\n",
    "# 10Compute/TheTemplates/%s_band/Std_filters/2_Selection_FlatPrior/\\\n",
    "# AllSamples_appMag/Goods'%Band\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "# Light-curve types to use to construct the Hubble diagram:\n",
    "# KindOfData4HD = 'CfA'\n",
    "# KindOfData4HD = 'CSP'\n",
    "# KindOfData4HD = 'Others'\n",
    "KindOfData4HD = 'AllSamples'\n",
    "\n",
    "#================================================================\n",
    "\n",
    "#    J band\n",
    " \n",
    "if Band == 'J':\n",
    "\n",
    "    # NOTE: The values of \"AverageAbsMag_atMax\" and \"err_AverageAbsMag_atMax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if BandMax == 'NIRmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   J band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.5451053137;  # 2018-05-02; 16:26 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.150887398253;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values\n",
    "            AverageAbsMag_atMax = -18.5527768929; \n",
    "            err_AverageAbsMag_atMax = 0.143477501392;\n",
    "            \n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range:\n",
    "        MinPhase = -8.5   # restframe days after T_Bmax\n",
    "        MaxPhase = 1   # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = -2.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "    elif BandMax == 'Bmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   J band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.3994883548;  # 2018-06-15; 11:37 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.162741328415;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   J band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.3994883548;  # 2018-06-21; 12:11 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.162741328415;\n",
    "\n",
    "            # ------------------------------\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   J band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.3728286471;  # 2018-06-21; 14:46 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.158568172895;\n",
    "            \n",
    "        elif zcmb_Max == 0.06:\n",
    "            \n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values\n",
    "            AverageAbsMag_atMax = -18.4100281935; \n",
    "            err_AverageAbsMag_atMax = 0.192207626319;\n",
    "            \n",
    "          \n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range. For B max there is not\n",
    "        # a search for the maximum because I've already determine\n",
    "        # the phase = 0 from the optical bands.\n",
    "        MinPhase = -1.   # restframe days after T_Bmax\n",
    "        MaxPhase = 1.  # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = 0.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "#================================================================\n",
    "\n",
    "#    Y band\n",
    "\n",
    "elif Band == 'Y':\n",
    "\n",
    "    # NOTE: The values of \"AverageAbsMag_atMax\" and \n",
    "    # \"err_AverageAbsMag_atMax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if BandMax == 'NIRmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   Y band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.4674939;  # 2018-04-27; 10:56 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.137352303229;\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   Y band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.472060069;  # 2018-05-02; 16:57 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.137443435879;\n",
    "\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "\n",
    "            AverageAbsMag_atMax =  nan; \n",
    "            err_AverageAbsMag_atMax = nan;   \n",
    "            \n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range:\n",
    "        MinPhase = -8.5   # restframe days after T_Bmax\n",
    "        MaxPhase = 1   # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = -2.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "    elif BandMax == 'Bmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   Y band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.2237434118;  # 2018-06-15; 18:35 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.170464542069;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   Y band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.2462580645;  # 2018-06-15; 18:24 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.147293100539;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   Y band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.2390095152;  # 2018-06-21; 12:05 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.148374112903;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   Y band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.2358845862;  # 2018-06-21; 14:48 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.141701608988;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "            \n",
    "            AverageAbsMag_atMax = nan; \n",
    "            err_AverageAbsMag_atMax = nan;\n",
    "\n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range. For B max there is not\n",
    "        # a search for the maximum because I've already determine\n",
    "        # the phase = 0 from the optical bands.\n",
    "        MinPhase = -1.   # restframe days after T_Bmax\n",
    "        MaxPhase = 1.  # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = 0.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "#================================================================\n",
    "\n",
    "#    H band\n",
    "\n",
    "elif Band == 'H':\n",
    "\n",
    "    # NOTE: The values of \"AverageAbsMag_atMax\" and \n",
    "    # \"err_AverageAbsMag_atMax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if BandMax == 'NIRmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   H band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.3117802222;  # 2018-05-02; 16:52 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.115596575531;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "            \n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values.\n",
    "            AverageAbsMag_atMax = nan; \n",
    "            err_AverageAbsMag_atMax = nan;\n",
    "            \n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range:\n",
    "        MinPhase = -8.5   # restframe days after T_Bmax\n",
    "        MaxPhase = 1   # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = -2.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "    elif BandMax == 'Bmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "\n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   H band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.2053968364;  # 2018-06-15; 18:52 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.164454734925;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   H band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.2045271333;  # 2018-06-21; 12:14 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.155052489158;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   H band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.1691600889;  # 2018-06-21; 14:50 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.1197098627;\n",
    "\n",
    "            # ------------------------------\n",
    "            #   H band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.2032561935;  # 2018-06-15; 18:46 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.17116956731;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "            \n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values.\n",
    "            AverageAbsMag_atMax = nan; \n",
    "            err_AverageAbsMag_atMax = nan;  \n",
    "\n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range. For B max there is not\n",
    "        # a search for the maximum because I've already determine\n",
    "        # the phase = 0 from the optical bands.\n",
    "        MinPhase = -1.   # restframe days after T_Bmax\n",
    "        MaxPhase = 1.  # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = 0.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "#================================================================\n",
    "\n",
    "#    K band\n",
    "\n",
    "elif Band == 'K':\n",
    "\n",
    "    # NOTE: The values of \"AverageAbsMag_atMax\" and \n",
    "    # \"err_AverageAbsMag_atMax\" do NOT \n",
    "    # depend on the value of \"vpecFix\".\n",
    "\n",
    "    if BandMax == 'NIRmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "\n",
    "            # ------------------------------\n",
    "            #   K band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.437566;  # 2018-05-01; 17:57 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.247517968355;\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   K band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.4255725333;  # 2018-05-01; 18:26 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.16932820498;\n",
    "            \n",
    "            # ------------------------------\n",
    "            #   K band | Band Max = NIRmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.4352868462;  # 2018-05-02; 17:02 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.17068523975;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "            \n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values.\n",
    "            AverageAbsMag_atMax = nan ; \n",
    "            err_AverageAbsMag_atMax = nan;\n",
    "            \n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range:\n",
    "        MinPhase = -9   # restframe days after T_Bmax\n",
    "        MaxPhase = 1   # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = 0\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff\n",
    "\n",
    "    elif BandMax == 'Bmax':\n",
    "\n",
    "        if zcmb_Max == 0.04:\n",
    "\n",
    "            # ------------------------------\n",
    "            #   K band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.4577185714;  # 2018-06-15; 18:59 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.295218816668;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   K band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.4115202778;  # 2018-06-15; 19:06 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.278908783659;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # OLD\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   K band | Band Max = Bmax | 0 < z < 0.04\n",
    "            # AverageAbsMag_atMax = -18.4516856842;  # 2018-06-21; 12:18 hrs.\n",
    "            # err_AverageAbsMag_atMax = 0.254396549648;\n",
    "            \n",
    "            # ------------------------------\n",
    "            # WATCH OUT: Specific to the GP subsample only!!!\n",
    "            #   K band | Band Max = Bmax | 0 < z < 0.04\n",
    "            AverageAbsMag_atMax = -18.3489594615;  # 2018-06-21; 14:53 hrs.\n",
    "            err_AverageAbsMag_atMax = 0.170252048275;\n",
    "\n",
    "        elif zcmb_Max == 0.06:\n",
    "        \n",
    "            # Using Foley+Cepheid+Special cases  z_CMB values.\n",
    "            AverageAbsMag_atMax = nan ; \n",
    "            err_AverageAbsMag_atMax = nan;\n",
    "\n",
    "        # Find the NIR maximum app mag of the light curve \n",
    "        # in a given rest-frame days range. For B max there is not\n",
    "        # a search for the maximum because I've already determine\n",
    "        # the phase = 0 from the optical bands.\n",
    "        MinPhase = -1.   # restframe days after T_Bmax\n",
    "        MaxPhase = 1.  # restframe days after T_Bmax\n",
    "\n",
    "        # Discard if the maximum is located at phase >= phaseB_atMax_Cutoff:\n",
    "        phaseB_atMax_Cutoff = 0.5\n",
    "\n",
    "        # Ok if the light curve is truncated (instead of a maximum) \n",
    "        # at phaseB =< phaseB_truncatedLC days.\n",
    "        phaseB_truncatedLC = phaseB_atMax_Cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import quad as intquad\n",
    "from shutil import copyfile # To copy/paste data files.\n",
    "\n",
    "import os\n",
    "import glob # To read the name of the files in a given directory\n",
    "\n",
    "\n",
    "#--- Fixed values ---\n",
    "OmMFix = 0.28 # Omega_Matter\n",
    "OmLFix = 0.72 # Omega_Lambda\n",
    "wFix = -1 # Dark energy EoS\n",
    "c = 299792.458  # Speed of light (km/s)\n",
    "cc = 299792.458  # Speed of light (km/s)\n",
    "\n",
    "5+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the name of this ipython notebook\n",
    "To print it in the output text files as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 12_HubbleDiagram_GP.ipynb\n"
     ]
    }
   ],
   "source": [
    "print '#', (NotebookName)\n",
    "# 12_HubbleDiagram_GP_v1_10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "import datetime \n",
    "\n",
    "# Read the time and date now\n",
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 73\n"
     ]
    }
   ],
   "source": [
    "shiftNum = 71\n",
    "\n",
    "#- Function to convert from index to days (phase).\n",
    "def index2day(index):\n",
    "    day = (index-shiftNum)/2.\n",
    "    return day\n",
    "\n",
    "#- Function to convert from days (phase) to index.\n",
    "def day2index(day):\n",
    "    index = 2*day + shiftNum\n",
    "    return index\n",
    "\n",
    "# print 'Testing the functions:', index2day(105), ',', day2index(-11)\n",
    "# Testing the functions: 17.0 , 49\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# Defining the minimal/maximal rows based on the days:\n",
    "\n",
    "MinRow = int(day2index(MinPhase)) # 54 # (53 = -9 days) (54 = -8.5 days)\n",
    "MaxRow = int(day2index(MaxPhase)) # 66 # (75 = 2 days), (66 = -2.5 days), \n",
    "# (65 = -3 days), (64 = -3.5 days), (63 = -4 days)\n",
    "\n",
    "print MinRow, MaxRow\n",
    "# 53 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu_{\\Lambda{\\rm CDM}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the functions work well: 33.0773926577\n"
     ]
    }
   ],
   "source": [
    "# Inverse of the dimensionless Hubble parameter\n",
    "def InvEHubblePar(z, OmM, wde):\n",
    "    \"Dimensionless Hubble parameter\"\n",
    "    InvEHubbleParInt = 1.0/(np.sqrt(OmM*(1.0+z)**3.0 + (1.0-OmM)*(1.+z)**(3.*(1.+wde))))\n",
    "    return InvEHubbleParInt\n",
    "\n",
    "# ---- The luminosity distance ----\n",
    "def LumDistanceVec(z, OmM, wde, Ho):\n",
    "    \"Luminosity distance\"\n",
    "    LumDistanceVecInt = 0.\n",
    "    LumDistanceVecInt = cc*(1.+z)*intquad(InvEHubblePar, 0., z, args=(OmM, wde))[0]/Ho \n",
    "    return LumDistanceVecInt\n",
    "\n",
    "# ---- Distance modulus scalar ----\n",
    "def DistanceMu(z, OmM, wde, Ho):\n",
    "    \"Distance modulus\"     \n",
    "    DistanceMuInt = 5.0*np.log10(LumDistanceVec(z, OmM, wde, Ho)) + 25.0\n",
    "    return DistanceMuInt\n",
    "\n",
    "# ---- Distance modulus Vector ----\n",
    "def DistanceMuVector(z, OmM, wde, Ho):\n",
    "    \"Distance modulus\"     \n",
    "    DistanceMuInt= []\n",
    "    for i in range(len(z)):\n",
    "        DistanceMuInt += [5.0*np.log10(LumDistanceVec(z[i], OmM, wde, Ho)) + 25.0] \n",
    "    return DistanceMuInt\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "ztest1 = 0.01\n",
    "\n",
    "print 'Checking that the functions work well:', DistanceMu(ztest1, OmMFix, wFix, HoFix)\n",
    "# Checking that the functions work well: 33.1141460988 # Ho=72\n",
    "# Checking that the functions work well: 33.0773926577 # Ho=73.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify string or number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Function to identify if a string is an integer number or a letter.\n",
    "# This will be used in the dictionary construction to properly read some SN names.\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Tests\n",
    "print is_number('5'), is_number('e')\n",
    "# True False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the instrinsic dispersion computationÂ¶\n",
    "\n",
    "##### Sigma peculiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052125037354329877"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigma^2_mu from the peculiar velocity uncertainty\n",
    "# This function is used to determine in the sections \"Intrinsic dispersion\" and \"Optical RMS\", to\n",
    "# determine the intrinsic dispersion.\n",
    "\n",
    "def sigma2_pec(zcmb, err_zcmb, vpec):\n",
    "    sigma2_pecInt = ((5/(zcmb*np.log(10)))*np.sqrt((vpec/cc)**2 + err_zcmb**2))**2\n",
    "    return sigma2_pecInt\n",
    "\n",
    "# Test\n",
    "sigma2_pec(0.0109942726, 0.0010420420, 150)\n",
    "# 0.052125037354329877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Likelihood to determine the intrinsic dispersion\n",
    "\n",
    "# -2ln(Likelihood) function\n",
    "# Eq. (B.6) of Blondin et al 2011\n",
    "\n",
    "# 'sigma2Pred' is the square of the intrinsic dispersion.\n",
    "\n",
    "def neg2lnLike(sigma2Pred, mu_resid_np, sigma2_pec_np):\n",
    "    sum1 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum1 = (sum1 + np.log(sigma2Pred + sigma2_pec_np[i]) + \n",
    "                (mu_resid_np[i]**2)/(sigma2Pred + sigma2_pec_np[i]) ) \n",
    "    return sum1\n",
    "\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.6) of Blondin et al 2011\n",
    "def neg2lnLikeFull(sigma2Pred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum1 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum1 = (sum1 + np.log(sigma2_appmagTBmax_np[i] + sigma2Pred + sigma2_pec_np[i]) +  \n",
    "                (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigma2Pred + sigma2_pec_np[i]) )  \n",
    "    return sum1\n",
    "\n",
    "# Test\n",
    "# neg2lnLike(0.15, mu_resid_z0_np, sigma2_pec_z0_np)\n",
    "# -98.297121896077712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Finding the uncertainty in the determination of sigma_int\n",
    "\n",
    "# Define the Fisher information matrix\n",
    "# Eq. (B.7) of Blondin et al 2011\n",
    "\n",
    "def FisherFunc(sigma2Pred, mu_resid_np, sigma2_pec_np):\n",
    "    sum2 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum2 = (sum2 + (mu_resid_np[i]**2)/(sigma2Pred + sigma2_pec_np[i])**3 -\n",
    "               1/(2*(sigma2Pred + sigma2_pec_np[i])**2)  )\n",
    "    return sum2\n",
    "\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.7) of Blondin et al 2011\n",
    "def FisherFuncFull(sigma2Pred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum2 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum2 = (sum2 + (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigma2Pred + sigma2_pec_np[i])**3 -\n",
    "               1/(2*(sigma2_appmagTBmax_np[i] + sigma2Pred + sigma2_pec_np[i])**2)  )\n",
    "    return sum2\n",
    "\n",
    "# Test\n",
    "# FisherFunc(0.049875, mu_resid_z0_np, sigma2_pec_z0_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cepheids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 13 SNe with Cepheid distances in Andy's compilation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sn1981B', 'sn1998aq', 'sn2001el', 'sn2002fk', 'sn2003du',\n",
       "       'sn2005cf', 'sn2007af', 'sn2007sr', 'sn2009ig', 'sn2011by',\n",
       "       'sn2011fe', 'sn2012cg', 'sn2012fr'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DirSNeWithCepheid = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "\n",
    "# From the Cepheid SNe list the only part that I use in the entire\n",
    "# notebook is the first column, i.e., the SN Name column.\n",
    "ListSNeCepheid = np.genfromtxt(DirSNeWithCepheid+\n",
    "                               'SNeWithCepheidDistances.txt', dtype=['S10', \n",
    "                                float,float,float,float,float,float])\n",
    "\n",
    "print \"# %s SNe with Cepheid distances in Andy's compilation.\"%len(ListSNeCepheid['f0'])\n",
    "ListSNeCepheid['f0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining directories\n",
    "\n",
    "MainDir = '/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/10Compute/TheTemplates/'\n",
    "\n",
    "DirGPFits = MainDir+Band+'_band/Std_filters/2_Selection_FlatPrior/%s_appMag_vpec_0/Goods/'%(KindOfData4HD)\n",
    "\n",
    "DirSaveOutput = MainDir+Band+'_band/Std_filters/4_HubbleDiagram_FlatPrior_GP/'+KindOfData4HD+\\\n",
    "'/vpec%s_%s/'%(vpecFix,BandMax)\n",
    "\n",
    "DirSavePlots = DirSaveOutput+'/Plots_GPFits/'\n",
    "\n",
    "#- Force the creation of the directory to save the outputs.\n",
    "#- \"If the subdirectory does not exist then create it\"\n",
    "import os # To use command line like instructions\n",
    "if not os.path.exists(DirSaveOutput): os.makedirs(DirSaveOutput)\n",
    "if not os.path.exists(DirSavePlots): os.makedirs(DirSavePlots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of -AllSamples- SNe with GP fit: 55\n"
     ]
    }
   ],
   "source": [
    "import os # To use command line like instructions\n",
    "import glob # To read the files in my directory\n",
    "\n",
    "# Change the working directory where the data files are located\n",
    "os.chdir(DirGPFits)\n",
    "\n",
    "#--- Reading the data files in the app mag folder \n",
    "if KindOfData4HD == 'CfA':\n",
    "    list_SNe2 = glob.glob('*'+'CfA_'+Band+'.txt')\n",
    "elif KindOfData4HD == 'CSP':\n",
    "    list_SNe2 = glob.glob('*'+'CSP_'+Band+'.txt')\n",
    "elif KindOfData4HD == 'Others':\n",
    "    list_SNe2 = glob.glob('*'+'Others_'+Band+'.txt')\n",
    "elif KindOfData4HD == 'AllSamples':\n",
    "    list_SNe2 = glob.glob('*'+Band+'.txt')\n",
    "\n",
    "\"\"\"\n",
    "#--- Reading the data files in the app mag folder \n",
    "if KindOfData4HD == 'CfA':\n",
    "    list_SNe2 = glob.glob('*'+'CfA_'+Band+'_GP_mean_sigma_Filled.dat')\n",
    "elif KindOfData4HD == 'CSP':\n",
    "    list_SNe2 = glob.glob('*'+'CSP_'+Band+'_GP_mean_sigma_Filled.dat')\n",
    "elif KindOfData4HD == 'Others':\n",
    "    list_SNe2 = glob.glob('*'+'Others_'+Band+'_GP_mean_sigma_Filled.dat')\n",
    "elif KindOfData4HD == 'AllSamples':\n",
    "    list_SNe2 = glob.glob('*'+Band+'_GP_mean_sigma_Filled.dat')\n",
    "\"\"\"\n",
    "\n",
    "print 'Number of -%s- SNe with GP fit: %s'%(KindOfData4HD, len(list_SNe2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Reading: <ListSNe_AppMag_Notes_.txt>\n",
      "# Number of SNe in the list = 13\n",
      "# Number of masked SNe in the list:  0\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------\n",
    "#     CREATE &/or READ THE NAME OF THE SNe FROM THE TEXT FILE\n",
    "\n",
    "# Change the working directory where the data files are located\n",
    "os.chdir(DirSaveOutput)\n",
    "\n",
    "\n",
    "# Reading the data files in that folder \n",
    "Textfiles = glob.glob('ListSNe_AppMag_*.txt')\n",
    "\n",
    "if 'ListSNe_AppMag_Notes_.txt' in Textfiles:\n",
    "    list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_Notes_.txt', dtype=['S35', int])\n",
    "    print '# Reading: <ListSNe_AppMag_Notes_.txt>'\n",
    "    \n",
    "elif 'ListSNe_AppMag_.txt' in Textfiles:\n",
    "    list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_.txt', dtype=['S35', int])\n",
    "    print '# Reading: <ListSNe_AppMag_.txt>'\n",
    "    \n",
    "else: # if ListSNe_AppMag_.txt doesn't exist, then create it and read it.\n",
    "    print '# ListSNe_AppMag_.txt not found. Creating it.'\n",
    "    # Create a list text file with the name of the SNe of the apparent mag LCs.\n",
    "    list_SNe_file = open(DirSaveOutput+'ListSNe_AppMag_.txt', 'w')\n",
    "    list_SNe_file.write('#        SN list with GP fit \\n')\n",
    "    list_SNe_file.write('# Note that these SNe have passed -a broader version- of my cutoffs. \\n')\n",
    "    list_SNe_file.write('# These SNe are ALL those located in: \\n')\n",
    "    list_SNe_file.write('# %s \\n'%DirGPFits)\n",
    "    \n",
    "    #------\n",
    "    now = datetime.datetime.now() # Read the time and date right now\n",
    "    text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd).\")\n",
    "    text_Date   = '# On date: %s \\n'%text_timenow\n",
    "    text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "    text_script = '# Script used: %s \\n'%NotebookName\n",
    "    text_line = '#'+'-'*50 + '\\n'\n",
    "\n",
    "    list_SNe_file.write(text_line); \n",
    "    list_SNe_file.write(text_Author); list_SNe_file.write(text_Date); list_SNe_file.write(text_script);\n",
    "    list_SNe_file.write(text_line);\n",
    "    #------\n",
    "  \n",
    "    # Upload the list of repeated SNe between CfA and CSP\n",
    "    DirRepeatedSNe = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "    RepeatedSNeList = np.genfromtxt(DirRepeatedSNe+'RepeatedSNe_between_CfA_CSP.txt',\n",
    "                                   dtype=['S10', int])\n",
    "    \n",
    "    # Upload the list of SNe to discard from the Hubble diagrams\n",
    "    DirSNeWithIssues = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/MyNotes/'\n",
    "    SNeWithIssuesList = np.genfromtxt(DirRepeatedSNe+'SNeWithIssues.txt',\n",
    "                                   dtype=['S30', 'S150'])\n",
    "    \n",
    "    for name in list_SNe2:\n",
    "        snname_int =    '%s'%name[0:8]\n",
    "        subsample_int = '%s'%name[-9:-6]\n",
    "        # print snname_int, subsample_int\n",
    "        \n",
    "        if snname_int not in SNeWithIssuesList['f0']:\n",
    "            if snname_int not in RepeatedSNeList['f0']:\n",
    "                # SNe to be NO commented:\n",
    "                list_SNe_file.write('%-32s  0 \\n'%name)\n",
    "            \n",
    "            # Comment automatically the repeated SNe.\n",
    "            elif snname_int in RepeatedSNeList['f0']:\n",
    "                for i1 in range(len(RepeatedSNeList['f0'])):\n",
    "                    if snname_int == RepeatedSNeList['f0'][i1]:\n",
    "                        if RepeatedSNeList['f1'][i1] == 1 and subsample_int =='CSP':\n",
    "                            list_SNe_file.write('%-32s    1 ## Repeated. CfA selected. \\n'%name)\n",
    "                        elif RepeatedSNeList['f1'][i1] == 2 and subsample_int =='CfA':\n",
    "                            list_SNe_file.write('%-32s    1 ## Repeated. CSP selected. \\n'%name)\n",
    "                        else:\n",
    "                            list_SNe_file.write('%-32s  0 \\n'%name)\n",
    "                        \n",
    "        elif snname_int in SNeWithIssuesList['f0']:\n",
    "            for i2 in range(len(SNeWithIssuesList['f0'])):\n",
    "                if snname_int == SNeWithIssuesList['f0'][i2]:\n",
    "                    list_SNe_file.write('%-32s    1 ## %s \\n'%(\n",
    "                        name, SNeWithIssuesList['f1'][i2]))\n",
    "\n",
    "    list_SNe_file.write(text_line)\n",
    "    list_SNe_file.write('# %s SNe in total in this list. \\n'%(len(list_SNe2)))\n",
    "    list_SNe_file.close()\n",
    "    \n",
    "    \n",
    "    # old----------\n",
    "    \"\"\" \n",
    "    for name in list_SNe2:\n",
    "        list_SNe_file.write('%-32s  0 \\n'%name)\n",
    "        # list_SNe_file.write(name)\n",
    "        # print name\n",
    "        \n",
    "        \n",
    "    list_SNe_file.write('# Number of SNe in this list = %s \\n'%(len(list_SNe2)))\n",
    "    list_SNe_file.close()\n",
    "    \"\"\"\n",
    "    #------------------------\n",
    "    \n",
    "    # Read the list I've just created:\n",
    "    \n",
    "    list_SNe = np.genfromtxt(DirSaveOutput+'ListSNe_AppMag_.txt', dtype=['S35', int])\n",
    "    print '# Reading: < ListSNe_AppMag_.txt >'\n",
    "    \n",
    "print '# Number of SNe in the list =', len(list_SNe)\n",
    "print '# Number of masked SNe in the list: ', sum(list_SNe['f1'])\n",
    "\n",
    "# ListSNe_AppMag_.txt not found. Creating it.\n",
    "# Number of SNe in the list = 132\n",
    "# Number of masked SNe in the list:  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "\n",
    "#### Compute apparent magnitude and distance modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sn1998bu__U_69_B_9_CfA_K\n",
      "sn2000E__U_5_B_27__Others_K\n",
      "sn2001ba__B_30_V_3_CSP_K\n",
      "sn2001bt__B_22_V_2_Others_K\n",
      "sn2001cz__B_14_V_1_Others_K\n",
      "sn2001el__U_20_B_4_Others_K\n",
      "sn2002dj__U_13_B_1_Others_K\n",
      "sn2005cf__U_36_B_1_CfA_K\n",
      "sn2006D__U_24_B_22_CfA_K\n",
      "sn2008gb__U_5_B_14_CfA_K\n",
      "sn2008hs__U_2_B_15_CfA_K\n",
      "sn2009an__u_prime__CfA_K\n",
      "sn2010ai__B_16_V_2_CfA_K\n",
      " \n",
      "# 13 SNe in this list. \n",
      "# 13 SNe no commented automatically (## or #_). \n",
      "# 0 SNe were commented automatically (## or #_). \n",
      "# Largest upper residual: 0.2855, SNe: sn2009an \n",
      "# Largest lower residual: -0.3605, SNe: sn2001cz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the GP fitting to the apparent magnitude light curves\n",
    "\n",
    "# Create a list of (MJD_NIRmax, appMag_NIRmax, error_appMag_NIRmax), in\n",
    "# addition to some other relevant quantities.\n",
    "os.chdir(DirGPFits)\n",
    "\n",
    "# Mean Absolute magnitude determined from histogram of 'appMagTmax_s - mu_s'?:\n",
    "# If so it is generated the final 'DistanceMu_Good_AfterCutoffs_Main_.txt' text file, otherwise\n",
    "# generate temporal text files.\n",
    "if  AbsMagFromHisto == True: textPrefix = ''; underline = ''\n",
    "else: textPrefix = 'TMP'; underline = '_' # 'TMP' stands for 'temporal' file.\n",
    "\n",
    "file_results = open(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_%s%s.txt'%(textPrefix, underline), 'w')\n",
    "\n",
    "file_results.write('# Apparent magnitudes and distance moduli computed from the GP fit directly. \\n')\n",
    "file_results.write('# <AverageAbsMag_atMax> = %s +/- %s used. \\n'%(AverageAbsMag_atMax, err_AverageAbsMag_atMax))\n",
    "file_results.write('# Peculiar velocity uncertainty assumed: %s km/s  \\n'%vpecFix)\n",
    "file_results.write('# Band used as reference of maximum: %s \\n'%BandMax)\n",
    "file_results.write('# Phase_Bmax range to look for the maximum: Minimum = %s days (%s rows), \\\n",
    "Maximum = %s days (%s rows) \\n'%(MinPhase, MinRow, MaxPhase, MaxRow))\n",
    "file_results.write('# Discard if the maximum is located at phase > phaseB_atMax_Cutoff = %s days. \\n'%phaseB_atMax_Cutoff)\n",
    "file_results.write('# Ok if the light curve is truncated (instead of a maximum) at phaseB =< \\\n",
    "phaseB_truncatedLC = %s days. \\n'%phaseB_truncatedLC)\n",
    "file_results.write('# Upper limit zcmb cutoff = %s \\n'%zcmb_Max) \n",
    "# file_results.write('# Intrinsic dispersion for the case (0 < z < %s) and used to obtain the \\\n",
    "# total photometric distance modulus uncertainty: \\n'%zcmb_Max)\n",
    "# file_results.write('# Intrinsic dispersion = %s \\n'%IntrinsicDisp)\n",
    "\n",
    "file_results.write('# phaseB_truncatedLC = %s days \\n'%phaseB_truncatedLC)\n",
    "file_results.write(\"# \\n\")\n",
    "file_results.write(\"# Cutoffs: \\n\")\n",
    "file_results.write(\"# z_cmb<%s | %s<dm15<%s | %s<EBV_host<%s | EBV_MW<%s \\n\"%(\n",
    "    zcmb_Max,dm15LowerLim, dm15UpperLim, EBVhostMin, EBVhostMax, EBVMWLim))\n",
    "\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd).\")\n",
    "text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "text_Date   = '# On date: %s \\n'%text_timenow\n",
    "text_script = '# Script used: %s \\n'%NotebookName\n",
    "text_line = '#'+'-'*80 + '\\n'\n",
    "\n",
    "file_results.write(text_line)\n",
    "file_results.write(text_Author); file_results.write(text_Date); \n",
    "file_results.write(text_script); \n",
    "file_results.write(text_line)\n",
    "\n",
    "file_results.write('#  SN name                      zcmb          err_zcmb      mu_GP      err_mu_GP \\\n",
    "mu_GP_residual  chi2_dof FlatCode  NIRMax_appMag  ErrNIRMax_appMag   mu_LCDM  sigma_pecInt  NIRMax_AbsMag  \\\n",
    "ErrNIRMax_AbsMag  MJD_NIRmax   err_MJD_Bmax   phaseB_NIRMax  zhelio        err_zhelio       dm15      \\\n",
    "err_dm15   EBVhost  err_EBVhost  EBV_MW    err_EBV_MW  Alamb    err_Alamb   R_F     mu_snoopy  \\\n",
    "err_mu_snoopy    MJD_Bmax     err_MJD_Bmax   BMax_appMag  ErrBMax_appMag \\n')\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "# The loop\n",
    "\n",
    "# Reset variables and arrays\n",
    "countTotal = 0;\n",
    "countCommented = 0; countNoCommented = 0;\n",
    "countCommented_cutoffs = 0;\n",
    "mu_resid_array = []; SNeName_list = [];\n",
    "\n",
    "\n",
    "for name, mask in list_SNe: # Loop over SNe.\n",
    "    # print name\n",
    "    SN_GPfit  = np.genfromtxt(name[:-4]+'_GP_mean_sigma_Filled.dat')\n",
    "    SN_LCdata = np.genfromtxt(name)\n",
    "     \n",
    "    zcmb      = SN_LCdata[0,0] # CMB redshift\n",
    "    err_zcmb  = SN_LCdata[0,1] # CMB redshift\n",
    "    zhelio    = SN_LCdata[0,2] # helio redshift\n",
    "    mu_LCDM   = SN_LCdata[2,2] # distance mu, LCDM\n",
    "    MJD_Bmax  = SN_LCdata[5,0] # MJD at t_Bmax\n",
    "    \n",
    "    # These values are just to be printed in the text file, i.e., they are not used\n",
    "    # for computing anything here.\n",
    "    mu_snoopy     = SN_LCdata[2,0] # distance mu, snoopy\n",
    "    err_mu_snoopy = SN_LCdata[2,1] # error distance mu, snoopy\n",
    "    err_zhelio    = SN_LCdata[0,3] # helio redshift\n",
    "    dm15          = SN_LCdata[1,0] # \n",
    "    err_dm15      = SN_LCdata[1,1] # \n",
    "    EBVhost       = SN_LCdata[4,0] #\n",
    "    err_EBVhost   = SN_LCdata[4,1] #\n",
    "    EBV_MW        = SN_LCdata[3,0] #\n",
    "    err_EBV_MW    = SN_LCdata[3,1] #\n",
    "    err_MJD_Bmax = SN_LCdata[5,1] # MJD at t_Bmax\n",
    "    Alamb      = SN_LCdata[3,2] \n",
    "    err_Alamb  = SN_LCdata[3,3] \n",
    "    R_F        = SN_LCdata[3,4]\n",
    "    \n",
    "    # The sample flag:\n",
    "    sampleFlag = name[-9:-6]\n",
    "    if sampleFlag == \"CfA\": FlatCode = 1\n",
    "    elif sampleFlag == \"CSP\": FlatCode = 2\n",
    "    elif sampleFlag == \"ers\": FlatCode = 3\n",
    "        \n",
    "    #-------- Peculiar velocity uncertainty -----------------       \n",
    "    # Create the variable \"snName\" containing the first 8 (or 7) letters of the SNe file name\n",
    "    # I use \"snName\" to compare with the SNe names in 'SNeWithCepheidDistances.txt', so that\n",
    "    # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "    if   name[7] == '_': snName = name[:7] # To read correctly, e.g., \"sn2011B\"\n",
    "    elif name[7] != '_':\n",
    "        if is_number(name[7]): snName = name[:15] # To read correctly, e.g., \"snf20080514-002\"\n",
    "        else: snName = name[:8]  # To read correctly, e.g., \"sn1998bu\" \n",
    "            \n",
    "    \n",
    "    sigma_pecInt = 0 # Reset its value:\n",
    "    # If this SNe has Cepheid distance, then use vpecFix=0 for it: \n",
    "    if snName in ListSNeCepheid['f0']: sigma_pecInt = np.sqrt(sigma2_pec(zcmb, err_zcmb, 0))\n",
    "    else: sigma_pecInt = np.sqrt(sigma2_pec(zcmb, err_zcmb, vpecFix))\n",
    "\n",
    "    #-------- At B maximum ------------------------------\n",
    "    \n",
    "    BMax_appMag    = SN_GPfit[70,1]  # B-band app mag\n",
    "    ErrBMax_appMag = SN_GPfit[70,2]  # B-band app mag error\n",
    "\n",
    "    if BandMax == 'Bmax':\n",
    "        \n",
    "        appMag_atMax    = BMax_appMag  # B-band app mag        \n",
    "        err_appMag_atMax = ErrBMax_appMag  # B-band app mag error\n",
    "        \n",
    "        phaseB_atMax = 0\n",
    "        MJD_atMax = MJD_Bmax\n",
    "\n",
    "        flag_kindOfMax = 1\n",
    "    \n",
    "    #-------- At NIR maximum ------------------------------\n",
    "    \n",
    "    elif BandMax == 'NIRmax':\n",
    "    \n",
    "        # Find the NIR maximum app mag of the light curve in a given rest-frame days range.\n",
    "        appMag_atMax = min(SN_GPfit[MinRow:MaxRow,1])\n",
    "\n",
    "        # Find the array index of the maximum \n",
    "        IndexNIRMax_appMag = np.where(appMag_atMax == SN_GPfit[MinRow:MaxRow,1])\n",
    "\n",
    "        # phase (relative to B band) of the NIR maximum\n",
    "        phaseB_atMax    = SN_GPfit[MinRow:MaxRow,0][IndexNIRMax_appMag[0][0]] \n",
    "        # NIR maximum apparent mag\n",
    "        # ok, old. NIRMax_appMag2  = SN_GPfit[MinRow:MaxRow,1][IndexNIRMax_appMag[0][0]] \n",
    "        # error_app mag at NIR max\n",
    "        err_appMag_atMax = SN_GPfit[MinRow:MaxRow,2][IndexNIRMax_appMag[0][0]] \n",
    "        \n",
    "        # MJD of the NIR maximum\n",
    "        MJD_atMax = phaseB_atMax*(1+zhelio) + MJD_Bmax\n",
    "        \n",
    "        #--- Distinguishing if the value found is a maximum or is truncated light curves ---\n",
    "        # NIR apparent mag at 1/2 day before t_NIR_max\n",
    "        appMag_BeforeMax = SN_GPfit[MinRow:MaxRow,1][IndexNIRMax_appMag[0][0]-1] \n",
    "        \n",
    "        # If appMag_BeforeMax > 39 then it means that the found maximum is \n",
    "        # actually a truncated light-curve then flag it with the number \"2\", \n",
    "        # otherwise flag it with \"1\" (meaning that it is an actual maximum).\n",
    "        if appMag_BeforeMax < 39 : flag_kindOfMax = 1   # = a maximum.\n",
    "        else: flag_kindOfMax = 2  # = a truncated light curve.\n",
    "        \n",
    "    #-------- Absolute magnitudes at max ------------\n",
    "    \n",
    "    # NIR Absolute magnitude at band max\n",
    "    AbsMag_atMax = appMag_atMax - mu_LCDM  \n",
    "\n",
    "    # Uncertainty in NIR Absolute magnitude at band max.\n",
    "    # This value is not used for computation, I determine its value\n",
    "    # just to write it down in the output text file.\n",
    "    err_AbsMag_atMax = np.sqrt(err_appMag_atMax**2 + sigma_pecInt**2)\n",
    "    \n",
    "    #-------- Photometric distance mu from GP fit ----------------\n",
    " \n",
    "    # Distance modulus from the Gaussian Processes fit at maximum\n",
    "    mu_GP = appMag_atMax - AverageAbsMag_atMax\n",
    "\n",
    "    # Uncertainty in the distance modulus from the Gaussian Processes fit at maximum\n",
    "    # old1. err_mu_GP = np.sqrt(err_appMag_atMax**2 + err_AverageAbsMag_atMax**2 )\n",
    "    # old2. err_mu_GP = np.sqrt(err_appMag_atMax**2 + IntrinsicDisp**2 )\n",
    "    err_mu_GP = err_appMag_atMax\n",
    "\n",
    "    # Residual\n",
    "    mu_GP_residual = mu_GP - mu_LCDM\n",
    "    \n",
    "    #---------- Cutoff and write the results to a data text file ------------------\n",
    "    \n",
    "    # Filter the SNe where there is not LC data at NIR-max or B-max. In the '_GP_mean_sigma_Filled.dat' text\n",
    "    # file I put the value of 40 at those phases.\n",
    "    # Comment the masked SNe in ListSNe_AppMag_.txt:\n",
    "    if mask==0: commentText = ''\n",
    "    else: commentText = '##  ' \n",
    "        \n",
    "    if appMag_atMax<39 and zcmb < zcmb_Max and phaseB_atMax <= phaseB_atMax_Cutoff: \n",
    "        \n",
    "        # Comment the SNe that fail the cutoffs.\n",
    "        if (dm15 >= dm15LowerLim and dm15 <= dm15UpperLim and \n",
    "            EBVhost >= EBVhostMin and EBVhost <= EBVhostMax and \n",
    "            EBV_MW < EBVMWLim):\n",
    "            comment_text_1 = ''\n",
    "            flag_cutoff = 0\n",
    "        else: \n",
    "            comment_text_1 = '#_ '\n",
    "            flag_cutoff = 1\n",
    "            countCommented_cutoffs += 1\n",
    "        \n",
    "        # Text to be written at the end of the line (in the \"Notes\" \n",
    "        # column) about the kind of maximum:\n",
    "        if flag_kindOfMax == 1 and phaseB_atMax <= phaseB_atMax_Cutoff:\n",
    "            comment_text_2 = 'NIR maximum at phase = %s days.'%phaseB_atMax\n",
    "        elif flag_kindOfMax == 2 and phaseB_atMax <= phaseB_truncatedLC:\n",
    "            comment_text_2 = 'LC truncated at phase = %s days.'%phaseB_atMax\n",
    "            \n",
    "        #--- write the data  --->\n",
    "        file_results.write('%s%s%-30s  %.10f  %.10f  %.6f  %.6f    %9.6f        1.0       %.0f       \\\n",
    "%.6f      %.6f         %.6f  %.6f    \\\n",
    "%.6f      %.6f         \\\n",
    "%.6f  %.6f      %10.6f      \\\n",
    "%.9f   %.9f      \\\n",
    "%.6f  %.6f  %9.6f  %.6f    %.6f  %.6f    %.6f  %.6f  %.6f    \\\n",
    "%.6f   %.6f     \\\n",
    "%.6f  %.6f      %.6f    %.6f        # %s \\n'%(commentText, comment_text_1, name[:-4], \n",
    "            zcmb, err_zcmb, mu_GP, err_mu_GP, mu_GP_residual, FlatCode,\n",
    "            appMag_atMax, err_appMag_atMax, mu_LCDM, sigma_pecInt,\n",
    "            AbsMag_atMax, err_AbsMag_atMax,\n",
    "            MJD_atMax, err_MJD_Bmax, phaseB_atMax,\n",
    "\n",
    "            zhelio, err_zhelio,\n",
    "            dm15, err_dm15, EBVhost, err_EBVhost, EBV_MW, err_EBV_MW, Alamb, err_Alamb, R_F,\n",
    "            mu_snoopy, err_mu_snoopy,\n",
    "            MJD_Bmax, err_MJD_Bmax, BMax_appMag, ErrBMax_appMag,\n",
    "            comment_text_2\n",
    "            ))\n",
    "        # <--- write the data ---\n",
    "        \n",
    "        # Add this good SNe to an array to later determine the SN with the\n",
    "        # largest values of distance-modulus residuals, i.e., the outliers.\n",
    "        mu_resid_array += [mu_GP_residual]; \n",
    "        SNeName_list += [snName];\n",
    "        \n",
    "        copyfile(DirGPFits+name[:-4]+'_GP_plot.png', DirSavePlots+name[:-4]+'_GP_plot.png')\n",
    "        print name[:-4]\n",
    "\n",
    "        countTotal = countTotal + 1\n",
    "        if mask==0 and flag_cutoff==0: \n",
    "            countNoCommented = countNoCommented + 1;\n",
    "        else: countCommented = countCommented + 1; \n",
    "            \n",
    "file_results.write(text_line)\n",
    "text_10 = '# %s SNe in this list. \\n'%countTotal\n",
    "text_11 = \"# %s SNe no commented automatically (## or #_). \\n\"%countNoCommented \n",
    "text_12 = \"# %s SNe were commented automatically (## or #_). \\n\"%countCommented \n",
    "text_12_2 = \"# %s SNe were commented automatically because didn't pass the \\\n",
    "cutoffs (#_). \\n\"%countCommented_cutoffs \n",
    "\n",
    "text_13 = '# Largest upper residual: %r, SNe: %s \\n'%(\n",
    "    round(max(mu_resid_array),4), SNeName_list[mu_resid_array.index(max(mu_resid_array))]   )\n",
    "text_14 = '# Largest lower residual: %r, SNe: %s \\n'%(\n",
    "    round(min(mu_resid_array),4),SNeName_list[mu_resid_array.index(min(mu_resid_array))]  )\n",
    "\n",
    "file_results.write(text_10); \n",
    "file_results.write(text_11); file_results.write(text_12); file_results.write(text_12_2);\n",
    "file_results.write(text_13); file_results.write(text_14);\n",
    "\n",
    "print ' '\n",
    "print text_10, text_11, text_12, text_13,text_14\n",
    "\n",
    "file_results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_results.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the datatable I've just created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_.txt >\n",
      "# 13 SNe in this file.\n"
     ]
    }
   ],
   "source": [
    "import os # To use command line like instructions\n",
    "import glob # To read the files in my directory\n",
    "\n",
    "# Change the working directory where the data files are located\n",
    "os.chdir(DirSaveOutput)\n",
    "\n",
    "# Reading the data files in that folder \n",
    "DistanceMuFiles = glob.glob('DistanceMu_Good_AfterCutoffs_Main*.txt')\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# Check if 'DistanceModuli_Notes_.txt' is already there, otherwise read\n",
    "# the 'DistanceModuli_.txt' file.\n",
    "if 'DistanceMu_Good_AfterCutoffs_Main_Notes_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_Notes_.txt', \n",
    "                                 dtype=['S30',\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float])\n",
    "    print '# Reading the file:  < DistanceMu_Good_AfterCutoffs_Main_Notes_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_.txt',\n",
    "                                 dtype=['S30',\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt',\n",
    "                                 dtype=['S30',\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_TMP_Notes_.txt >'\n",
    "    \n",
    "elif 'DistanceMu_Good_AfterCutoffs_Main_TMP_.txt' in DistanceMuFiles:\n",
    "    DistMu_array = np.genfromtxt(DirSaveOutput+'DistanceMu_Good_AfterCutoffs_Main_TMP_.txt',\n",
    "                                 dtype=['S30',\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float,float,float,float,float,float,float,float,\n",
    "                                       float,float,float])\n",
    "    print '# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_TMP_.txt >'\n",
    "else: print '# < DistanceMu_Good_AfterCutoffs_Main_.txt > file not found!!!'\n",
    "\n",
    "print \"# %s SNe in this file.\"%len(DistMu_array)\n",
    "\n",
    "# Reading the file: < DistanceMu_Good_AfterCutoffs_Main_TMP_.txt >\n",
    "# 63 SNe in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining average Absolute magnitude of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting the histogram with the Gaussian estimation\n",
    "\n",
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# best fit of data.\n",
    "# 'norm.fit' simply compute the mean and standard devation of the sample.\n",
    "(AverageAbsMag_atMax, err_AverageAbsMag_atMax) = norm.fit(DistMu_array['f12'])\n",
    "\n",
    "#------ Plot -----------\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(DistMu_array['f12'], 20, normed=True, facecolor='green', alpha=0.5)\n",
    "# n, bins, patches = plt.hist(DistMu_array['f12'], 20, normed=False, facecolor='green', alpha=0.5)\n",
    "\n",
    "\n",
    "# add a 'best fit' Gaussian line\n",
    "y = mlab.normpdf(bins, AverageAbsMag_atMax, err_AverageAbsMag_atMax )\n",
    "l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel(r'$\\hat{m}_{\\rm Bmax} - \\mu_{\\Lambda{\\rm CDM}}$')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(r'Histogram. (mean=%.2f, std dev = %.2f)' %(AverageAbsMag_atMax, err_AverageAbsMag_atMax))\n",
    "\n",
    "plt.grid(True)\n",
    "plt.savefig(DirSaveOutput+'Plot_histo_AbsMag_GP_%s_.png'%vpecFix)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ------------------------------\n",
      "#   K band | Band Max = Bmax | 0 < z < 0.04\n",
      "# AverageAbsMag_atMax = -18.3489594615;  # 2018-06-21; 14:54 hrs.\n",
      "# err_AverageAbsMag_atMax = 0.170252048275;\n"
     ]
    }
   ],
   "source": [
    "# The results that I will use now.\n",
    "# NOTE: This value is independent of what I have assume about \"AverageAbsMag_atMax\" and\n",
    "# \"err_AverageAbsMag_atMax\" at the top of the notebook in the User section because\n",
    "# I've just recomputed it in the cell above.\n",
    "# NOTE: The values of \"AverageAbsMag_atMax\" and \"err_AverageAbsMag_atMax\" do NOT \n",
    "# depend on the value of \"vpecFix\".\n",
    "\n",
    "# ------------------------------\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d; %H:%M hrs.\")\n",
    "text_Date   = '# On date: %s \\n'%text_timenow\n",
    "# ------------------------------\n",
    "\n",
    "print '#', '-'*30\n",
    "print '#  ', Band, 'band | Band Max =', \\\n",
    "BandMax, '| 0 < z <', zcmb_Max\n",
    "# print '# (mean abs mag, std deviation)\\n' \n",
    "# print \"\"\n",
    "\n",
    "print \"# AverageAbsMag_atMax = %s;  # %s\"%(AverageAbsMag_atMax, text_timenow)\n",
    "print \"# err_AverageAbsMag_atMax = %s;\"%(err_AverageAbsMag_atMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse-variance weights array\n",
    "WeightsInvVar = 1/np.square(DistMu_array['f13'])\n",
    "\n",
    "# Inverse-variance weighted average\n",
    "WeightedAbsMag = np.average(DistMu_array['f12'], weights=WeightsInvVar )\n",
    "\n",
    "# Useful definitions to determine the weighted population standard deviation\n",
    "V1 = np.sum(WeightsInvVar)\n",
    "V2 = np.sum(np.square(WeightsInvVar))\n",
    "\n",
    "product2 = 0\n",
    "# Computing the unbiased weighted population standard deviation\n",
    "for i in range(len(DistMu_array['f12'])):\n",
    "    # print i\n",
    "    absMagInt = DistMu_array['f12'][i]\n",
    "    product2 = product2 + WeightsInvVar[i]*(absMagInt-WeightedAbsMag)**2\n",
    "    \n",
    "error_WeightedAbsMag = np.sqrt(product2/(V1 - (V2/V1)))\n",
    "\n",
    "# print 'Weighted Abs Mag =', WeightedAbsMag\n",
    "# print 'Weighted Std dev =', error_WeightedAbsMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "    K band   Pec velocity = 150 km/s. Band Max = Bmax\n",
      "-18.3489594615  = mean abs mag\n",
      "-18.385226 = median\n",
      "-18.3975230883 = Weighted Abs Mag\n",
      "0.0363984567271 = uncertainty in the weighted average\n",
      "0.170252048275 = population standard deviation\n",
      "0.159355693626 = unbiased weighted population standard deviation\n"
     ]
    }
   ],
   "source": [
    "# Compute some other values\n",
    "\n",
    "print '-'*30\n",
    "print '   ', Band, 'band   Pec velocity =', vpecFix, 'km/s. Band Max =', BandMax\n",
    "print np.mean(DistMu_array['f12']), ' = mean abs mag'\n",
    "print np.median(DistMu_array['f12']), '= median' \n",
    "print WeightedAbsMag, '= Weighted Abs Mag'\n",
    "print np.sqrt(1/np.sum(WeightsInvVar) ), '= uncertainty in the weighted average'\n",
    "print np.std(DistMu_array['f12']), '= population standard deviation'\n",
    "print error_WeightedAbsMag, '= unbiased weighted population standard deviation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 0 < z < 0.04\n",
    "\"\"\"\n",
    "\n",
    "------------------------------\n",
    "    J band   Pec velocity = 150 km/s. Band Max = NIRmax\n",
    "-18.566632254  = mean abs mag\n",
    "-18.587673 = median\n",
    "-18.586175105 = Weighted Abs Mag\n",
    "0.0107267650756 = uncertainty in the weighted average\n",
    "0.170036484735 = population standard deviation\n",
    "0.145823909562 = unbiased weighted population standard deviation\n",
    "\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsic dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of arrays for mu_residuals.\n",
    "\n",
    "mu_resid_z0_np = np.zeros(len(DistMu_array))\n",
    "sigma2_appMagTBmax_z0_np = np.zeros(len(DistMu_array))\n",
    "sigma2_pec_z0_np = np.zeros(len(DistMu_array))\n",
    "\n",
    "mu_resid_z001 = []\n",
    "sigma2_appMagTBmax_z001 = []\n",
    "sigma2_pec_z001 = []\n",
    "\n",
    "PlotTotalMu = False # I silence this variable for now.\n",
    "\n",
    "for i in range(len(DistMu_array)): # loop over 'DistanceMu_Good_AfterCutoffs_Main_.txt'\n",
    "    \n",
    "    zcmbInt     = DistMu_array[i][1]  # zcmb\n",
    "    err_zcmbInt = DistMu_array[i][2]  # error_zcmb\n",
    "    mu_resid_z0_np[i]   = DistMu_array[i][5]  # Delta_mu\n",
    "    \n",
    "    \n",
    "    # Create the variable \"snName\" containing the first 8 (or 7) letters of the SNe file name\n",
    "    # I use \"snName\" to compare with the SNe names in 'SNeWithCepheidDistances.txt', so that\n",
    "    # I will not compute a peculiar velocity uncertainty for those SNe.\n",
    "    try:\n",
    "        if   DistMu_array[i][0][7] == '_': \n",
    "            snName = DistMu_array[i][0][:7]  # To read correctly, e.g., \"sn2011B_\"\n",
    "        elif DistMu_array[i][0][7] != '_':\n",
    "            # To read correctly, e.g., \"snf20080514-002\"\n",
    "            if is_number(DistMu_array[i][0][7]): snName = DistMu_array[i][0][:15] \n",
    "            else: snName = DistMu_array[i][0][:8]  # To read correctly, e.g., \"sn1998bu\" \n",
    "    except: snName = DistMu_array[i][0][:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "     \n",
    "    if PlotTotalMu == True:\n",
    "        if snName in ListSNeCepheid['f0']: \n",
    "            sigma2_pec_z0_np[i] = sigma2_pec(zcmbInt, err_zcmbInt, 0)\n",
    "        else: sigma2_pec_z0_np[i] = sigma2_pec(zcmbInt, err_zcmbInt, vpecFix)\n",
    "    else:\n",
    "        sigma2_pec_z0_np[i] = (DistMu_array[i][11])**2   # (sigma_mu_pecVel)^2\n",
    "    \n",
    "    if PlotTotalMu==False: \n",
    "        # error variance of the app mag at TBmax\n",
    "        sigma2_appMagTBmax_z0_np[i] = (DistMu_array[i][9])**2  \n",
    "    \n",
    "    if zcmbInt > 0.01:\n",
    "        mu_resid_z001 += [DistMu_array[i][5]]  # Delta_mu  \n",
    "        \n",
    "        if PlotTotalMu == True:\n",
    "            if snName in ListSNeCepheid['f0']: \n",
    "                sigma2_pec_z001 += [sigma2_pec(zcmbInt, err_zcmbInt, 0)]\n",
    "            else: sigma2_pec_z001 += [sigma2_pec(zcmbInt, err_zcmbInt, vpecFix)]\n",
    "        else:\n",
    "            sigma2_pec_z001 += [(DistMu_array[i][11])**2]  # (sigma_mu_pecVel)^2        \n",
    "        \n",
    "        if PlotTotalMu==False:\n",
    "            # error variance of the app mag at TBmax\n",
    "            sigma2_appMagTBmax_z001 += [(DistMu_array[i][9])**2]  \n",
    "        \n",
    "# Convert the list to np.arrays:\n",
    "mu_resid_z001_np = np.array(mu_resid_z001)\n",
    "sigma2_appMagTBmax_z001_np = np.array(sigma2_appMagTBmax_z001)\n",
    "sigma2_pec_z001_np = np.array(sigma2_pec_z001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print 'Number of SNe with z>0 :', len(mu_resid_z0_np)\n",
    "# print 'Number of SNe with z>0.01 :', len(mu_resid_z001_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 13 13 13\n",
      "# 7 7 7\n"
     ]
    }
   ],
   "source": [
    "# Checking the sized of the arrays: the left and right numbers have to be the same\n",
    "# in a given row printed below.\n",
    "\n",
    "print '#', len(mu_resid_z0_np),   len(sigma2_appMagTBmax_z0_np),   len(sigma2_pec_z0_np)\n",
    "print '#', len(mu_resid_z001_np), len(sigma2_appMagTBmax_z001_np), len(sigma2_pec_z001_np)\n",
    "\n",
    "# 63 63 63\n",
    "# 49 49 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -30.412303\n",
      "         Iterations: 10\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -15.588611\n",
      "         Iterations: 6\n",
      "         Function evaluations: 12\n",
      " \n",
      "Best estimated value of sigma^2_Pred (z>0) = [ 0.01033594]\n",
      "Best estimated value of sigma_Pred (z>0) = [ 0.10166581]\n",
      " \n",
      "Best estimated value of sigma^2_Pred (z>0.01) = [ 0.02179688]\n",
      "Best estimated value of sigma_Pred (z>0.01) = [ 0.14763765]\n"
     ]
    }
   ],
   "source": [
    "# Finding the best estimated value for sigma2Pred by \n",
    "# minimizing the -2ln(Likelihood) function\n",
    "\n",
    "from scipy.optimize import fmin as simplex\n",
    "\n",
    "Method=7 # I silence this variable for now.\n",
    "\n",
    "InitialGuess = 0.15**2\n",
    "\n",
    "if Method==7 and PlotTotalMu==False:\n",
    "    SimplexResult_z0 = simplex(neg2lnLikeFull, InitialGuess, \n",
    "                               args=(mu_resid_z0_np, sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np))\n",
    "    SimplexResult_z001 = simplex(neg2lnLikeFull, InitialGuess, \n",
    "                                 args=(mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np))\n",
    "\n",
    "else:\n",
    "    SimplexResult_z0 = simplex(neg2lnLike, InitialGuess, \n",
    "                               args=(mu_resid_z0_np, sigma2_pec_z0_np))\n",
    "    SimplexResult_z001 = simplex(neg2lnLike, InitialGuess, \n",
    "                                 args=(mu_resid_z001_np, sigma2_pec_z001_np))\n",
    "\n",
    "\n",
    "print ' '\n",
    "print 'Best estimated value of sigma^2_Pred (z>0) =', SimplexResult_z0\n",
    "print 'Best estimated value of sigma_Pred (z>0) =', np.sqrt(SimplexResult_z0)\n",
    "print ' '\n",
    "print 'Best estimated value of sigma^2_Pred (z>0.01) =', SimplexResult_z001\n",
    "print 'Best estimated value of sigma_Pred (z>0.01) =', np.sqrt(SimplexResult_z001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPECIAL CASE:\n",
    "\n",
    "\"\"\" \n",
    "# When the intrinsic dispersion is very close to zero.\n",
    "\n",
    "# Finding the best estimated value for sigma2Pred by \n",
    "# minimizing the -2ln(Likelihood) function\n",
    "\n",
    "\n",
    "# Defining the function to compute the intrinsic dispersion (sigmaPred) instead\n",
    "# of the square of the intrinsic dispersion (sigma2Pred): for the case of determining\n",
    "# the instrisic dispersion from total distance modulus of YJHK band only and 0.01<z<0.06,\n",
    "# I obtain an error due to a very small value of sigmaPred, so that during minimizing \n",
    "# the likelihood function to determine sigmaPred, it is sampled some negative values.\n",
    "\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.6) of Blondin et al 2011\n",
    "def neg2lnLikeFull_2(sigmaPred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum1 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum1 = (sum1 + np.log(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i]) +  \n",
    "                (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i]) )  \n",
    "    return sum1\n",
    "\n",
    "#-------------------------------\n",
    "from scipy.optimize import fmin as simplex\n",
    "\n",
    "SimplexResult_z0_a = simplex(neg2lnLikeFull_2, 0.15, \n",
    "                               args=(mu_resid_z0_np, sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np))\n",
    "\n",
    "SimplexResult_z001_a = simplex(neg2lnLikeFull_2, 0.15, \n",
    "                               args=(mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np))\n",
    "\n",
    "\n",
    "SimplexResult_z001 = SimplexResult_z0_a**2\n",
    "SimplexResult_z001 = SimplexResult_z001_a**2\n",
    "\n",
    "print 'Best estimated value of sigma_Pred (z>0) =', SimplexResult_z0_a\n",
    "print 'Best estimated value of sigma_Pred (z>0.01) =', SimplexResult_z001_a\n",
    "\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of sigma^2_pred (z>0) = 0.000126\n",
      "Variance of sigma^2_pred (z>0.01) = 0.000426\n",
      "\n",
      "Error_sigma_pred (z>0) = 0.055\n",
      "Error_sigma_pred (z>0.01) = 0.07\n"
     ]
    }
   ],
   "source": [
    "# Computing the uncertainty on sigma_pred\n",
    "\n",
    "# The variance error of sigma^2_pred:\n",
    "\n",
    "if Method==7 and PlotTotalMu==False:\n",
    "    Var_sigma2_pred_z0 =   1/FisherFuncFull(SimplexResult_z0[0],   \n",
    "                                            mu_resid_z0_np,   sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np)\n",
    "    Var_sigma2_pred_z001 = 1/FisherFuncFull(SimplexResult_z001[0], \n",
    "                                            mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np)\n",
    "else:\n",
    "    Var_sigma2_pred_z0 =   1/FisherFunc(SimplexResult_z0[0],   mu_resid_z0_np,   sigma2_pec_z0_np)\n",
    "    Var_sigma2_pred_z001 = 1/FisherFunc(SimplexResult_z001[0], mu_resid_z001_np, sigma2_pec_z001_np)\n",
    "\n",
    "error_sigma_pred_z0   = np.sqrt(Var_sigma2_pred_z0  /(4*SimplexResult_z0[0]))\n",
    "error_sigma_pred_z001 = np.sqrt(Var_sigma2_pred_z001/(4*SimplexResult_z001[0]))\n",
    "\n",
    "print 'Variance of sigma^2_pred (z>0) =', round(Var_sigma2_pred_z0,6)\n",
    "print 'Variance of sigma^2_pred (z>0.01) =', round(Var_sigma2_pred_z001,6)\n",
    "print '\\nError_sigma_pred (z>0) =', round(error_sigma_pred_z0,3)\n",
    "print 'Error_sigma_pred (z>0.01) =', round(error_sigma_pred_z001,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPECIAL CASE:\n",
    "\n",
    "\"\"\" \n",
    "# Computing the uncertainty on sigma_pred\n",
    "\n",
    "\n",
    "\n",
    "# When the intrinsic dispersion is very close to zero.\n",
    "\n",
    "# For the case of using a normalized template. This is the full Eq. (B.7) of Blondin et al 2011\n",
    "def FisherFuncFull_2(sigmaPred, mu_resid_np, sigma2_pec_np, sigma2_appmagTBmax_np):\n",
    "    sum2 = 0\n",
    "    for i in range(len(mu_resid_np)):\n",
    "        sum2 = (sum2 + (mu_resid_np[i]**2)/(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i])**3 -\n",
    "               1/(2*(sigma2_appmagTBmax_np[i] + sigmaPred**2 + sigma2_pec_np[i])**2)  )\n",
    "    return sum2\n",
    "\n",
    "#-------------------------------------------------\n",
    "\n",
    "if Method==7 and PlotTotalMu==False:\n",
    "    Var_sigma2_pred_z0 =   1/FisherFuncFull_2(SimplexResult_z0_a[0],   \n",
    "                                            mu_resid_z0_np,   sigma2_pec_z0_np, sigma2_appMagTBmax_z0_np)\n",
    "    Var_sigma2_pred_z001 = 1/FisherFuncFull_2(SimplexResult_z001_a[0], \n",
    "                                            mu_resid_z001_np, sigma2_pec_z001_np, sigma2_appMagTBmax_z001_np)\n",
    "    \n",
    "error_sigma_pred_z0   = np.sqrt(Var_sigma2_pred_z0  /(4*SimplexResult_z0_a[0]**2))\n",
    "error_sigma_pred_z001 = np.sqrt(Var_sigma2_pred_z001/(4*SimplexResult_z001_a[0]**2))\n",
    "\n",
    "print 'Variance of sigma^2_pred (z>0) =', round(Var_sigma2_pred_z0,6)\n",
    "print 'Variance of sigma^2_pred (z>0.01) =', round(Var_sigma2_pred_z001,6)\n",
    "print '\\nError_sigma_pred (z>0) =', round(error_sigma_pred_z0,3)\n",
    "print 'Error_sigma_pred (z>0.01) =', round(error_sigma_pred_z001,3)\n",
    "\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPECIAL CASE:\n",
    "\n",
    "\"\"\" \n",
    "# Setting by hand the intrinsic dispersion to zero when it is negative and very close to zero\n",
    "\n",
    "SimplexResult_z0 = [0]\n",
    "\n",
    "SimplexResult_z0[0] = 0\n",
    "error_sigma_pred_z0 = 0\n",
    "\n",
    "\"\"\" \n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the intrinsic dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------\n",
      "# Intrinsic dispersion = 0.101665812838 +/- 0.0553092193199\n",
      " \n",
      "# Date: 2018-06-21; 14:54 hrs. \n",
      "# IntrinsicDisp = 0.10167 # K | vpecFix=150 km/s | 0<z<0.04.\n"
     ]
    }
   ],
   "source": [
    "print '#'+'-'*50\n",
    "# print \"# %s band, vpecFix = %s km/s\"%(Band, vpecFix)\n",
    "# print \"# Intrinsic dispersion for the case (0 < z < %s):\"%(zcmb_Max)\n",
    "print '# Intrinsic dispersion = %s +/- %s'%(np.sqrt(SimplexResult_z0[0]), \n",
    "                                            error_sigma_pred_z0)\n",
    "\n",
    "# ------------------------------\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d; %H:%M hrs.\")\n",
    "# ------------------------------\n",
    "\n",
    "print ' '\n",
    "print '# Date: %s '%(text_timenow)\n",
    "print \"# IntrinsicDisp = %.5f # %s | vpecFix=%s km/s | 0<z<%s.\"%(\n",
    "    np.sqrt(SimplexResult_z0[0]), Band, vpecFix, zcmb_Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# Intrinsic dispersion = 0.103380365641 +/- 0.0181455651003\n",
    " \n",
    "# Date: 2018-02-22; 17:53 hrs. \n",
    "# IntrinsicDisp = 0.10338 # J | vpecFix=150 km/s | 0<z<0.04.\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Intrinsic dispersion = 0.170408516513 +/- 0.0363568720916\n",
    " \n",
    "# Date: 2018-02-22; 22:10 hrs. \n",
    "# IntrinsicDisp = 0.17041 # Y | vpecFix=150 km/s | 0<z<0.04."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the consistency between the error bars of the residual distance modulus vs the scatter in the Hubble-diagram residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------\n",
      "# K band | vpecFix = 150 km/s | 0 < z < 0.04\n",
      "# chi^2 = 11.1715555172 | Number of data = 13\n",
      "# chi^2_dof = 0.859350424402\n"
     ]
    }
   ],
   "source": [
    "ratio_int = 0;  \n",
    "\n",
    "for i in range(len(DistMu_array)):\n",
    "    # print i\n",
    "    \n",
    "    mu_resid     = DistMu_array[i][5]\n",
    "    error_appMag = DistMu_array[i][9]\n",
    "    sigma_pecVel = DistMu_array[i][11]\n",
    "        \n",
    "    ratio_int = ratio_int + ((mu_resid**2) / (error_appMag**2 + \n",
    "                            sigma_pecVel**2 + SimplexResult_z0[0]) )    \n",
    "    \n",
    "chi2_dof_HD    = ratio_int / len(DistMu_array)\n",
    "\n",
    "\n",
    "print '#'+'-'*40\n",
    "print \"# %s band | vpecFix = %s km/s | 0 < z < %s\"%(Band, vpecFix, zcmb_Max)\n",
    "print '# chi^2 =', ratio_int, '| Number of data =', len(DistMu_array)\n",
    "print '# chi^2_dof =', chi2_dof_HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# J band | vpecFix = 150 km/s | 0 < z < 0.04\n",
    "# chi^2 = 57.9577533241 | Number of data = 63\n",
    "# chi^2_dof = 0.919964338478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the summary of values to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textfile_1 = open(DirSaveOutput+\"Summary_HDScatter_RMS_.txt\", 'w')\n",
    "\n",
    "now = datetime.datetime.now() # Read the time and date right now\n",
    "text_timenow = now.strftime(\"%Y-%m-%d (yyyy-mm-dd).\")\n",
    "text_Author = '# Data table created by: Arturo Avelino \\n'\n",
    "text_Date   = '# On date: %s \\n'%text_timenow\n",
    "text_script = '# Script used: %s \\n'%NotebookName\n",
    "text_line = '#'+'-'*50 + '\\n'\n",
    "\n",
    "textfile_1.write(\"# Summary of the scatter in the Hubble residual \\n\")\n",
    "textfile_1.write(\"# %s band \\n\"%Band)\n",
    "\n",
    "textfile_1.write(text_line)\n",
    "textfile_1.write(text_Author); textfile_1.write(text_Date); \n",
    "textfile_1.write(text_script); \n",
    "textfile_1.write(text_line)\n",
    "\n",
    "textfile_1.write('# Apparent magnitudes and distance moduli computed from the GP fit directly. \\n')\n",
    "textfile_1.write('# Peculiar velocity uncertainty assumed: %s km/s  \\n'%vpecFix)\n",
    "textfile_1.write('# Band used as reference of maximum: %s \\n'%BandMax)\n",
    "textfile_1.write('# Phase_Bmax range to look for the maximum: Minimum = %s days (%s rows), \\\n",
    "Maximum = %s days (%s rows) \\n'%(MinPhase, MinRow, MaxPhase, MaxRow))\n",
    "textfile_1.write('# Discard if the maximum is located at phase > \\\n",
    "phaseB_atMax_Cutoff = %s days. \\n'%phaseB_atMax_Cutoff)\n",
    "textfile_1.write('# Ok if the light curve is truncated (instead of a maximum) at phaseB =< \\\n",
    "phaseB_truncatedLC = %s days. \\n'%phaseB_truncatedLC)\n",
    "textfile_1.write('# phaseB_truncatedLC = %s days \\n'%phaseB_truncatedLC)\n",
    "textfile_1.write('# Upper limit zcmb cutoff = %s \\n'%zcmb_Max) \n",
    "\n",
    "textfile_1.write(text_line)\n",
    "textfile_1.write('# Intrinsic dispersion for the case (0 < z < %s) and used to obtain the \\n\\\n",
    "# total photometric distance modulus uncertainty: \\n'%zcmb_Max)\n",
    "\n",
    "textfile_1.write('%14.10f  %.10f  # Intrinsic dispersion and its uncertainty for the case \\\n",
    "0 < z_cmb < %s \\n'%(np.sqrt(SimplexResult_z0[0]), error_sigma_pred_z0, zcmb_Max))\n",
    "\n",
    "# Sometimes I get error when computing SimplexResult_z001, these lines help\n",
    "# to alleviate the writting of the file.\n",
    "# ---->>\n",
    "try: \n",
    "    intDisp001 = np.sqrt(SimplexResult_z001[0])\n",
    "    err_intDisp001 = error_sigma_pred_z001\n",
    "except:\n",
    "    print \"Hola\"\n",
    "    \n",
    "if intDisp001>0.:\n",
    "    textfile_1.write('%14.10f  %.10f  # Intrinsic dispersion and its uncertainty for the case \\\n",
    "# 0.01 < z_cmb < %s \\n'%(intDisp001, err_intDisp001, zcmb_Max))\n",
    "else:\n",
    "    textfile_1.write('-1         -1  # Intrinsic dispersion and its uncertainty for the case \\\n",
    "# 0.01 < z_cmb < %s \\n')\n",
    "# <<-----\n",
    "\n",
    "textfile_1.write('%14.10f  %.10f  # (AverageAbsMag_atMax, err_AverageAbsMag_atMax) \\n'%(\n",
    "       AverageAbsMag_atMax, err_AverageAbsMag_atMax))\n",
    "\n",
    "textfile_1.write('%14.10f  %-12.0f  # (chi^2, Number of SNe) for the case (0 < z < %s) \\\n",
    "\\n'%(ratio_int, len(DistMu_array), zcmb_Max))\n",
    "textfile_1.write('%14.10f  0             # chi^2_dof \\n'%chi2_dof_HD)\n",
    "\n",
    "textfile_1.write(text_line)\n",
    "textfile_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the app-mag Hubble diagram from (zcmb, $m_{\\rm NIR max}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# All done.\n"
     ]
    }
   ],
   "source": [
    "fontsizePlot = 16\n",
    "\n",
    "nbins1= 51\n",
    "z1 = np.linspace(0.01, 0.1, nbins1)\n",
    "mu1 = DistanceMuVector(z1, OmMFix, wFix, HoFix)\n",
    "\n",
    "#---------------------------------\n",
    "# Plot\n",
    "\n",
    "fig = plt.figure() \n",
    "\n",
    "# Plotting the data\n",
    "plt.errorbar(DistMu_array['f1'], DistMu_array['f8'], yerr=DistMu_array['f9'], \n",
    "             fmt='.', color=[1,0,0],  ms=10, elinewidth=1.5, capthick=1.5)\n",
    "\n",
    "# Plotting the theory\n",
    "# plt.plot(z1, mu1, color='black')\n",
    "\n",
    "# plt.xlim(xlimPlots)\n",
    "plt.xlim(0,0.06)\n",
    "\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel('Redshift', fontsize=fontsizePlot)\n",
    "plt.ylabel('Apparent magnitude', fontsize=fontsizePlot)\n",
    "plt.title('Hubble diagram, %s band'%Band)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(DirSaveOutput+'Plot_HubbleDiagram_appMag_%s_.png'%vpecFix, format='png')\n",
    "plt.close()\n",
    "\n",
    "#----------------------\n",
    "\n",
    "print \"# All done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
